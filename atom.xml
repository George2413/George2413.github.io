<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>lllllcy</title>
  
  <subtitle>2020.7</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-09-04T11:23:55.484Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>George</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>有三AI文章阅读12---解决模式崩溃的框架</title>
    <link href="http://example.com/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/"/>
    <id>http://example.com/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/</id>
    <published>2021-09-04T11:47:00.000Z</published>
    <updated>2021-09-04T11:23:55.484Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-解决模式崩溃的两条路线"><a href="#1-解决模式崩溃的两条路线" class="headerlink" title="1.解决模式崩溃的两条路线"></a>1.解决模式崩溃的两条路线</h2><p>GAN的模式崩溃问题，本质上还是GAN的训练优化问题，理论上说，如果GAN可以收敛到最优的纳什均衡点，那模式崩溃的问题便自然得到解决。举例如下图，红线代表生成数据的概率密度函数，而蓝线代表训练数据集的概率密度函数，本来红线只有一个模式，也就是生成器几乎只会产生一种样本，而在理论上的最优解中，红线与蓝线重合，这时候在生成器中采样自然能几乎得到三种样本，与训练集的数据表现为一致。</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/v2-b110d096b8abd12aea5f9d7cb2c033e2_720w.jpg" alt="img" style="zoom: 80%;"><p>当然，实际中几乎不会达到全局最优解，我们看似收敛的GAN其实只是进入了一个局部最优解。故一般而言，我们有两条思路解决模式崩溃问题：1.<strong>提升GAN的学习能力，进入更好的局部最优解</strong>，例如上一期unrolled GAN，便是增加了生成器“先知”能力；如下图所示，通过训练红线慢慢向蓝线的形状、大小靠拢，比较好的局部最优自然会有更多的模式，直觉上可以一定程度减轻模式崩溃的问题。</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/v2-3949e86b68fce8de6361778d967b795b_720w.jpg" alt="img" style="zoom:80%;"><p>2.<strong>放弃寻找更优的解，只在GAN的基础上，显式得要求GAN捕捉更多的模式</strong>（如下图所示），虽然红线与蓝线的相似度并不高，但是“强制”增添了生成样本的多样性，而且这类方法大都直接修改GAN的结构。</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/v2-216c2a998977811a16e879b2815e6291_720w.jpg" alt="img" style="zoom:80%;"><h2 id="2-MAD-GAN"><a href="#2-MAD-GAN" class="headerlink" title="2.MAD-GAN"></a><strong>2.MAD-GAN</strong></h2><p>今天要介绍的MAD-GAN及其变体便是第二类方法的代表之一。</p><p>它的核心思想是这样的：<strong>即使单个生成器会产生模式崩溃的问题，但是如果同时构造多个生成器，且让每个生成器产生不同的模式，则这样的多生成器结合起来也可以保证产生的样本具有多样性</strong></p><p>如下图的3个生成器：</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/1630753458383.png" alt="1630753458383" style="zoom:80%;"><p>需要说明一下，<strong>简单得添加几个彼此孤立的生成器并无太大意义，它们可能会归并成相同的状态，对增添多样性并无益处</strong></p><p>如下图的3个生成器：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/v2-15f2d2cfe758ea5a3f3c211167af9b46_720w.jpg" alt="img"></p><p><strong>理想的状态是：多个生成器彼此“联系”，不同的生成器尽量产生不相似的样本，而且都能欺骗判别器。</strong></p><p>在MAD（Multi-agent diverse）GAN中，共包括k个初始值不同的生成器和1个判别器，与标准GAN的生成器一样，每个生成器的目的仍然是产生虚假样本试图欺骗判别器。对于判别器，它不仅需要分辨样本来自于训练数据集还是其中的某个生成器（这仍然与标准GAN的判别器一样），而且还需要驱使各个生成器尽量产生不相似的样本。</p><p>需要将判别器做一些修改：<strong>将判别器最后一层改为k+1维的softmax函数，对于任意输入样本x，D(x)为k+1维向量，其中前k维依次表示样本x来自前k个生成器的概率，第k+1维表示样本x来自训练数据集的概率</strong>。同时，构造k+1维的delta函数作为标签，如果x来自第i个生成器，则delta函数的第i维为1，其余为0，若x来自训练数据集，则delta函数的第k+1维为1，其余为0。显然，D的目标函数应为最小化D(x)与delta函数数的交叉熵：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630753866000.svg" alt="[公式]"> </p><p>直观上看，<strong>这样的损失函数会迫使每个x尽量只产生于其中的某一个生成器，而不从其他的生成器中产生</strong>，将其展开则为： <img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630753866024.svg" alt="[公式]"></p><p>生成器目标函数为： <img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630753866014.svg" alt="[公式]"> </p><p>对于固定的生成器，最优判别器为： <img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630753866022.svg" alt="[公式]"> <img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630753866054.svg" alt="[公式]"> </p><p>可以看出，其形式几乎同标准形式的GAN相同，只是不同生成器之间彼此“排斥”产生不同的样本。另外，可以证明当 <img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630753865998.svg" alt="[公式]"> </p><p>达到最优解，再一次可以看出，<strong>MAD-GAN中并不需要每个生成器的生成样本概率密度函数逼近训练集的概率密度函数，每个生成器都分别负责生成不同的样本，只须保证生成器的平均概率密度函数等于训练集的概率密度函数即可。</strong></p><h2 id="3-MAD-GAN-Sim"><a href="#3-MAD-GAN-Sim" class="headerlink" title="3.MAD-GAN-Sim"></a><strong>3.MAD-GAN-Sim</strong></h2><p>MAD-GAN-Sim是一种“更强力”的版本，<strong>它不仅考虑了每个生成器都分别负责生成不同的样本，而且更细致地考虑了样本的相似性问题</strong>。其出发点在于：来自于不同模式的样本应该是看起来不同的，故<strong>不同的生成器应该生成看起来不相似的样本</strong>。</p><p>这一想法用数学符号描述即为：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630754166179.svg" alt="[公式]"> </p><p>其中， <img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630754166097.svg" alt="[公式]"> 表示从生成样本的空间到特征空间的某种映射（我们可选择生成器的中间层，其思想类似于特征值匹配）， <img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630754166099.svg" alt="[公式]"> 表示相似度的度量，多选用余弦相似度函数，用于计算两个样本对应的特征的相似度。</p><p>对于给定的噪声输入z，考虑第i个生成器与其他生成器的样本生成情况，若样本相似度比较大，则 <img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630754166206.svg" alt="[公式]"> 相比较 <img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630754166095.svg" alt="[公式]"> 应该大很多，由于<img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630754166095.svg" alt="[公式]"> 的值比较小，<img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630754166198.svg" alt="[公式]"> 便会进行调整不再生成之前的那个相似的样本，转而去生成其他样本，利用这种“排斥”机制，我们就实现了让不同的生成器应该生成看起来不相似的样本。</p><p>将上述限制条件引入到生成器中，我们可以这样训练生成器，对于任意生成器i，对于给定的z，如果上面的条件满足，则像MAD-GAN一样正常计算，其梯度为：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630754166109.svg" alt="[公式]"> </p><p>如果条件不满足，将上述条件作为正则项添加到目标函数中，则其梯度为：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB12/equation-1630754166248.svg" alt="[公式]"></p><p>这样尽量使得判别器更新后，条件能够满足。MAD-GAN-Sim的思路非常直接清晰，不过代价就是增加非常多的计算量。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-解决模式崩溃的两条路线&quot;&gt;&lt;a href=&quot;#1-解决模式崩溃的两条路线&quot; class=&quot;headerlink&quot; title=&quot;1.解决模式崩溃的两条路线&quot;&gt;&lt;/a&gt;1.解决模式崩溃的两条路线&lt;/h2&gt;&lt;p&gt;GAN的模式崩溃问题，本质上还是GAN的训练优化问题</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN训练" scheme="http://example.com/tags/GAN%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读11---解决模式崩溃的目标函数</title>
    <link href="http://example.com/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/"/>
    <id>http://example.com/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/</id>
    <published>2021-09-04T08:20:00.000Z</published>
    <updated>2021-09-04T10:54:11.711Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-unrolled-GAN"><a href="#1-unrolled-GAN" class="headerlink" title="1.unrolled GAN"></a>1.unrolled GAN</h2><p>首先需要说明：<strong>生成器在某一时刻单纯地将样本都聚集到某几个高概率的峰下并不是我们讨厌模式崩溃的根本原因，如果生成器能自动调整权值，将生成样本分散到整个训练数据的流形上，则能自动跳出当前的模式崩溃状态，并且理论上生成器确实“具备”该项能力</strong>（因为GoodFellow证明了GAN会实现最优解）。</p><p>但是<strong>实际情况</strong>是：对于生成器的不断训练并未使其学会提高生成样本的多样性，<strong>生成器只是在不断将样本从一个峰转移聚集到另一个峰下。这样的过程“没完没了”，无法跳出模式崩溃的循环</strong>。无论你在何时终止训练，都面临着模式崩溃，只是在不同时刻，生成样本所聚集的峰不同罢了。</p><p>不过，这种情况的发生有一定的必然性，我们先使用原始形式GAN对这个过程进行示意描述，其目标函数为：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/equation-1630745850849.svg" alt="[公式]"> </p><p>真实数据集的概率分布还是如第一部分所示，生成器生成样本的概率分布如下：</p><img src="https://pic1.zhimg.com/80/v2-3ad53825d11413982b8beb32f1a07be4_720w.jpg" alt="img" style="zoom:50%;"><p>我们先更新判别器：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/equation-1630745850792.svg" alt="[公式]"></p><p>假设判别器达到了最优状态，则其表达式应为：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/equation-1630745850805.svg" alt="[公式]"> </p><p>对应的，D(x)的图像为：</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/1630745987380.png" alt="1630745987380" style="zoom:50%;"><p>可以看出，这时判别器会立刻“怀疑”x=-3附近样本点的真实性，接下来更新生成器：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/equation-1630745850810.svg" alt="[公式]"></p><p>此时的生成器将会非常“无可奈何”，为了使得目标函数f最小，最好的方法便是将样本聚集到x=3附近，即：</p><img src="https://pic4.zhimg.com/80/v2-bfade923a159ad62b3065598a6563c0b_720w.jpg" alt="img" style="zoom:50%;"><p>再更新判别器，同上述过程，判别器会立刻“怀疑”x=3附近样本点的真实性……这样的糟糕结果会不断循环下去。</p><p>对此，<strong>unrolled GAN认为：正是因为生成器缺乏“先见之明”，导致了无法跳出模式崩溃的困境，生成器每次更新参数时，只考虑在当前生成器和判别器的状态下可以获得的局部最优解，生成器并不知道当前选择的最优解并不是全局最优解。</strong></p><p>我们通过一定的改进，来提高生成器的“先见之明”。具体说来，判别器的目标函数仍然为：</p><p>&emsp;&emsp;&emsp;<img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/equation-1630745850792.svg" alt="[公式]"> </p><p>参数更新方式为采用梯度下降方式连续更新K次，如下：</p><p>&emsp;&emsp;&emsp;&emsp;<img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/equation-1630745850849.svg" alt="[公式]"> </p><p>而生成器的优化目标修改为：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/equation-1630745850825.svg" alt="[公式]"></p><p><strong>即生成器在更新时，不仅仅考虑当前生成器的状态，还会额外考虑K次更新后判别器的状态，综合两个信息做出最优解</strong>。其梯度的变化为：</p><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/equation-1630745850854.svg" alt="[公式]" style="zoom:90%;"> </p><p>第一项就是非常熟悉的标准GAN形式的计算得到的梯度，而第二项便是考虑K次更新后判别器的状态而产生的附加项。</p><p>我们现在再看刚才的问题，unrolled GAN会跳出模式崩溃的循环。同样的初始状态，</p><img src="https://pic1.zhimg.com/80/v2-3ad53825d11413982b8beb32f1a07be4_720w.jpg" alt="img" style="zoom:50%;"><p>生成器在进行下一步更新时，面对以下两种可能性（左边是之前提到过的模式崩溃状态，右边是理想的样本生成状态）：</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/v2-fe52a314b9ce5376fd28fdeba07b6ba4_720w.jpg" alt="img" style="zoom: 80%;"><p>经计算，选择右边会比选择左边产生更小的目标函数值，故实际中，生成器进行梯度更新将会趋向于右边的状态从而跳出模式崩溃。可以看出，<strong>生成器跳出模式崩溃的核心原因就是更新参数时不仅考虑当下状态，而且额外考虑了K步判别器的反应，从而避免了找局部最优解的行为</strong>，当然需要说明，这样做是明显增加了计算量的。</p><h2 id="2-DRAGAN"><a href="#2-DRAGAN" class="headerlink" title="2.DRAGAN"></a>2.DRAGAN</h2><p>GAN的参数优化问题并不是一个凸优化问题，<strong>存在许多局部纳什均衡状态</strong>。即使GAN进入某个纳什均衡状态，损失函数表现为收敛，其仍旧可产生模式崩溃，我们认为此时参数进入一个坏的局部均衡点。</p><p>通过实践，发现当GAN出现模式崩溃问题时，通常伴随着这样的表现：当判别器在训练样本附近更新参数时，其梯度值非常大，<strong>故DRAGAN的解决方法是：对判别器，在训练样本附近施加梯度惩罚项：</strong></p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB11/equation-1630746726812.svg" alt="[公式]"></p><p>这种方式试图在训练样本附近构建线性函数，因为线性函数为凸函数具有全局最优解。需要额外说明，DRAGAN的形式与WGAN-GP颇为相似，只是WGAN-GP是在全样本空间施加梯度惩罚，而DRAGAN只在训练样本附近施加梯度惩罚。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-unrolled-GAN&quot;&gt;&lt;a href=&quot;#1-unrolled-GAN&quot; class=&quot;headerlink&quot; title=&quot;1.unrolled GAN&quot;&gt;&lt;/a&gt;1.unrolled GAN&lt;/h2&gt;&lt;p&gt;首先需要说明：&lt;strong&gt;生成器在某一时</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN训练" scheme="http://example.com/tags/GAN%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读10---从动力学视角看GAN以及一致优化</title>
    <link href="http://example.com/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/"/>
    <id>http://example.com/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/</id>
    <published>2021-09-04T06:20:00.000Z</published>
    <updated>2021-09-04T08:49:26.234Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-相关知识"><a href="#1-相关知识" class="headerlink" title="1.相关知识"></a><strong>1.相关知识</strong></h2><p>先不谈GAN，先介绍一个特别重要的与动力学收敛性相关的命题，考虑一个如下形式的函数：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738532489.svg" alt="[公式]"> </p><p>其中h大于0。有这样一个命题：如果存在一个比较特殊的点（<strong>不动点</strong>）使得：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738532486.svg" alt="[公式]"> </p><p>而且在该不动点，函数F(x)的雅可比矩阵F’(x)的所有特征值（非对称矩阵的特征值为复数）的绝对值均小于1，则从该不动点的一小邻域内的任意一点开始，使用如下形式的数值迭代法：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738532643.svg" alt="[公式]"> </p><p>则F最终会收敛至：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738532599.svg" alt="[公式]"> </p><p>为了直观一些，上述的数值迭代过程其实是在使用数值迭代的方式求：y=x和y=x+hG(x)两个函数的交点，如下示意：</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630738544913.png" alt="1630738544913" style="zoom: 50%;"><p>非常难得有一个好的关于收敛性的结论，而且其数值迭代的方式与实际的GAN训练方式也吻合，我们考虑将GAN对接到这个结论中。</p><p>我们将生成器和判别器的目标函数均写成max的形式：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738752284.svg" alt="[公式]"></p><p>那么对应于第一小节的式子，x对应为GAN的参数：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738752241.svg" alt="[公式]"></p><p>而 <strong>h 可以对应为训练时候的学习速率</strong>，而G(x)则对应为矢量场v：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738752290.svg" alt="[公式]"></p><p>这样看来，就是<strong>使用同时梯度下降法进行参数更新</strong>（由于将目标函数写成max形式，准确来说是梯度上升法）：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738752296.svg" alt="[公式]"></p><p>将一般形式与GAN对接起来后，再次考虑之前关于收敛性的结论，便是：<strong>如果存在满足如下形式的点（即不动点）</strong></p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738752287.svg" alt="[公式]"></p><p>并且在不动点，矢量场v的雅可比矩阵的所有特征值的绝对值均小于1<strong>（在不动点，v=0，即梯度为0），</strong>则从该不动点的某一个邻域内任意一点开始迭代，则最终进入收敛状态。<strong>（那么我们可以对GAN的训练过程进行“检查”，当出现一个梯度为0的参数点时，“检查”其矢量场的雅可比矩阵的特征值是否都在单位圆内，如果在则GAN的迭代最终会收敛进该点。）</strong></p><h2 id="2-对接GAN"><a href="#2-对接GAN" class="headerlink" title="2.对接GAN"></a>2.对接GAN</h2><p><font size="4">雅可比矩阵：   jacobi描述输入的每个维度上的分量对输出上每个的分量的结果贡献度 </font></p><p> 雅克比矩阵是由偏导数组成的,偏导数对应各个自变量前的系数,这些系数组合在一起就是向量,雅克比矩阵每一列都是一个向量. </p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630739426535.png" alt="1630739426535" style="zoom:67%;"><p>在纳什均衡点处，其雅可比矩阵是负定的。</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738993496.svg" alt="[公式]" style="zoom:76%;"><p>反过来，<font color="red"><strong>可以通过检查雅可比矩阵的性质来判断是否达到了局部收敛，如果在某个点，其一阶导数为0，且其雅可比矩阵为半负定矩阵，则该点为纳什均衡点。</strong></font></p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738993512.svg" alt="[公式]"></p><p>我们知道半负定矩阵的特征值均小于等于0，则：<strong>如果在某一点的雅可比矩阵的特征值为负实数，则在足够小的学习速率的前提下，训练过程收敛；如果特征值出现复数，则训练一般而言不会实现局部收敛；如果复数特征值的实部很小而虚部比较大，此时需要要求非常高的学习速率才能达到收敛状态。</strong></p><h2 id="3-特征值分析"><a href="#3-特征值分析" class="headerlink" title="3.特征值分析"></a>3.特征值分析</h2><p>训练GAN要找到梯度为0似乎不是那么困难，但是实现第二个条件：在不动点的矢量场v的雅可比矩阵的所有特征值的绝对值均小于1 可能比较困难，我们来详细分析一下。考虑一般情况下的表达式：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630740229725.svg" alt="[公式]"></p><p>F(x)的雅可比矩阵为：</p><p><img src="https://www.zhihu.com/equation?tex=F%27(x)=I+hG%27(x)%5C%5C+" alt="[公式]"></p><p>对其进行特征值分解，单位矩阵I的特征值是实数1，而考虑到一般情况下另外两个矩阵是非对称矩阵，则其特征值必然是复数，设G’(x)分解出的特征值为：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630740229729.svg" alt="[公式]"> </p><p>则F’(x)的分解出的特征值为</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630740229870.svg" alt="[公式]"> </p><p>如下所示：</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630740247619.png" alt="1630740247619" style="zoom: 60%;"><p>特征值很容易跑出到单位圆之外<strong>。要保证其绝对值小于1（即在单位圆里），首先要保证a小于0</strong>，(a大于等于0时，该条件不可能满足)，如下所示：</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630740270304.png" alt="1630740270304" style="zoom: 50%;"><p>即G’(x)分解出的特征值的实部为负数，此时：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+&%5B(1+ha)+hb%5C+i%5D%5B(1+ha)-hb%5C+i%5D%3C1%5C%5C+%5CLeftrightarrow+&+h%3C%5Cfrac%7B1%7D%7B%5Cmid+a+%5Cmid%7D%5Cfrac%7B2%7D%7B1+(b/a)%5E2%7D+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"></p><p>也就是说，<strong>要想进入收敛状态，特征值的实部要为负数，且同时要求学习速率h一定要足够小</strong>！其上界取决于特征值。但是这里有一个矛盾点，如果你将学习速率设置得太小，你的训练时长将会变得特别长。</p><p>同样地，在GAN中，需要保证矢量场v的雅可比矩阵</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630740229915.svg" alt="[公式]"></p><p>的所有特征值的实部为负数。<strong>但是实际中，这个条件是不太可能达到的，尤其是存在实部几乎为0而虚部的值比较大的情况，而且学习速率要设置的足够小。</strong></p><p>注意到矢量场v的雅可比矩阵是与生成器和判别器的目标函数f、g相关的，<strong>考虑调整一下f和g，使得在不动点处的特征值的实部为负数。</strong></p><h2 id="4-一致优化"><a href="#4-一致优化" class="headerlink" title="4.一致优化"></a>4.一致优化</h2><h3 id="4-1-emsp-基本概念"><a href="#4-1-emsp-基本概念" class="headerlink" title="4.1&emsp;基本概念"></a>4.1&emsp;基本概念</h3><p>一致优化(Conseensus Optimization)是一种理论上比较好的方法，它做了一点“手脚”使得特征值的实部尽量为负数。先考虑一般的形式：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630741233747.svg" alt="[公式]"> </p><p>其中， γ 大于0，A为可逆矩阵，表达式为：</p><p><img src="https://www.zhihu.com/equation?tex=A(x)=I-%5Cgamma+G%27(x)%5E%5Cmathrm%7BT%7D%5C%5C" alt="[公式]"> </p><p>严谨起见，需要说明一下：如果某个x是</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630741233746.svg" alt="[公式]"> </p><p>的一个不动点，则该x也是</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630741233747.svg" alt="[公式]"> </p><p>的不动点，这里并没有因为在式子中添加A(x)而影响了不动点，之前可能在哪里收敛，之后还是可能在那个点收敛。而且在该不动点，</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+F%27(x)&=I+h(A%27(x)G(x)+A(x)G%27(x))%5C%5C+=&I+hA(x)G%27(x)%5C%5C+=&I+h%5B(I-%5Cgamma+G%27(x)%5E%7B%5Cmathrm%7BT%7D%7D)G%27(x)%5D%5C%5C+=&I+hG%27(x)-h%5Cgamma+G%27(x)%5E%7B%5Cmathrm%7BT%7D%7DG%27(x)+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"></p><p>可以看出，相比于第3部分的表达式，<strong>新增加的一项会使得特征值向实数部的负数方向偏移</strong>（新增项为负定矩阵，其特征值必然为负实数），如图所示</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630741458983.png" alt="1630741458983" style="zoom:50%;"><p>如果超参数γ设置比较合理，“有希望”保证特征值均落在单位圆内。</p><p>现在，我们将上述方式对接到GAN中，将生成器和判别器的目标函数修改为：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630741233649.svg" alt="[公式]"></p><p>其中， <img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630741233733.svg" alt="[公式]"></p><p>可以写成如下形式：</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630741233763.svg" alt="[公式]" style="zoom: 80%;"><p>化简可有：</p><img src="https://www.zhihu.com/equation?tex=%5Cleft%28++%5Cbegin%7Bmatrix%7D++%5Ctheta_G+%5C%5C++%5Ctheta_D+%5C%5C+++%5Cend%7Bmatrix%7D+++%5Cright%29%3A%3D%5Cleft%28++%5Cbegin%7Bmatrix%7D++%5Ctheta_G+%5C%5C++%5Ctheta_D+%5C%5C+++%5Cend%7Bmatrix%7D+++%5Cright%29%2Bh+v%28%7B%5Ctheta_G%7D%2C%7B%5Ctheta_D%7D%29+-%5Cgamma+v%27%28%7B%5Ctheta_G%7D%2C%7B%5Ctheta_D%7D%29%5E%7B%5Cmathrm%7BT%7D%7Dv%28%7B%5Ctheta_G%7D%2C%7B%5Ctheta_D%7D%29+%5C%5C" alt="[公式]" style="zoom:80%;"><p>其雅可比矩阵的表达式为：</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630741692748.png" alt="1630741692748" style="zoom:80%;"><p>根据之前的结论，如果γ设置比较合理，学习速率h足够小，则其特征值均会落入单位圆内，参数会进入不动点，也就是说进入纳什均衡的状态。</p><p><strong>最后说明一下，一般GAN中，生成器和判别器的目标函数符号是相反的，但是我们同时对它们增加相同符号的正则项，在正则项部分上，它们的优化目标是一致的，故为一致优化。</strong></p><h3 id="4-2-emsp-具体数学表达"><a href="#4-2-emsp-具体数学表达" class="headerlink" title="4.2&emsp;具体数学表达"></a>4.2&emsp;具体数学表达</h3><p>一致优化以标准的GAN+一致优化正则项为例，其损失函数的表达式为：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630745097746.svg" alt="[公式]"></p><p>在Dirac-GAN中，对应的损失函数成为：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630745097664.svg" alt="[公式]"></p><p>相应的动力学系统：</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630745097667.svg" alt="[公式]"></p><p>结果有点复杂，但是确实在Dirac-GAN中精确收敛至(0,0)：</p><p>实际情况中必须保证学习速率要足够小，才可能收敛。</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630745362356.png" alt="1630745362356" style="zoom:67%;"><h2 id="个人理解："><a href="#个人理解：" class="headerlink" title="个人理解："></a>个人理解：</h2><p>如果存在一个不动点，而且在该不动点，函数F(x)的雅可比矩阵F’(x)的<strong>所有特征值的绝对值均小于1</strong>，则从该不动点的一小邻域内的任意一点开始，使用欧拉法进行迭代，则 F 最终会收敛到这个点</p><p>&emsp;&emsp;<img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738532489.svg" alt="[公式]"> </p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630738532486.svg" alt="[公式]"> </p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630743130041.png" alt="1630743130041" style="zoom: 80%;"><p>但是想让所有特征值的绝对值均小于1，不太容易实现，因为它本来就是一个复数的形式。所以我们可以让实部为负数并且h尽可能小，这样有可能让数值在单位圆内，即特征值小于1。h在GAN中表示学习了。</p><p>但是<strong>所有</strong>特征值的实部为负数。但是实际中，这个条件是不太可能达到的。</p><p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630740247619.png" alt="1630740247619" style="zoom: 45%;">                    <img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630740270304.png" alt="1630740270304" style="zoom: 40%;"></p><p>所以我们使用一致优化方法，本质上是在这个特征值的实部加一个负数，让a+这个负数小于0。</p><img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630741458983.png" alt="1630741458983" style="zoom:45%;"><p>具体实现方法： 乘以一项A（X），其中， γ 大于0，A为可逆矩阵，</p><p>&emsp;&emsp;<img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/equation-1630741233747.svg" alt="[公式]">   </p><p><img src="https://www.zhihu.com/equation?tex=A(x)=I-%5Cgamma+G%27(x)%5E%5Cmathrm%7BT%7D%5C%5C" alt="[公式]"></p><p>化简：</p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+F%27%28x%29%26%3DI%2Bh%28A%27%28x%29G%28x%29%2BA%28x%29G%27%28x%29%29%5C%5C+%3D%26I%2BhA%28x%29G%27%28x%29%5C%5C+%3D%26I%2Bh%5B%28I-%5Cgamma+G%27%28x%29%5E%7B%5Cmathrm%7BT%7D%7D%29G%27%28x%29%5D%5C%5C+%3D%26I%2BhG%27%28x%29-h%5Cgamma+G%27%28x%29%5E%7B%5Cmathrm%7BT%7D%7DG%27%28x%29+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"><p>F(x)转换为GAN 的形式后：<img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630743811696.png" alt="1630743811696" style="zoom: 80%;"></p><p>化简结果如下：   <img src="https://www.zhihu.com/equation?tex=%5Cleft%28++%5Cbegin%7Bmatrix%7D++%5Ctheta_G+%5C%5C++%5Ctheta_D+%5C%5C+++%5Cend%7Bmatrix%7D+++%5Cright%29%3A%3D%5Cleft%28++%5Cbegin%7Bmatrix%7D++%5Ctheta_G+%5C%5C++%5Ctheta_D+%5C%5C+++%5Cend%7Bmatrix%7D+++%5Cright%29%2Bh+v%28%7B%5Ctheta_G%7D%2C%7B%5Ctheta_D%7D%29+-%5Cgamma+v%27%28%7B%5Ctheta_G%7D%2C%7B%5Ctheta_D%7D%29%5E%7B%5Cmathrm%7BT%7D%7Dv%28%7B%5Ctheta_G%7D%2C%7B%5Ctheta_D%7D%29+%5C%5C" alt="[公式]" style="zoom:80%;"></p><p>其雅可比矩阵的表达式为：    <img src="/2021/09/04/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/1630741692748.png" alt="1630741692748" style="zoom:80%;"></p><p><font size="5"><font color="red">如果γ设置比较合理，学习速率h足够小，则其特征值均会落入单位圆内，参数会进入不动点，也就是说进入纳什均衡的状态。</font></font></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-相关知识&quot;&gt;&lt;a href=&quot;#1-相关知识&quot; class=&quot;headerlink&quot; title=&quot;1.相关知识&quot;&gt;&lt;/a&gt;&lt;strong&gt;1.相关知识&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;先不谈GAN，先介绍一个特别重要的与动力学收敛性相关的命题，考虑一个如下形</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN训练" scheme="http://example.com/tags/GAN%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>ResNet</title>
    <link href="http://example.com/2021/09/04/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/"/>
    <id>http://example.com/2021/09/04/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/</id>
    <published>2021-09-04T03:50:00.000Z</published>
    <updated>2021-09-04T04:05:55.452Z</updated>
    
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="训练技巧（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN训练" scheme="http://example.com/tags/GAN%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读9---几个训练小技巧</title>
    <link href="http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/"/>
    <id>http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/</id>
    <published>2021-09-03T07:47:00.000Z</published>
    <updated>2021-09-04T08:06:35.767Z</updated>
    
    <content type="html"><![CDATA[<p>今天这篇小文将从博弈论的角度出发来审视一下GAN训练时的问题，并给出了3个稳定训练的小技巧。 </p><h2 id="1-博弈论与GAN"><a href="#1-博弈论与GAN" class="headerlink" title="1. 博弈论与GAN"></a>1. 博弈论与GAN</h2><p>先从博弈论的角度来重新描述GAN模型。游戏中有两个玩家：D（判别器）和G（生成器），D试图在判别器的参数空间上寻找最好的解使得它的损失函数最小：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630655364940.svg" alt="[公式]"></p><p>G也试图在生成器的参数空间上寻找最好的解使得它的损失函数最小：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation.svg" alt="[公式]"></p><p>需要说明，D和G并不是彼此独立的，对于GAN，整个博弈是“交替进行决策”的。例如先确定生成器G的参数，则D会在给定的G的参数的条件下更新判别器的参数以此最小化D的损失函数，如下面中蓝线过程（提升D的辨别能力）；接着G会在给定的D的参数的条件下更新判别器的参数以此来最小化G的损失函数，如下面中绿线过程（提升G的生成能力）……直到达到一个稳定的状态：纳什均衡。</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/1630655383491.png" alt="1630655383491" style="zoom: 67%;"><p>在纳什均衡点，两者的参数到达一种“制衡”状态。在给定G的参数情况下，D当前的参数便对应了D损失函数的最小值，同样在给定D的参数情况下，G当前的参数便对应了G损失函数的最小值，也就是说在交替更新过程中，D和G均不可能单独做出任何改变。</p><p>解空间中可能存在多个纳什均衡点，而且纳什均衡点并不意味着全局最优解，但是是一种经过多次博弈后的稳定状态，所以说<strong>GAN的任务是并非寻找全局最优解，而是寻找一个纳什均衡状态，损失函数收敛即可</strong>。在损失函数非凸、参数连续、参数空间维度很高的情况下，不可能通过严格的数学计算去更新参数从而找到纳什均衡，在GAN中，每次参数更新（对应蓝线、绿线表示的过程）使用的是梯度下降法；另外，每次D或者G对自身参数更新都会减少自身的损失函数同时加大对方的损失函数，这导致了寻找GAN的纳什均衡是比较困难的。</p><p><strong>针对于GAN训练的收敛性问题，我们接下来将介绍几种启发式的技巧。</strong></p><h2 id="2-特征匹配"><a href="#2-特征匹配" class="headerlink" title="2. 特征匹配"></a>2. 特征匹配</h2><p>在GAN中，<strong>判别器D输出一个0到1之间的标量表示接受的样本来源于真实数据集的概率</strong>，而<strong>生成器的训练目标就是努力使得该标量值最大</strong>。如果从特征匹配(feature matching)的角度来看，整个判别器D(x)由两部分功能组成，先通过前半部分f(x)提取到样本的抽象特征，后半部分的神经网络根据抽象特征进行判定分类，即</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/v2-e36ec9a4f13c36a22ae88ce9a1844580_720w.jpg" alt="img" style="zoom:50%;"><p>f(x)表示判别器中截止到中间某层神经元激活函数的输出。在训练判别器时，我们试图找到一种能够区分两类样本的特征提取方式f(x)，而在训练生成器的时候，我们可以不再关注D(x)的概率输出，我们可以关注：<strong>从生成器生成样本的中用f(x)提取的抽象特征是否与在真实样本中用f(x)提取的抽象特征相匹配</strong>，另外，为了匹配这两个抽象特征的分布，考虑其一阶统计特征：均值，即可将生成器的目标函数改写为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862789.svg" alt="[公式]"></p><p>采用这样的方式，我们可以让生成器不过度训练，让训练过程相对稳定一些。</p><h2 id="3-历史均值"><a href="#3-历史均值" class="headerlink" title="3. 历史均值"></a>3. 历史均值</h2><p>历史均值(historical averaging)是一个非常简单方法，就是在生成器或者判别器的<strong>损失函数中添加一项</strong>：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862874.svg" alt="[公式]"></p><p><strong>这样做使得判别器或者生成器的参数不会突然产生较大的波动</strong>，直觉上看，在快要达到纳什均衡点时，参数会在纳什均衡点附近不断调整而不容易跑出去。这个技巧在处理低维问题时确实有助于进入纳什均衡状态从而使损失函数收敛， <font color="red"><strong>但是GAN中面临的是高维问题，助力可能有限。</strong></font>  </p><h2 id="4-单侧标签平滑—————-没看懂"><a href="#4-单侧标签平滑—————-没看懂" class="headerlink" title="4.单侧标签平滑—————-没看懂"></a>4.单侧标签平滑—————-没看懂</h2><p>标签平滑(label smoothing)方法最开始在1980s就提出过，它在分类问题上具有非常广泛的应用，主要是为了解决过拟合问题。一般的，我们的分类器最后一层使用softmax层输出分类概率（Sigmoid只是softmax的特殊情况），我们用二分类softmax函数来说明一下标签平滑的效果。</p><p>对于给定的样本x，其类别为1，则标签为[1,0]，如果不用标签平滑，只使用“硬”标签，其交叉熵损失函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862866.svg" alt="[公式]"></p><p>这时候通过最小化交叉熵损失函数来训练分类器，本质上是使得：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862941.svg" alt="[公式]"> </p><p>其实也就是使得：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862790.svg" alt="[公式]"></p><p>对于给定的样本x，使z1的值无限大（当然这在实际中是不可能的）而使z2趋于0，无休止拟合该标签1，便产生了过拟合、降低了分类器的泛化能力。如果使用标签平滑手段，对给定的样本x，其类别为1，例如平滑标签为[1-ε ,ε]，交叉损失函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862813.svg" alt="[公式]"></p><p>当损失函数达到最小值时，有：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862801.svg" alt="[公式]"></p><p>选择合适的参数，理论上的最优解z1与z2存在固定的常数差值（此差值由ε决定），便不会出现z1无限大，远大于z2的情况了。 如果将此技巧用在GAN的判别器中，即对生成器生成的样本输出概率值0变为β ，则生成器生成的单样本交叉熵损失函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862835.svg" alt="[公式]"></p><p>而对数据集中的样本打标签由1降为α，则数据集中的单样本交叉熵损失函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862834.svg" alt="[公式]"></p><p>总交叉损失函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862834.svg" alt="[公式]"></p><p>其最优解D(x)为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862933.svg" alt="[公式]"></p><p>实际训练中，有大量这样的x：其在训练数据集中概率分布为0，而在生成器生成的概率分布不为0，他们经过判别器后输出为β。为了能迅速“识破”该样本，最好将β降为0，这就是所谓的单侧标签平滑。</p><p>训练GAN时，我们对它的要求并不是找到全局最优解，能进入一个纳什均衡状态、损失函数收敛就可以了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;今天这篇小文将从博弈论的角度出发来审视一下GAN训练时的问题，并给出了3个稳定训练的小技巧。 &lt;/p&gt;
&lt;h2 id=&quot;1-博弈论与GAN&quot;&gt;&lt;a href=&quot;#1-博弈论与GAN&quot; class=&quot;headerlink&quot; title=&quot;1. 博弈论与GAN&quot;&gt;&lt;/a&gt;1. </summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN训练" scheme="http://example.com/tags/GAN%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读13---mini-batch discriminator</title>
    <link href="http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/"/>
    <id>http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/</id>
    <published>2021-09-03T07:47:00.000Z</published>
    <updated>2021-09-04T11:41:56.510Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-模式崩溃的原因"><a href="#1-模式崩溃的原因" class="headerlink" title="1.模式崩溃的原因"></a><strong>1.模式崩溃的原因</strong></h2><p>当模式崩溃发生时，生成器 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655045.svg" alt="[公式]"> 往往会把很多不同的z均映射成某个 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655051.svg" alt="[公式]"> （更确切地说，指 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655051.svg" alt="[公式]"> 以及其附近的点，用A表示），接下来更新判别器 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655032.svg" alt="[公式]"> 后，判别器会很快发现这个病态的mode A从而降低了对这个mode A的信任程度（信任程度即该点来源于训练数据集的概率），而信任mode B，则生成器会把很多不同的z均映射成 <img src="https://www.zhihu.com/equation?tex=x%27" alt="[公式]"> ，其中<img src="https://www.zhihu.com/equation?tex=x%27" alt="[公式]">表示一个新的mode B，如下图所示。接着，判别器发现 <img src="https://www.zhihu.com/equation?tex=x%27" alt="[公式]"> 这个新的的病态mode B……</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/v2-4df60db538ca630c881ddec7c18114aa_720w.jpg" alt="img" style="zoom:67%;"><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/v2-0af46dd9ef7efcbfdce17c1a8c31be21_720w.jpg" alt="img" style="zoom:67%;"><p>生成器和判别器陷入这样没有意义的循环。我们梳理一下上面的环节，生成器 <img src="https://www.zhihu.com/equation?tex=G(z)" alt="[公式]"> 把很多不同的z均映射成某个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]">，而不是将部分 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation.svg" alt="[公式]"> 映射到mode A，部分 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation.svg" alt="[公式]"> 映射到mode B，但这不应该引起担忧，因为可以训练判别器来识别这个不好的mode A再改进 <img src="https://www.zhihu.com/equation?tex=G(z)" alt="[公式]"> 即可；接着，训练判别器环节也没有问题，实践中甚至担忧判别器训练得过好了；那么问题出在最后一步：生成器把生成样本都转移放置到新的mode B下！显然，生成器的训练是“过分”的，理想上生成器应该将部分生成样本都转移放置到mode B下，保留部分生成样本在mode A下，如下图所示。</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/v2-c2723672b55bc77e50186f86ed6d0642_720w.jpg" alt="img" style="zoom:67%;"><p>其实这并不奇怪，因为在训练生成器时，目标函数为：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655099.svg" alt="[公式]" style="zoom:80%;"><p>其过程为：生成器 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655045.svg" alt="[公式]"> 生成m个样本 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655051.svg" alt="[公式]"> ，然后将m个 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655051.svg" alt="[公式]"> 分别独立送给判别器 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655032.svg" alt="[公式]"> 判定获得梯度信息。在上面的例子中，由于判别器不信任mode A而非常信任mode B，故对于任意 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655051.svg" alt="[公式]"> ，判别器都将指引其接近mode B： <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655026.svg" alt="[公式]"> ，也就是说对于任意 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655051.svg" alt="[公式]">，判别器传递给生成器 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754655045.svg" alt="[公式]">得到的梯度的方向是相同的，生成器按着该梯度方向更新参数极易把所有的生成样本转移到mode B下。</p><h2 id="2-mini-batch-discriminator"><a href="#2-mini-batch-discriminator" class="headerlink" title="2.mini-batch discriminator"></a>2.mini-batch discriminator</h2><p><strong>根据第一节的讨论，原因还是出现在判别器上，因为判别器每次只能独立处理一个样本，生成器在每个样本上获得的梯度信息缺乏“统一协调”</strong>，都指向了同一个方向，而且也不存在任何机制要求生成器的输出结果彼此有较大差异。</p><p>小批量判别器给出的解决方案是：<strong>让判别器不再独立考虑一个样本，而是同时考虑一个小批量的样本</strong>。</p><p>具体办法如下： 对于一个小批量的每个样本 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754884304.svg" alt="[公式]"> ，将判别器的某个中间层 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698052.svg" alt="[公式]"> 的结果引出，为一个n维向量 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698059.svg" alt="[公式]"> ，将该向量与一个可学习的张量 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698071.svg" alt="[公式]"> 相乘，得到样本 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698081.svg" alt="[公式]"> 的 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698078.svg" alt="[公式]"> 维的特征矩阵 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698177.svg" alt="[公式]"> ，可视为得到了 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698173.svg" alt="[公式]"> 个 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698120.svg" alt="[公式]"> 维特征。</p><p>接着，每一个样本 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698081.svg" alt="[公式]"> 与小批量中其他样本的第 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698105.svg" alt="[公式]"> 个特征的差异和为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698113.svg" alt="[公式]"> 其中， <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698109.svg" alt="[公式]"> 表示 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698177.svg" alt="[公式]"> 的第 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698105.svg" alt="[公式]"> 行，并使用L1范数表示两个向量的差异。</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/v2-03299723b0bbf6aade82769bb757f8e7_720w.jpg" alt="img"></p><p>那么每个样本都将会计算得到一个对应的向量：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698137.svg" alt="[公式]"> </p><p>最后将 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698134.svg" alt="[公式]"> 作为额外接入引出的中间层的下一层 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698152.svg" alt="[公式]"> 即可，<strong>也就是说在原来判别器的基础上加了一个mini-batch层</strong>，其输入是<img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698059.svg" alt="[公式]">，而输出是<img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698134.svg" alt="[公式]">，中间还包括一个可学习参数 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698157.svg" alt="[公式]"> 。<strong>原始的判别器要求给出样本来源于训练数据集的概率，而小批量判别器的任务仍然是输出样本来源于训练数据集的概率，只不过它能力更强，因为它能利用批量样本中的其他样本作为附加信息。</strong></p><p>还是在第一节的例子中，使用小批量判别器，当发生模式崩溃的生成器需要更新时， <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698158.svg" alt="[公式]"> 首先生成一个批量的样本 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698172.svg" alt="[公式]"> ，由于这些样本都在mode A下，则计算得到的mini-batch层结果<img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698183.svg" alt="[公式]">必然与训练数据集的计算得到的mini-batch层结果有很大差异<strong>，捕捉到的差异信息会使小批量判别器 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630754698177.svg" alt="[公式]"> 值不会太低，小批量判别器不会简单地对所有样本给出相同的梯度方向。</strong></p><h2 id="3-简化版本"><a href="#3-简化版本" class="headerlink" title="3.简化版本"></a>3.简化版本</h2><p>在Progressive GAN中，给出了一个简化版本的小批量判别器，其思想与上述相同，只是计算方式比较简单。</p><p>对于判别器的输入样本 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630755252541.svg" alt="[公式]">，抽取某中间层作为 m 维特征有 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630755252548.svg" alt="[公式]"> ，<strong>计算每个维度的标准差并求均值</strong>，即 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630755252519.svg" alt="[公式]"> </p><p>其中</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630755252440.svg" alt="[公式]" style="zoom:80%;"><p>最后将 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E9%98%85%E8%AF%BB13/equation-1630755252541.svg" alt="[公式]"> 作为特征图与中间层的输出拼接到一起。Progressive GAN的小批量判别器中不含有需要学习的参数，而是直接计算批量样本的统计特征，更为简洁。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-模式崩溃的原因&quot;&gt;&lt;a href=&quot;#1-模式崩溃的原因&quot; class=&quot;headerlink&quot; title=&quot;1.模式崩溃的原因&quot;&gt;&lt;/a&gt;&lt;strong&gt;1.模式崩溃的原因&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;当模式崩溃发生时，生成器 &lt;img src=&quot;/2</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN训练" scheme="http://example.com/tags/GAN%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读8---GAN训练遇到的问题</title>
    <link href="http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/"/>
    <id>http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/</id>
    <published>2021-09-03T07:19:00.000Z</published>
    <updated>2021-09-04T08:06:30.838Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-梯度消失问题"><a href="#1-梯度消失问题" class="headerlink" title="1.梯度消失问题"></a>1.梯度消失问题</h2><p>在早期的GAN中，有一条经验：<strong>不要把判别器训练得太好，以避免后期梯度消失导致无法训练生成器</strong>。在第三期中，我们曾谈论过类似的问题，只不过是从f-divergence的角度来探讨的，简而言之，判别器的任务是辅助学习数据集的本质概率分布和生成器定义的隐式概率分布之间的某种距离，生成器的任务是使该距离达到最小。<strong>当两个概率分布没有重合或者重合部分可忽略时，其f散度值为常数；当两者完全重合时，f散度值突变成0</strong>，<strong>f散度距离无法为生成器提供可以减少损失函数的梯度信息，生成器无法训练获得优化方向。</strong></p><p>这次我们从GAN的训练过程的角度再一次来谈论这个问题。通过理论和大量的实践，我们几乎可以认为数据集的本质概率分布和生成器定义的隐式概率分布均是高维数据空间中的低维流形，几乎不存在重叠部分（重叠部分测度为0），可以证明此时必然存在一个最优判别器D*可以将两个分布完全分开，它在数据集的分布上置1而在生成分布上置0，即：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630653729743.svg" alt="[公式]"></p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630653729736.svg" alt="[公式]"></p><p>而且在x的邻域内，其导数为0，即</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation.svg" alt="[公式]"></p><p>此时，我们无法使用反向传播算法来使生成器进行学习，因为我们可以证明出：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630653729714.svg" alt="[公式]"></p><p>即不断训练判别器D(x)使其逼近最优判别器的代价是：梯度消失！生成器无法获得任何信息来进行更新，两个分布之间的距离并没有被缩小，整个迭代过程变成无用的循环过程。</p><h2 id="2-采样计算距离问题"><a href="#2-采样计算距离问题" class="headerlink" title="2.采样计算距离问题"></a>2.采样计算距离问题</h2><p>WGAN是解决上述梯度消失问题的一个好办法， 现在我们来看在实际训练GAN时候的第二个问题：</p><p>首先来看一个小例子，我们定义一个标准的正态分布：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295100.svg" alt="[公式]"></p><p>从该分布中采样出m个样本组成一个均匀分布：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295108.svg" alt="[公式]"></p><p>那么可以有一个结论：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295102.svg" alt="[公式]"></p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295110.svg" alt="[公式]"></p><p>也就是说，在有限个采样个数的情况下（实际中样本数m足够大是不可能成立的），均匀分布的样本并不能等同于源分布，两者还有一定的“距离”。那么对于两个正态分布，很可能“采样”分布之间距离并不等于两个分布之间的真实距离。</p><p>实际的结论确实如此：对于两个标准正态分布  <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654345451.svg" alt="[公式]">   和 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295222.svg" alt="[公式]"> 以及两个分别从中采样得到的样本的均匀分布 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295182.svg" alt="[公式]"> 和 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295256.svg" alt="[公式]"> ，有非常大的概率认为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295135.svg" alt="[公式]"></p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295137.svg" alt="[公式]"></p><p>在GAN中，我们也是通过采样来近似计算分布之间的距离的，最理想下状态，两个概率分布之间的距离等于两个“采样”分布的距离，或者相差很小：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295153.svg" alt="[公式]"></p><p>但考虑到上述简单的正态分布的例子中尚且存在这样的问题，<strong>有理由认为在GAN中，依靠采样来估计的分布之间的距离并不等于两个分布的真实的距离</strong>。如果生成器接受到的距离信息是有偏差的，则很可能无法将生成器定义的隐式概率分布逼近到数据集的本质概率分布。</p><h2 id="3-minmax问题"><a href="#3-minmax问题" class="headerlink" title="3.minmax问题"></a>3.minmax问题</h2><p>GAN的理想训练模式是这样的：固定生成器G，迭代k次训练判别器D；然后固定判别器D，训练生成器G，两者依次交替使用梯度下降法进行更新。这里会造成一种困惑，我们到底是在解决一个minmax问题还是maxmin问题？而且，通常情况下：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654521104.svg" alt="[公式]"></p><p>在maxmin的角度来看，<strong>GAN的训练过程会产生mode collapse问题，就是指生成器生成的样本有大量的重复，多样性非常差</strong>（这是一个在实践中经常出现的问题，在之后的文章中，我们将花许多精力来介绍mode collapse问题的解决方案）。</p><p>真实数据集的本质概率密度函数通常是多峰函数，也就是具有很多模式(mode)，我们用一个非常简洁、极端的例子来说明一下。假设真实数据集的本质概率密度函数有3个峰。首先，对于固定的判别器D，生成器面临min问题，会努力将概率集值中放置到一个或几个高概率的点(mode)上，例如x=5.0，希望以这种“偷懒”的方式来欺骗判别器D。</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/v2-6318f833259542cc0089d09a13811873_720w.jpg" alt="img" style="zoom:80%;"><p>对判别器进行更新，根据最优判别器的表达式：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654521123.svg" alt="[公式]" style="zoom: 80%;"><p>更新后D(x)为：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/1630654845573.png" alt="1630654845573" style="zoom: 80%;"><p>可以看出，训练后的D会对x=5.0及其周围点的“极其不信任”。接下来再更新生成器时，为了取得最小值，生成器会将概率放置到其他的高概率的、判别器信任的点(mode)上，例如x=0，即：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/v2-70a2dfe00801e1aea42ba44f73a2611b_720w.jpg" alt="img" style="zoom:80%;"><p>再次更新判别器D(x)，其函数图像为：</p><p><img src="https://pic4.zhimg.com/80/v2-0a8d650d974ffc2f522006115df9583b_720w.jpg" alt="img"></p><p>这时判别器识别降低了x=0的信任程度，但是同时又恢复了对x=5.0的信任程度，那么接下来再更新生成器时，生成器其又会将高概率点放置在x=-5.0或者x=5.0的点周围······</p><p><strong>在实践中，我们发现生成器往往不能包涵所有的mode，通常只包含一个或几个mode。在训练过程中，生成器的概率放置不断地从一个mode转换到另一个mode中。</strong></p><h2 id="4-参数空间与函数空间问题"><a href="#4-参数空间与函数空间问题" class="headerlink" title="4.参数空间与函数空间问题"></a>4.参数空间与函数空间问题</h2><p>理论上，GAN确实可以收敛，但是该优化过程是在函数空间中完成的。实践操作中，我们的优化操作是在参数空间中进行的，理论上的保证在现实中并不成立。对于有限个参数的判别器，GAN的平衡状态很可能是不存在的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-梯度消失问题&quot;&gt;&lt;a href=&quot;#1-梯度消失问题&quot; class=&quot;headerlink&quot; title=&quot;1.梯度消失问题&quot;&gt;&lt;/a&gt;1.梯度消失问题&lt;/h2&gt;&lt;p&gt;在早期的GAN中，有一条经验：&lt;strong&gt;不要把判别器训练得太好，以避免后期梯度消失导致</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN训练" scheme="http://example.com/tags/GAN%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读7---IPM与xGAN</title>
    <link href="http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/"/>
    <id>http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/</id>
    <published>2021-09-03T06:19:00.000Z</published>
    <updated>2021-09-04T08:06:24.398Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-IPM（积分概率度量）"><a href="#1-IPM（积分概率度量）" class="headerlink" title="1.IPM（积分概率度量）"></a>1.IPM（积分概率度量）</h2><p> IPM  (integral probability metric)  是一种对于两个概率分布之间的距离的度量。在IPM技术中，首先定义了满足某种限制条件的某一类函数的集合F，然后寻找一个最优的f(x)∈F使得两个分布之间的差异最大，该最大的差异值即为两个分布之间的距离： </p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630650157961.svg" alt="[公式]"></p><p>这里要求 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation.svg" alt="[公式]"> 是可测、有界的实值函数，且函数空间 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630650157951.svg" alt="[公式]"> 是对称的。</p><p>正是由于不同的 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630650157951.svg" alt="[公式]"> ，决定了两种分布之间的各种各样的距离度量以及他们的性质。这点与f-divergence很像，例如在WGAN中：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation.svg" alt="[公式]"> WGAN将判别器函数限定为满足1-Lipschitz条件，则对应了Wasserstein距离：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630650157846.svg" alt="[公式]"></p><p>另外需要说明，这样定义的距离度量虽然满足对称性、非负性、三角不等式，但是当该距离为0时，并不能严格证明两个分布相等，故为一种伪度量。</p><p>在这样的框架下，GAN的判别器(critic)的<strong>先学习某种两个分布之间的距离</strong>，其目标函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630650157973.svg" alt="[公式]"></p><p>接着，优化生成器使得该距离最小：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630650158006.svg" alt="[公式]"></p><h2 id="2-IPM-vs-f-divergence"><a href="#2-IPM-vs-f-divergence" class="headerlink" title="2. IPM vs f-divergence"></a>2. IPM vs f-divergence</h2><p><strong>一般在生成模型中，往往先计算生成模型的概率分布和真实数据集的概率分布之间的距离，再以此距离作为目标函数来训练生成模型。而在GAN的框架中，需要先利用数学技巧将距离转化成可以通过采样来计算的形式，再使用神经网络（也就是判别器）来帮助逼近两个概率分布的距离，最后距离作为目标函数来训练生成模型。</strong></p><p>GAN中的概率分布之间的距离度量大概分为两类，在f-divergence中，通过<strong>选择不同的f(x)来制造不同的GAN</strong>：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630651872059.svg" alt="[公式]"></p><p>在IPM中，通过选择不同的函数空间来制造不同的GAN：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630651872070.svg" alt="[公式]"></p><p>正如之前所说，f-divergence的问题是：随着数据空间维数增加，距离难以计算；由于两个概率分布的支撑集未对齐，会出现无穷值。而IPM定义的距离，数学性质更好，其值并不受数据维度的影响。</p><hr><h2 id="个人对GAN理解："><a href="#个人对GAN理解：" class="headerlink" title="个人对GAN理解："></a>个人对GAN理解：</h2><h4 id="1-GAN有一个生成器一个判别器，判别器的作用是在高维概率密度空间寻找两个概率分布的距离，生成器的作用是生成一种概率分布去逼近真实的概率分布。"><a href="#1-GAN有一个生成器一个判别器，判别器的作用是在高维概率密度空间寻找两个概率分布的距离，生成器的作用是生成一种概率分布去逼近真实的概率分布。" class="headerlink" title="1.GAN有一个生成器一个判别器，判别器的作用是在高维概率密度空间寻找两个概率分布的距离，生成器的作用是生成一种概率分布去逼近真实的概率分布。"></a>1.GAN有一个生成器一个判别器，判别器的作用是在高维概率密度空间寻找两个概率分布的距离，生成器的作用是生成一种概率分布去逼近真实的概率分布。</h4><h4 id="2-虽然图片在高维空间是一个点、但是在比它低一个维度的空是由很多的点组成，而不是单独一个点。例如三维空间一个点对应二维空间是一个平面。"><a href="#2-虽然图片在高维空间是一个点、但是在比它低一个维度的空是由很多的点组成，而不是单独一个点。例如三维空间一个点对应二维空间是一个平面。" class="headerlink" title="2.虽然图片在高维空间是一个点、但是在比它低一个维度的空是由很多的点组成，而不是单独一个点。例如三维空间一个点对应二维空间是一个平面。"></a>2.虽然图片在高维空间是一个点、但是在比它低一个维度的空是由很多的点组成，而不是单独一个点。例如三维空间一个点对应二维空间是一个平面。</h4><h4 id="3-G和D两者，个人觉得D是最重要的核心、D决定了什么类型的距离、什么类型的概率空间。D更新一次、G更新好几次。"><a href="#3-G和D两者，个人觉得D是最重要的核心、D决定了什么类型的距离、什么类型的概率空间。D更新一次、G更新好几次。" class="headerlink" title="3.G和D两者，个人觉得D是最重要的核心、D决定了什么类型的距离、什么类型的概率空间。D更新一次、G更新好几次。"></a>3.G和D两者，个人觉得D是最重要的核心、D决定了什么类型的距离、什么类型的概率空间。D更新一次、G更新好几次。</h4><h4 id="4-D和G并是独立训练的，所以几乎不会生成完全相同的数据分布。"><a href="#4-D和G并是独立训练的，所以几乎不会生成完全相同的数据分布。" class="headerlink" title="4.D和G并是独立训练的，所以几乎不会生成完全相同的数据分布。"></a>4.D和G并是独立训练的，所以几乎不会生成完全相同的数据分布。</h4><p>GAN中的概率分布之间的距离度量大概分为两类，在f-divergence中，通过<strong>选择不同的f(x)来制造不同的GAN</strong>：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630651872059.svg" alt="[公式]"></p><p>在IPM中，通过选择不同的函数空间来制造不同的GAN：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630651872070.svg" alt="[公式]"></p><h2 id="IPM太复杂、、了解即可，具体使用到了再看一遍。"><a href="#IPM太复杂、、了解即可，具体使用到了再看一遍。" class="headerlink" title="IPM太复杂、、了解即可，具体使用到了再看一遍。"></a>IPM太复杂、、了解即可，具体使用到了再看一遍。</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-IPM（积分概率度量）&quot;&gt;&lt;a href=&quot;#1-IPM（积分概率度量）&quot; class=&quot;headerlink&quot; title=&quot;1.IPM（积分概率度量）&quot;&gt;&lt;/a&gt;1.IPM（积分概率度量）&lt;/h2&gt;&lt;p&gt; IPM  (integral probabilit</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读6---奇异值和SNGAN</title>
    <link href="http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/"/>
    <id>http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/</id>
    <published>2021-09-03T03:30:00.000Z</published>
    <updated>2021-09-04T08:06:18.774Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/1630640020039.png" alt="1630640020039"></p><p>在GAN中，<strong>Wasserstein距离比f散度拥有更好的数学性质，它处处连续，几乎处处可导且导数不为0</strong>，所以我们更多的使用Wasserstein距离。在上一期的结尾，我们得到critic（判别器）的目标函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation.svg" alt="[公式]"></p><p><strong>1-Lipschitz限制即要求在任意点，函数的一阶导数在[-1,1]的范围内，这个限制在神经网络中并不容易实现，之后的许多工作便是围绕这点来展开的。</strong></p><p>本篇所讲的SNGAN便是一种“严格”地解决了1-Lipshcitz约束的方法。</p><h2 id="1-Lipshcitz限制"><a href="#1-Lipshcitz限制" class="headerlink" title="1.Lipshcitz限制"></a>1.Lipshcitz限制</h2><p>所谓Lipshcitz限制，在最简单的一元函数中，即</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630647493192.svg" alt="[公式]"></p><p>或者也可以写成</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630647493206.svg" alt="[公式]"></p><p>直观上看，它要求任意两点之间连线的“斜率”绝对值小于Lipshcitz常数k。在WGAN中要求k=1，1-Lipshcitz限制要求对于f(x)，输入的微小变化不会导致输出产生较大变化。我们常见的函数，比如|x|，sin(x)都显而易见的满足该限制：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/1630647515431.png" alt="1630647515431" style="zoom:80%;"><p>我们以一个最简单的例子来展示一下，如何使用谱范数施加1-Lipshcitz限制。考虑f(x)=Wx，其中</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630647493082.svg" alt="[公式]" style="zoom: 80%;"><p>显然，f(x)=Wx不满足1-Lipshcitz限制，考虑到</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630647493078.svg" alt="[公式]" style="zoom: 80%;"><p>那么若将W整体缩小4倍，</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630647493187.svg" alt="[公式]" style="zoom: 80%;"><p>即可以得到：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630647493200.svg" alt="[公式]" style="zoom: 80%;"><p>可以看出，虽然线性函数f(x)=Wx不满足1-Lipshcitz限制，但是使用谱范数处理后的f*(x)可以满足1-Lipshcitz限制。接下来，我们将对这条思路进行补充、推广，最后得到SNGAN将是显而易见的事情了。</p><h2 id="2-SNGAN"><a href="#2-SNGAN" class="headerlink" title="2. SNGAN"></a>2. SNGAN</h2><p>通常在神经网络中的每一层，先进行输入乘权重的线性运算，再将其送入激活函数，由于通常选用ReLU作为激活函数，因此，一般而言，即使神经网络的输出是非线性的，但是在x的一个足够小的邻域内，它一个表现为线性函数Wx，W的具体形式与x有关。真实的判别器f(x)的函数图像应该是类似这种：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/1630648071657.png" alt="1630648071657" style="zoom: 67%;"><p>考虑到对于任意给定的x，均有</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648046563.svg" alt="[公式]"></p><p>ReLu激活函数可以用对角方阵D表示，如果Wx的第i维大于0，则D的第i个对角元素为1，否则为0，需要注意D的具体形式与W,x均有关系，但是D的最大奇异值必然是1。</p><p>整体标记各层的权值、偏置项：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648046578.svg" alt="[公式]"></p><p>那么可以得到</p><p><img src="https://www.zhihu.com/equation?tex=W_%7B%5CTheta,x%7D=D_%7B%5CTheta,x%7D%5E%7BL%7DW_x%5E%7BL%7DD_%7B%5CTheta,x%7D%5E%7BL-1%7DW_x%5E%7BL-1%7D%C2%B7%C2%B7%C2%B7D_%7B%5CTheta,x%7D%5E%7B1%7DW_x%5E%7B1%7D%5C%5C" alt="[公式]"></p><p>根据：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648046583.svg" alt="[公式]"></p><p>可得到：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Csigma(W_%7B%5CTheta,x%7D)+&%5Cle%5Csigma(D_%7B%5CTheta,x%7D%5E%7BL%7D)%5Csigma(W_x%5E%7BL%7D)%5Csigma(D_%7B%5CTheta,x%7D%5E%7BL-1%7D)%5Csigma(W_x%5E%7BL-1%7D)%C2%B7%C2%B7%C2%B7%5Csigma(D_%7B%5CTheta,x%7D%5E%7B1%7D)%5Csigma(W%5E%7B1%7D_x)%5C%5C+&%5Cle+%5Cprod_%7Bl=1%7D%5E%7BL%7D%5Csigma(W%5El_x)+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"></p><p>不必像第二部分所描述办法整体求解W的谱范数，充分利用上述不等式，我们<strong>只需要计算每层的权值矩阵的最大奇异值，即可完成1-Lipshcitz限制。</strong></p><p>对于每层的权值矩阵，处理为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648046559.svg" alt="[公式]"></p><p>则会有结果：对于任意x，</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Ccfrac%7B%5Cparallel+f_%7B%7D(x+%5Cdelta)-f_%7B%7D(x)%5Cparallel_2%7D%7B%5Cparallel+%5Cdelta+%5Cparallel+_2%7D+&=%5Ccfrac%7B%5Cparallel+%5Chat%7BW%7D_%7Bx%7D%5Cdelta+%5Cparallel_2%7D%7B%5Cparallel+%5Cdelta+%5Cparallel+_2%7D%5C%5C+&%5Cle+%5Csigma(%5Chat%7BW%7D_%7Bx%7D)%5C%5C+&%5Cle+%5Ccfrac%7B%5Csigma(D_%7B%5CTheta,x%7D%5E%7BL%7D)%5Csigma(W_x%5E%7BL%7D)%5Csigma(D_%7B%5CTheta,x%7D%5E%7BL-1%7D)%5Csigma(W_x%5E%7BL-1%7D)%C2%B7%C2%B7%C2%B7%5Csigma(D_%7B%5CTheta,x%7D%5E%7B1%7D)%5Csigma(W_x%5E%7B1%7D)%7D%7B%5Csigma(W_x%5E%7BL%7D)%5Csigma(W_x%5E%7BL-1%7D)%C2%B7%C2%B7%C2%B7%5Csigma(W_x%5E%7B1%7D)%7D%5C%5C+&%5Cle+1+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"></p><p>为了严格起见，需要说明，<strong>f(x)在x的任意邻域内都满足1-Lipshcitz限制，则f(x)在定义域上满足1-Lipshcitz限制</strong>。</p><p>这里通过对真正的解决判别器f(x)的1-Lipshcitz限制问题，方法非常朴素且巧妙。</p><h2 id="个人理解："><a href="#个人理解：" class="headerlink" title="个人理解："></a>个人理解：</h2><p>首先需要计算出来每一层权值矩阵的最大特征值、然后用该层的权值矩阵去除以这个数，把整体缩小k倍，</p><p>这样特征值就会小于等于1，所有特征值乘起来肯定也是小于等于 1的。这样就满足了1-Lipshcitz限制。</p><h2 id="扩展：-谱归一化（SPECTRAL-NORMALIZATION）"><a href="#扩展：-谱归一化（SPECTRAL-NORMALIZATION）" class="headerlink" title="扩展： 谱归一化（SPECTRAL NORMALIZATION）"></a>扩展： 谱归一化（SPECTRAL NORMALIZATION）</h2><p> 谱归一化约束，通过约束 GAN 的 Discriminator 的每一层网络的权重矩阵(weight matrix)的谱范数来约束 Discriminator 的 Lipschitz 常数， 从而增强 GAN 在训练过程中的稳定性。 </p><p>我们知道向量的<code>1-范数</code>、<code>2-范数</code>等等，<code>1-范数</code>表示向量元素绝对值之和，<code>2-范数</code>表示向量元素绝对值的平方和再开方。 扩展开来，<strong>向量的<code>p-范数</code>表示的意思是向量所有元素绝对值的<code>p</code>次方和的<code>1/p</code>次幂。</strong><br>了解了向量的范数的概念，其实矩阵的范数就是在向量的基础上推广开来而已，不过因为矩阵多了一维，所以定义看起来复杂了一些。<br>矩阵的<code>1-范数</code>，则是列和范数，即矩阵的所有列向量绝对值之和的最大值，矩阵的<code>2-范数</code>，是<code>A*A</code><strong>矩阵的最大特征值的开平方</strong>，即：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715529.svg" alt="[公式]"></p><p>式中， <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715545.svg" alt="[公式]"> 为 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715524.svg" alt="[公式]"> 的特征值的绝对值的最大值。<br>其实，矩阵的诱导<code>p-范数</code>也可以类似向量的<code>p-范数</code>推广开来：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715524.svg" alt="[公式]"></p><p>那么，啥又是矩阵的谱范数？<br>就是矩阵的<code>2-范数</code>！<strong>。其值为矩阵<code>A</code>的最大的奇异值或者半正定矩阵<code>A*A</code>的最大特征值的平方根</strong>。</p><p>好了，解释完了矩阵的谱范数的概念，我们继续说谱归一化。</p><p>对于网络的一个layer： <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715552.svg" alt="[公式]"> ，从定义上来说，其<code>Lipscchitz norm</code> <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715568.svg" alt="[公式]"> <em>的值等于</em> <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715577.svg" alt="[公式]"> <em>，其中</em> <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715559.svg" alt="[公式]"> <em>即指矩阵<code>A</code>的谱范数。</em><br><em>那么，</em> <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715459.svg" alt="[公式]"> ， 则根据Lipschitz 定义的不等式，有：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cleft+%5C%7Cf++%5Cright+%5C%7C%7BLip%7D+%E2%89%A4%5Cleft+%5C%7C+(h_L+%E2%86%92+W%5E%7BL+1%7Dh_L)%5Cright+%5C%7C%7BLip%7D%C2%B7+%5Cleft+%5C%7Ca_L%5Cright+%5C%7C%7BLip%7D++%C2%B7+%5Cleft+%5C%7C+(h%7BL-1%7D+%E2%86%92+W%5E%7BL%7Dh_%7BL-1%7D)%5Cright+%5C%7C%7BLip%7D...+%5Cleft+%5C%7Ca_1%5Cright+%5C%7C%7BLip%7D%C2%B7++%5Cleft+%5C%7C+(h_%7B0%7D+%E2%86%92+W%5E%7B1%7Dh_%7B0%7D)%5Cright+%5C%7C_%7BLip%7D" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=++++%E3%80%80%E3%80%80+=%5Cprod_%7Bl=1%7D%5E%7BL+1%7D%5Cleft+%5C%7C(h_%7Bl%E2%88%921%7D%E2%86%92+W%5Elh_%7Bl%E2%88%921%7D)+%5Cright+%5C%7C%7BLip%7D++=%5Cprod_%7Bl=1%7D%5E%7BL+1%7D%5Csigma+(W%5El)" alt="[公式]"></p><p>于是，当约束权重矩阵 <code>W</code>使其<code>LIpschitz constraint</code> <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715583.svg" alt="[公式]"> ，则有：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715571.svg" alt="[公式]"></p><p>那么，当我们这样约束的时候，带入上一个不等式，便可得到 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715588.svg" alt="[公式]"> <code>is bounded from above by 1</code>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/1630640020039.png&quot; alt=&quot;1630640020039&quot;&gt;&lt;/p&gt;
&lt;p&gt;在GAN中，&lt;str</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读3---度量和fGAN</title>
    <link href="http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/"/>
    <id>http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/</id>
    <published>2021-09-02T09:10:00.000Z</published>
    <updated>2021-09-04T08:06:12.443Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-分布间的距离"><a href="#1-分布间的距离" class="headerlink" title="1.分布间的距离"></a>1.分布间的距离</h2><p>最初提出的GAN是基于博弈论角度的，它包括一个判别器和一个生成器，判别器会给出输入的样本来源于训练集的概率，而生成器会努力产生可以欺骗判别器的样本。整个GAN的流程稍微复杂却非常具象，甚至可以将其拟人化来理解。其实，更一般地，我们应该从样本概率分布的角度去理解GAN，从这里入手虽然略微抽象，但是能触碰到GAN的本质。</p><p>GAN的生成器隐式地<strong>定义了一个概率分布，并依此概率分布来生成样本</strong>，而训练样本集也是在某一个概率分布上连续独立采样获得的，故GAN的目标就是：<strong>驱使生成器定义的隐式的概率分布接近训练样本集的本质概率分布。</strong></p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/1630574460321.png" alt="1630574460321" style="zoom:80%;"><p> 不同的概率密度函数之间距离有“远近之分”，如下图中黄色分布和蓝色分布的距离比较近，而红色分布和蓝色分布的距离比较远，我们需要定义度量函数来量化分布之间的距离（将两个概率密度函数映射为一个实数）。 </p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/1630574717452.png" alt="1630574717452" style="zoom:67%;"><p> <strong>在向量空间中，将每一个向量视为一个元素，存在许多种两个元素间距离的度量方式</strong>，比如闵科夫斯基距离、欧式距离、曼哈顿距离、切比雪夫距离等。<strong>类似的，将每一个概率分布视为概率密度函数空间中的一个元素，则可以定义元素之间的距离</strong>。需要注意定义的距离需要满足<strong>非负性、对称性、三角不等式</strong>。 </p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/1630578559510.png" alt="1630578559510" style="zoom:80%;"><h2 id="2-f-divergence"><a href="#2-f-divergence" class="headerlink" title="2.f-divergence"></a><strong>2.f-divergence</strong></h2><p>f-divergence则提供了一套“距离”，对于数据集的本质概率分布和生成器隐式的概率分布，我们用以下公式来定义它们的距离：</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630578582159.svg" alt="[公式]"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630578582181.svg" alt="[公式]"></p><p>其中要求，<strong>f(u)为凸函数，且f(1)=0。f(1)=0保证了当两个分布完全重合时，f散度为0</strong>。<strong>f(u)为凸函数保证了f-divergence的值非负</strong>。我们用Jensen不等式来简单证明一下：</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation.svg" alt="[公式]" style="zoom:80%;"><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630578582210.svg" alt="[公式]" style="zoom:80%;"><p>f散度中f(u)的具体形式如下图所示：</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/v2-7eb64e734be348f3b452bd6e4d5fac3e_720w.jpg" alt="img" style="zoom: 58%;"><h2 id="3-共轭函数"><a href="#3-共轭函数" class="headerlink" title="3.共轭函数"></a>3.共轭函数</h2><p>即使知道了f散度的一般表达式，我们也无法精确计算其值。</p><p>我们利用共轭函数将f散度转变成可以计算的形式。<strong>共轭（或对偶）通常指成对出现的两个具有很强关系的实体，它们具有相同的结构和意义</strong>。<strong>无论原函数是否是凸函数，其共轭函数必为凸函数</strong>（凸函数在做优化时拥有非常好的数学性质）。</p><p>定义共轭函数为</p><p><img src="https://www.zhihu.com/equation?tex=f(u)=%5Cmax_%7Bt%5Cin+f%27(D)%7D%5C%7Btu-g(t)%5C%7D%5C%5C" alt="[公式]"> </p><p> t的定义域为f(u)的一阶导数的值域。即对于任意给定的u，要遍历所有可能的t代入计算，然后寻找最大值。 </p><p>此时f散度可转化为</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+D_f(p_%7Bdata%7D%5Cparallel+p_g)&=%5Cint_x+p_g(x)f(%5Cfrac%7Bp_%7Bdata%7D(x)%7D%7Bp_g(x)%7D)dx%5C%5C+&=%5Cint_x+p_g(x)%5B%5Cmax_%7Bt%5Cin+f%27(D)%7D%5C%7Bt%5Cfrac%7Bp_%7Bdata%7D(x)%7D%7Bp_g(x)%7D-g(t)%5C%7D%5Ddx%5C%5C+&=%5Cint_x%5Cmax_%7Bt%5Cin+f%27(D)%7D%5Btp_%7Bdata%7D(x)-g(t)p_g(x)%5Ddx%5C%5C+&%5Cgeq%5Cmax_%7Bt%5Cin+f%27(D)%7D%5Cint_x%5Btp_%7Bdata%7D(x)-g(t)p_g(x)%5Ddx%5C%5C+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"></p><p> t和u具有非常复杂的数学解析关系，则t和x也具有非常复杂的数学解析关系，即使用共轭函数给出了f散度的一个下界，依然无法写成解析式而利用蒙特卡洛方法求解。利用神经网络强大的函数拟合能力，可以构造一个神经网络来拟合t和x的复杂函数关系，即 <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630579742308.svg" alt="[公式]"> ，这里要注意通过设置最后一层的激活函数以保证神经网络的输出在f(u)的一阶导数的值域中。 </p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+&%5Cmax_%7Bt%5Cin+f%27(D)%7D%5Cint_x%5Btp_%7Bdata%7D(x)-g(t)p_g(x)%5Ddx%5C%5C+=&%5Cmax_%7B%5Ctheta%7D%5Cint_xp_%7Bdata%7D(x)T_%7B%5Ctheta%7D(x)-p_g(x)g(T_%7B%5Ctheta%7D(x))dx%5C%5C+=&%5Cmax_%7B%5Ctheta%7D%5Cmathbb%7BE%7D_%7Bx%5Csim+p_%7Bdata%7D%7D%5BT_%7B%5Ctheta%7D(x)%5D-%5Cmathbb%7BE%7D_%7Bx%5Csim+p_g%7D%5Bg(T_%7B%5Ctheta%7D(x))%5D+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"> </p><p>所以，对于这个神经网络T，我们应该以</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630579839033.svg" alt="[公式]"></p><p>为目标函数通过采样的方式进行训练，将求极值的问题转化成训练神经网络的问题，理论上，经过完美的训练，上述目标函数即转化成了f散度。所以在fGAN的框架下来看，训练判别器本质上是为了逼近一个f散度，然后利用f散度去指示生成器的学习。从现在开始，判别器已经不再像最原始的GAN拥有具象的意义了。</p> <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/v2-f9310de8170c172ddcc336725f64f5b0_720w.jpg" alt="img" style="zoom:80%;"> <h2 id="4-几个小问题"><a href="#4-几个小问题" class="headerlink" title="4.几个小问题"></a>4.几个小问题</h2><p>KL散度和逆KL散度在严格意义上并不是一种度量，因为不符合对称性，即</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630581634007.svg" alt="[公式]"></p><p>非对称性意味着使用KL散度或者逆KL散度作为优化目标，其得到结果将具有显著差异。例如，用分布Q去拟合分布P，选择KL散度，Q会将诸多高概率的峰模糊化，</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/1630581689827.png" alt="1630581689827" style="zoom: 50%;"><p>如若使用逆KL散度，则会导致Q去拟合高概率的单峰。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/1630581711341.png" alt="1630581711341" style="zoom:50%;"><p>另一个需要解释的问题，为什么JS散度效果不好。因为训练集的概率分布和生成器隐式定义的概率分布往往只是高维空间的低维流形，例如在三维空间中，两个分布均是二维流形，其交集最多为一条直线，以至于在计算JS散度时可以忽略。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/1630581740276.png" alt="1630581740276" style="zoom:50%;"><p>即对于任意x，在绝大部分情况下，两个概率分布至少有一个为0。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630581634060.svg" alt="[公式]" style="zoom: 67%;"><p>显然，这样计算得来的JS散度为常数。所以如果将判别器训练的太好（即学习到了JS散度）但JS散度为一个常数，无法提供任何梯度信息供生成器训练，就是大家常说的“学不动”。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-分布间的距离&quot;&gt;&lt;a href=&quot;#1-分布间的距离&quot; class=&quot;headerlink&quot; title=&quot;1.分布间的距离&quot;&gt;&lt;/a&gt;1.分布间的距离&lt;/h2&gt;&lt;p&gt;最初提出的GAN是基于博弈论角度的，它包括一个判别器和一个生成器，判别器会给出输入的样本来源</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读3---对偶与WGAN</title>
    <link href="http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/"/>
    <id>http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/</id>
    <published>2021-09-02T09:10:00.000Z</published>
    <updated>2021-09-04T08:06:15.324Z</updated>
    
    <content type="html"><![CDATA[<p> 说到对GAN的理解，我们不能简单停留在“生成器产生样本，判别器分辨样本真假”的阶段了，在经过上一篇文章后，对GAN的理解应该是：先学习一个关于生成器定义的隐式概率分布和训练数据集的本质概率分布之间的距离度量，然后优化生成器来缩减这个距离度量。今天的主要内容依旧围绕这个距离度量来展开。 </p><h2 id="1-度量连续性的问题"><a href="#1-度量连续性的问题" class="headerlink" title="1.度量连续性的问题"></a>1.度量连续性的问题</h2><p>在第二篇文章的最后，我们简要讨论了f散度的问题。实际中，生成器定义的隐式概率分布和训练数据集的本质概率分布几乎不存在重叠部分，而且随着数据维度增加，这个趋势会更加严重，那么采样计算得来的f散度距离不仅不连续，而且几乎处处导数为0。</p><p>用一个非常简单的例子来解释一下，在二维空间有两个无任何重合的均匀分布，其中</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation.svg" alt="[公式]"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630584299151.svg" alt="[公式]"></p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/1630584313712.png" alt="1630584313712" style="zoom:50%;"><p>计算一下两个分布的KL散度，JS散度</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630584430067.svg" alt="[公式]" style="zoom:70%;"><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630584430074.svg" alt="[公式]" style="zoom:70%;"><p>可以看出，当P和Q没有重合或者重合部分可忽略时，其f散度值为常数；当两者完全重合时，f散度值为0，即f散度无法为生成器提供可以减少损失函数的梯度信息，生成器无法训练获得优化方向。</p><p>对于此问题的一种解决方案是：通过对数据集中的样本和生成器生成的样本增加噪声，使得原本的两个低维概率分布“弥散”到整个高维空间，强行让它们产生不可忽略的重叠，此时的f散度便能“指示”出两个分布的距离。在训练过程中，我们可以先添加方差比较大的噪声，以尽可能使两个分布产生较大重叠部分，随着两个分布距离的拉近，可以逐渐降低噪声的方差，直至最后可以去掉噪声完全靠JS散度来指示生成器的学习。</p><p>但是为了本质地解决问题，我们需要寻找一种更合理的距离度量。直观上，该距离最好处处连续，在两个分布不重合的位置处处可导且导数不为0。</p><h2 id="2-Wasserstein距离"><a href="#2-Wasserstein距离" class="headerlink" title="2.Wasserstein距离"></a>2.Wasserstein距离</h2><p>Wasserstein距离是一个数学性质非常良好距离度量，数学形式稍微有点复杂。我们用一个小例子来引入，定义两个离散概率分布P和Q，其随机变量取值只能为1,2,3,4。如何对P调整使其等于Q？</p><img src="https://pic4.zhimg.com/80/v2-5845beb5f4231be76408b23ef9228c0b_720w.jpg" alt="img" style="zoom:67%;"> <p>其实是很简单的一个问题，我们逐位置来分解计算，</p><ol><li> 对于P的1位置，其值为0.25，我们将这0.25保持在1位置 </li><li> 对于P的2位置，其值为0.25，我们也将这0.25保持在2位置 </li><li> 对于P的3位置，其值为0.5，我们将其中的0.25放置到1位置，将0.25放置到2位置</li><li> P的4位置为0，不用做任何分解和移动 </li></ol><p>即可有如下分解矩阵</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/1630585750932.png" alt="1630585750932" style="zoom:67%;"><p> 然后，我们再考虑关于路程的移动耗费问题。如果定义从1位置到2位置路程为1，从1位置到3位置路程为2……对P的1位置，将0.25保留在1位置不产生耗费，对P的2位置，将0.25保留在2位置不产生耗费，但是将对P的3位置，将0.25移动到1位置，需要耗费：0.25*(3-1)=0.5；将0.25移动到2位置，需要耗费：0.25*(2-1)=0.25，故整个方案将产生0.75的耗费。当然，我们也可以有其他方案，例如： </p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/1630586082108.png" alt="1630586082108" style="zoom: 67%;"><p> 可以证明的是总存在一个耗费最小的方案。Wasserstein距离便是选择某一种最小消耗方案对应的总消耗值。 </p><h3 id="在数学形式上，"><a href="#在数学形式上，" class="headerlink" title="在数学形式上，"></a><strong>在数学形式上，</strong></h3><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377332.svg" alt="[公式]"></p><p>其中， <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377295.svg" alt="[公式]"> 是两个分布构成全部可能的联合分布的集合。而 <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377265.svg" alt="[公式]"></p><p>是该集合中的一个联合分布，且该联合分布要求</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377308.svg" alt="[公式]"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377310.svg" alt="[公式]"></p><p>简而言之就是， <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377265.svg" alt="[公式]"> 定义一个传输方案， <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377285.svg" alt="[公式]"> 定义了路程函数（ <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377185.svg" alt="[公式]"> 的每个位置传输到 <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377342.svg" alt="[公式]"> 每个位置的传输路程），求双重积分计算总传输耗费值，最后在所有这些方案中取最小耗费值的传输方案，其对应的总耗费值即为距离。</p><p>在WGAN中，</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377216.svg" alt="[公式]"></p><p>当然也可以定义2-Wasserstein距离：</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377282.svg" alt="[公式]"></p><p>或者k-Wasserstein距离：</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377344.svg" alt="[公式]"></p><p>针对于刚开始提出的小例子，我们用Wasserstein则可得到：</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377223.svg" alt="[公式]"></p><p>可以看出Wasserstein距离处处连续，而且几乎处处可导，数学性质非常好，能够在两个分布没有重叠部分的时候，依旧给出合理的距离度量。</p><h2 id="3-对偶问题"><a href="#3-对偶问题" class="headerlink" title="3.对偶问题"></a>3.对偶问题</h2><p>如果要计算Wasserstein距离，那需要遍历所有满足条件的联合概率分布，然后计算每个联合概率分布下的总消耗值，最后取最小的总消耗值，在维度较高时，该问题几乎不可解决。与之前fGAN有点类似，当一个优化问题难以求解时，可以考虑将其转化为比较容易求解的对偶问题。关于对偶理论，其最早源于求解线性规划问题，每个线性规划问题都有一个与之对应的对偶问题，对偶问题是以原问题的约束条件和目标函数为基础构造而来的，对偶问题也是一个线性规划问题，且当求解成功对偶问题时，其原问题也自然解决。</p><p> 我们先将Wasserstein距离表示成线性规划的形式，定义向量： </p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/1630587362224.png" alt="1630587362224" style="zoom:80%;"><p> 定义向量： </p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/1630587382579.png" alt="1630587382579" style="zoom:80%;"><h2 id="后面没看懂…………………不过自己的理解如下"><a href="#后面没看懂…………………不过自己的理解如下" class="headerlink" title="后面没看懂…………………不过自己的理解如下"></a>后面没看懂…………………不过自己的理解如下</h2><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/1630587880480.png" alt="1630587880480"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 说到对GAN的理解，我们不能简单停留在“生成器产生样本，判别器分辨样本真假”的阶段了，在经过上一篇文章后，对GAN的理解应该是：先学习一个关于生成器定义的隐式概率分布和训练数据集的本质概率分布之间的距离度量，然后优化生成器来缩减这个距离度量。今天的主要内容依旧围绕这个距离</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读3---生成模型和GAN</title>
    <link href="http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/"/>
    <id>http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/</id>
    <published>2021-09-02T07:30:00.000Z</published>
    <updated>2021-09-04T08:06:08.923Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-生成模型"><a href="#1-生成模型" class="headerlink" title="1 生成模型"></a><strong>1 生成模型</strong></h2><p>在机器学习或者深度学习领域，生成模型具有非常广泛的应用，它可以用于测试模型的高维概率分布的表达能力，可以用于强化学习、半监督学习，可以用于处理多模输出问题，以及最常见的产生“真实”数据问题。</p><p><strong>简单而言，有监督学习与无监督学习的区别之处在于是否存在标签信息。</strong>在有监督学习生成方法中，我们学得联合概率分布P(X,Y)，然后求出生成模型P(Y|X)，其重点在于学习联合分布。例如，在朴素贝叶斯方法中，我们通过数据集学习到先验概率分布P(Y)和条件概率分布P(X|Y)，即可得到联合概率分布P(X,Y)；在隐马尔可夫模型中，我们通过数据集学习到初始概率分布、状态转移概率矩阵和观测概率矩阵，即得到了一个可以表示状态序列和观测序列的联合分布的马尔可夫模型。<strong>而在GAN、VAE等无监督生成模型中，只存在关于X的数据集，我们的目标或者近似得到P(X)的概率密度函数，或者直接产生符合X本质分布的样本。</strong></p><h2 id="2-极大似然估计"><a href="#2-极大似然估计" class="headerlink" title="2 极大似然估计"></a><strong>2 极大似然估计</strong></h2><p>我们从最简单的生成模型开始说起。考虑这样一个问题，依概率P(X)在X中独立采样n次构建一个包含n样本的数据集，如何根据这个数据集来求得X的概率密度函数P(X)。其实这个问题并不容易解决，可是如果再额外提供一些关于X的先验知识，比如X服从正态分布，那这个问题便可以使用极大似然法轻松搞定。</p><p>如若X服从正态分布，则概率密度函数P(X)的表达式形式已知，只需要再确定均值、方差两个参数值便可以得到P(X)。接下来便是计算数据集的似然函数，对似然函数取负对数，然后最小化即可，即</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/equation.svg" alt="[公式]"> </p><p>其实，对随机变量X的概率密度函数的建模源于先验知识，极大似然估计只是一个参数估计的方法。容易证明，<strong>极大似然法本质上是在最小化数据集的经验性分布和模型分布之间的KL散度</strong>，而且当具备某些条件时，参数的极大似然估计值会趋近于真实值。</p><h2 id="3-GAN-—-具体可看周总结9-8"><a href="#3-GAN-—-具体可看周总结9-8" class="headerlink" title="3 GAN —-具体可看周总结9.8"></a><strong>3 GAN</strong> —-具体可看周总结9.8</h2><p>全程没有任何显式地出现过概率密度函数，直接做一个end-to-end的模型。g(z)的本质是一个参数化计算过程，它能很好地学习到z排布情况以及从z到x的映射。我们所做的就是根据训练数据来推断参数，然后选择合适的g，其代表便是GAN。 </p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/1630573743479.png" alt="1630573743479"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/1630573759342.png" alt="1630573759342"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/1630573767836.png" alt="1630573767836"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/1630573808796.png" alt="1630573808796"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/1630573844467.png" alt="1630573844467"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-生成模型&quot;&gt;&lt;a href=&quot;#1-生成模型&quot; class=&quot;headerlink&quot; title=&quot;1 生成模型&quot;&gt;&lt;/a&gt;&lt;strong&gt;1 生成模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在机器学习或者深度学习领域，生成模型具有非常广泛的应用，它可以用于测试模型</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读1---GAN原理</title>
    <link href="http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/"/>
    <id>http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/</id>
    <published>2021-09-02T04:10:00.000Z</published>
    <updated>2021-09-04T08:05:54.915Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-生成器判别器比较："><a href="#1-生成器判别器比较：" class="headerlink" title="1.生成器判别器比较："></a>1.生成器判别器比较：</h2><p>判别式模型 ，优点是分类边界灵活 ，学习简单，性能较好；缺点是不能得到概率分布 。<br>生成式模型 ，优点是收敛速度快，可学习分布，可应对隐变量 ；缺点是学习复杂 ，分类性能较差。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/1630555982895.png" alt="1630555982895" style="zoom:67%;"><p> 上面是一个分类例子，可知判别式模型，有清晰的分界面，而生成式模型，有清晰的概率密度分布。生成式模型，可以转换为判别式模型，反之则不能。 </p><h2 id="2-判别器优化目标与求解"><a href="#2-判别器优化目标与求解" class="headerlink" title="2.判别器优化目标与求解"></a>2.判别器优化目标与求解</h2><p>下面是它的优化目标。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/1630556912745.png" alt="1630556912745" style="zoom:67%;"><p>D是判别器，它的学习目标，是最大化上面的式子，而G是生成器，它的学习目标，是最小化上面的式子。上面问题的求解，通过迭代求解D和G来完成。<br>要求解上面的式子，等价于求解下面的式子。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-8cd69f7686525dabfef9dcfc70e70f24_720w.jpg" alt="img" style="zoom: 80%;"><p>其中D(x)属于(0,1)，上式是alog(y) + blog(1−y)的形式，取得最大值的条件是D(x)=a/(a+b)，此时等价于下面式子。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-d1c432ebece6171fcbc44a409e60e5a1_720w.jpg" alt="img" style="zoom:75%;"><p>如果用KL散度来描述，上面的式子等于下面的式子。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/1630556947010.png" alt="1630556947010" style="zoom:67%;">当且仅当pdata(x)=pg(x)时，取得极小值-log4，此时d=0.5，无法分辨真实样本和假样本。<p>GAN从理论上，被证实存在全局最优解。</p><h2 id="3-JS散度和KL散度理解"><a href="#3-JS散度和KL散度理解" class="headerlink" title="3. JS散度和KL散度理解"></a>3. JS散度和KL散度理解</h2><h4 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h4><ul><li>用来衡量两个分布之间的差异，等于一个交叉熵减去一个信息熵（交叉熵损失函数的由来）<img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/20200501153718560.png" alt="在这里插入图片描述" style="zoom:80%;"></li></ul><p> 请问KL散度的不对称性在训练中会产生的问题 ： 如果两个分布没有重叠部分，KL散度直接为∞，这样就一旦没有重叠的话就无法判断两个分布的距离 </p><h4 id="JS-Jenson’s-Shannon-散度"><a href="#JS-Jenson’s-Shannon-散度" class="headerlink" title="JS(Jenson’s Shannon)散度"></a>JS(Jenson’s Shannon)散度</h4><p>一般地，JS散度是对称的，其取值是 0 到 1 之间。如果两个分布 P,Q 离得很远，完全没有重叠的时候，那么KL散度值是没有意义的，而JS散度值是一个常数。这在学习算法中是比较致命的，这就意味这这一点的梯度为 0。梯度消失了。</p><p> <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/20200501154128640.png" alt="在这里插入图片描述"> </p><p> <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/20200501154147675.png" alt="在这里插入图片描述"><br><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/2020050115420360.png" alt="在这里插入图片描述"> </p><h2 id="为什么会出现两个分布没有重叠的现象"><a href="#为什么会出现两个分布没有重叠的现象" class="headerlink" title="为什么会出现两个分布没有重叠的现象"></a>为什么会出现两个分布没有重叠的现象</h2><p> <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/2020050115431689.png" alt="在这里插入图片描述"> </p><h2 id="GAN的主要问题"><a href="#GAN的主要问题" class="headerlink" title="GAN的主要问题"></a>GAN的主要问题</h2><p>​       GAN的训练是依次迭代D和G，如果判别器D学的不好，生成器G得不到正确反馈，就无法稳定学习。如果判别器D学的太好，整个loss迅速下降，G就无法继续学习。</p><p>​       GAN的优化需要生成器和判别器达到纳什均衡，但是因为判别器D和生成器G是分别训练的，纳什平衡并不一定能达到，这是早期GAN难以训练的主要原因。</p><h2 id="风格迁移"><a href="#风格迁移" class="headerlink" title="风格迁移"></a>风格迁移</h2><p> 【20】Isola P, Zhu J Y, Zhou T, et al. Image-to-Image Translation with Conditional Adversarial Networks[J]. 2016:5967-5976. </p><p>实现了像素级别的风格转换，它的关键是<strong>提供了两个域中有相同数据的成对训练样本</strong>，本质上，是一个CGAN。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-6d616d7f501b73ddc31afd4d97c80719_720w.jpg" alt="img"></p><p>【 21】Zhu J Y, Park T, Isola P, et al. Unpaired image-to-image translation using cycle-consistent adversarial networks[J]. arXiv preprint, 2017.<br>【22】Yi Z, Zhang H, Tan P, et al. Dualgan: Unsupervised dual learning for image-to-image translation[J]. arXiv preprint, 2017. </p><p>cycle-gan/dual-gan则更胜一筹，<strong>不需要配对的数据集，可以实现源域和目标域的相互转换。</strong></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-28658b2356813059fdb271f07ff0ecaa_720w.jpg" alt="img"></p><p> 【23】Chang H, Lu J, Yu F, et al. Pairedcyclegan: Asymmetric style transfer for applying and removing makeup[C]//2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2018. </p><p>pairedcycle    将源域和目标域的相互转换用到化妆和去妆，很有趣的应用。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-c5d1d348e16f78e0db1b2f267476f01b_720w.jpg" alt="img"></p><p> 【24】Wei L, Zhang S, Gao W, et al. Person Transfer GAN to Bridge Domain Gap for Person Re-Identification[J]. arXiv preprint arXiv:1711.08565, 2017. </p><p>学习了一个数据集到另一个数据集的迁移，可以用于迁移学习，如实现漫画风格。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-d751021c8d244e7ee35537164cb875d0_720w.jpg" alt="img"></p><p> 【28】Chen Y, Lai Y K, Liu Y J. CartoonGAN: Generative Adversarial Networks for Photo Cartoonization[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 9465-9474. </p><p>【28】实现了卡通风格的转换。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-2b34fc469389b4271e1eafb742b7c8ff_720w.jpg" alt="img"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-生成器判别器比较：&quot;&gt;&lt;a href=&quot;#1-生成器判别器比较：&quot; class=&quot;headerlink&quot; title=&quot;1.生成器判别器比较：&quot;&gt;&lt;/a&gt;1.生成器判别器比较：&lt;/h2&gt;&lt;p&gt;判别式模型 ，优点是分类边界灵活 ，学习简单，性能较好；缺点是不能得</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读2---GAN五个基本结构</title>
    <link href="http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/"/>
    <id>http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/</id>
    <published>2021-09-02T04:10:00.000Z</published>
    <updated>2021-09-04T08:06:05.383Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-单判别器单生成器"><a href="#1-单判别器单生成器" class="headerlink" title="1.单判别器单生成器"></a>1.单判别器单生成器</h2><p>个基本的用于生成图像的GAN的结构就是这样的。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-7876af8591afba7209c84f4dffef9019_720w.jpg" alt="img"></p><p>Generator就是生成器，它输入噪声，输出产生的图像。通常噪声就是一个一维的向量，经过reshape为二维图像，然后利用若干个反卷积层来学习上采样。</p><p>如全卷积的DCGAN模型[1]，输入就是1<em>100的向量，然后经过一个全连接层学习，reshape到4</em>4<em>1024的张量，再经过4个上采样的反卷积网络，生成64</em>64的图。</p><p>Discrimator就是普通的CNN分类器，输入真实样本或者生成的假样本进行分类，在DCGAN中也是4个卷积层。</p><h2 id="2-多判别器单生成器"><a href="#2-多判别器单生成器" class="headerlink" title="2 多判别器单生成器"></a>2 多判别器单生成器</h2><p>采用多个判别器[2]的好处带来了类似于boosting的优势，训练一个过于好的判别器，会损坏生成器的性能，这是GAN面临的一个大难题。如果能够训练多个没有那么强的判别器，然后进行boosting，可以取得不错的效果，甚至连dropout技术都可以应用进来。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-c074556ea6de9a92825594b8bac79d7d_720w.jpg" alt="img"></p><p>多个判别器还可以相互进行分工，比如在图像分类中，一个进行粗粒度的分类，一个进行细粒度的分类。在语音任务中，各自用于不同声道的处理。</p><h2 id="3-单判别器多生成器"><a href="#3-单判别器多生成器" class="headerlink" title="3 单判别器多生成器"></a>3 单判别器多生成器</h2><p>一般来说，生成器相比判别器要完成的任务更难，因为它要完成数据概率密度的拟合，而判别器只需要进行判别，导致影响GAN性能的一个问题就是模式坍塌，即生成高度相似的样本。</p><p>采用多个生成器单个判别器的方法，可以有效地缓解这个问题。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-afe2bc28e5eef370ad7706e526ad6d5f_720w.jpg" alt="img"></p><p>从上图结构可以看出，多个生成器采用同样的结构，在网络的浅层还共享权重。</p><h2 id="4-增加分类器"><a href="#4-增加分类器" class="headerlink" title="4 增加分类器"></a>4 增加分类器</h2><p>在利用GAN进行半监督的图像分类任务时，判别器需要同时担任两个角色，即判别生成的假样本，以及预测类别，这对判别器提出了较高的要求。通过增加一个分类器可以分担判别器的工作量，即将捕捉样本和标签的条件分布这一任务交给生成器和分类器，而判别器只专注于区分真实样本和生成的样本。</p><p>这一类结构以Triple Generative Adversarial Nets为代表，下图是它的网络结构。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-607f83bf70d07214dc0ea70bc13539e8_720w.jpg" alt="img"></p><h2 id="5-多个生成器多个判别器"><a href="#5-多个生成器多个判别器" class="headerlink" title="5 多个生成器多个判别器"></a>5 多个生成器多个判别器</h2><h4 id="5-1-级联结构"><a href="#5-1-级联结构" class="headerlink" title="5.1 级联结构"></a>5.1 级联结构</h4><p>早期以DCGAN为代表的网络生成的图片分辨率太低，质量不够好，都不超过100×100，在32×32或者64×64左右。这是因为难以一次性学习到生成高分辨率的样本，收敛过程容易不稳定。</p><p>类似的问题在图像分割，目标检测中都存在。在目标检测中，级联网络被广泛使用，即采用从粗到精的方法依次改进检测器的性能。在图像分割中进行上采样时也采用学习小倍率的放大而不是大倍率的方法，如利用两个2倍上采样替换一个4倍的上采样，不仅可以增强网络的表达能力，还降低了学习难度。</p><p>基于此，金字塔GAN结构被提出并广泛使用，它参考图像领域里面的金字塔结构由粗到精一步一步生成图像，并添加残差进行学习。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-22a2cf287efb97ca459710749b44d0f1_720w.jpg" alt="img"></p><p>上图就是它的结构，从低分辨率z3开始，逐级提升，最终生成I0，这是一个金字塔形状的结构，以下符号较多用图片代替。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-08e2f8c505c51c00025e36233857062b_720w.jpg" alt="img" style="zoom: 67%;"><h4 id="5-2-并行与循环结构"><a href="#5-2-并行与循环结构" class="headerlink" title="5.2 并行与循环结构"></a><strong>5.2 并行与循环结构</strong></h4><p>GAN有一大应用就是风格化，实现两个域之间的风格互换，以CycleGAN[6]为典型代表。它包含了多个生成器和多个判别器。Cycle的典型结构如下：</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-39005682b78d5c336a39d2adc69d4a6d_720w.jpg" alt="img"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-f7b6760003bd274c6304186fc0bf627e_720w.jpg" alt="img"></p><p>X和Y分别表示两个域的图像，可知这里存在两个生成器G和F，分别用于从X到Y的生成和Y到X到生成，包含两个判别器，分别是Dx和Dy。而损失本身也增加了一个循环损失。</p><p>另外在cross domain学习中也常用到多判别器多生成器多结构，分别学习不同的域。而且各个域的判别器和生成器通常会共享一些权重，如下图是CoGAN[7]的网络结构。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-fcc0f005574f85f377cc8df9eed0b9aa_720w.jpg" alt="img"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-单判别器单生成器&quot;&gt;&lt;a href=&quot;#1-单判别器单生成器&quot; class=&quot;headerlink&quot; title=&quot;1.单判别器单生成器&quot;&gt;&lt;/a&gt;1.单判别器单生成器&lt;/h2&gt;&lt;p&gt;个基本的用于生成图像的GAN的结构就是这样的。&lt;/p&gt;
&lt;p&gt;&lt;img sr</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="知乎文章阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E7%9F%A5%E4%B9%8E%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>详细解读batch norm</title>
    <link href="http://example.com/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/"/>
    <id>http://example.com/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/</id>
    <published>2021-08-29T04:50:02.000Z</published>
    <updated>2021-08-31T02:38:13.438Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Batch-Normalization-概念"><a href="#Batch-Normalization-概念" class="headerlink" title="Batch Normalization 概念"></a>Batch Normalization 概念</h1><p>Batch Normalization：批标准化<br>批：一批数据，通常为mini-batch<br>标准化：0均值，1方差</p><p>计算方式：<br>mini-batch中有x 1 , x 2 , . . . x m x_1,x_2,…x_m个数据，有两个待学习的参数 γ , β 然后通过这两个参数对x进行BN变化。 </p><p> 1.计算均值。    2.计算方差。     3.归一化处理到均值为0，方差为1。    4.恢复出这一层网络所要学到的分布   </p><p>具体计算公式看下图：</p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630212948797.png" alt="1630212948797" style="zoom:60%;"><p>在公式中求normalize这步中，为了防止分母为0的情况出现，加了一个修正系数ϵ ，得到的x ^ i  是一个服从0均值，1标准差的分布。最后对x ^ i  进行scale和shift操作就是通过两个超参数进行的。</p><h1 id="PyTorch的Batch-Nomalzaton-1d-2d-3d实现"><a href="#PyTorch的Batch-Nomalzaton-1d-2d-3d实现" class="headerlink" title="PyTorch的Batch Nomalzaton 1d/2d/3d实现"></a>PyTorch的Batch Nomalzaton 1d/2d/3d实现</h1><p><strong>_BatchNorm（基类）</strong><br>·nn.BatchNorm1d<br>·nn.BatchNorm2d<br>·nn.BatchNorm3d</p><p><strong>基类的参数：</strong><br>·num_features：一个样本特征数量（最重要）<br>·eps：分母修正项，一般是1e-5<br>·momentum：指数加权平均估计当前mean/var<br>·affine：是否需要affine transform，默认是true<br>·track_running_stats：是训练状态，还是测试状态</p><p><strong>主要属性：</strong><br>·running_mean：均值就是图片公式中的μ<br>·running_Var：方差图片公式中的σ<br>·weight:affine transform中的γ （可学习）<br>·bias:affine transform中的β（可学习）<br>上面四个属性中，后面两个是可学习的，前面两个呢？<br>在训练阶段：均值和方差采用<strong>指数加权平均</strong>计算<br>running_mean=(1-momentum)* pre_running_mean +momentum * mean_t<br>running_var=(1-momentum)* pre_running_var+ momentum * var_t<br>在测试阶段：当前统计值（已经估计好的值）</p><h2 id="1D"><a href="#1D" class="headerlink" title="1D"></a>1D</h2><p>·nn.BatchNorm1d input=B* 特征数* 1d特征<br>看下图可知，有3个batch，每个batch的特征数量是5个，特征的维度是1.所以大小是3<em>5</em>1，有时候1省略不写变成3 * 5.<br>那如何计算BatchNorm1d 的四个属性呢？<br>对每个特征横着看，对1.1.1求均值方差，学习γ 和β可得到第一个特征的四个属性，<br>同样对2.2.2求均值方差，学习γ 和β 可得到第二个特征的四个属性<br>同样对3.3.3求均值方差，学习γ 和β 可得到第三个特征的四个属性</p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630220059607.png" alt="1630220059607" style="zoom:67%;"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">9</span>)  <span class="comment"># 设置随机种子</span></span><br><span class="line">flag = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> flag:</span><br><span class="line">    batch_size = <span class="number">3</span></span><br><span class="line">    num_features = <span class="number">5</span><span class="comment">#特征数5个</span></span><br><span class="line">    momentum = <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line">    features_shape = (<span class="number">1</span>)<span class="comment">#1d，就是图中的每个特征维度为1</span></span><br><span class="line"></span><br><span class="line">    feature_map = torch.ones(features_shape) <span class="comment">#得到一个为1的张量                                                   </span></span><br><span class="line">    feature_maps = torch.stack([feature_map*(i+<span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_features)], dim=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 然后在特征数量方向进行扩展，就是图中的y轴        </span></span><br><span class="line">    feature_maps_bs = torch.stack([feature_maps <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size)], dim=<span class="number">0</span>)  </span><br><span class="line">    <span class="comment"># 在batch方向上进行扩展，就是图中的x轴          </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;input data:\n&#123;&#125; \n  shape is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(feature_maps_bs, feature_maps_bs.shape))<span class="comment">#打印出来应该是3*5*1</span></span><br><span class="line">    </span><br><span class="line">    bn = nn.BatchNorm1d(num_features=num_features, momentum=momentum)</span><br><span class="line"></span><br><span class="line">    running_mean, running_var = <span class="number">0</span>, <span class="number">1</span>          <span class="comment">## 均值和方差初始化</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        outputs = bn(feature_maps_bs)              <span class="comment">## running_mean=(1-momentum)* pre_running_mean +momentum * mean_t</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\niteration:&#123;&#125;, running mean: &#123;&#125; &quot;</span>.<span class="built_in">format</span>(i, bn.running_mean))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;iteration:&#123;&#125;, running var:&#123;&#125; &quot;</span>.<span class="built_in">format</span>(i, bn.running_var))</span><br><span class="line"></span><br><span class="line">        running_mean = (<span class="number">1</span> - momentum) * running_mean + momentum * mean_t</span><br><span class="line">        running_var = (<span class="number">1</span> - momentum) * running_var + momentum * var_t</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;iteration:&#123;&#125;, 第二个特征的running mean: &#123;&#125; &quot;</span>.<span class="built_in">format</span>(i, running_mean))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;iteration:&#123;&#125;, 第二个特征的running var:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i, running_var))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出结果：</p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630222648383.png" alt="1630222648383" style="zoom:77%;"><h3 id="均值计算"><a href="#均值计算" class="headerlink" title="均值计算"></a>均值计算</h3><p>根据公式：running_mean=(1-momentum)* pre_running_mean +momentum * mean_t</p><p>由于是第一次迭代，pre_running_mean （上一次的均值）没有，默认是0，</p><p>当前均值mean_t = 1、2、3、4、5</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">     第一个特征（3个1）                       计算结果：running_mean=(1-0.3)*0+0.3 * 1 = 0.3；</span><br><span class="line">同理，第二个特征（3个2）                       计算结果：running_mean=(1-0.3)*0+0.3 * 2 = 0.6；</span><br><span class="line">同理，第三个特征（3个3）                       计算结果：running_mean=(1-0.3)*0+0.3 * 3 = 0.9；</span><br><span class="line">同理，第二个特征（3个4）                       计算结果：running_mean=(1-0.3)*0+0.3 * 4 = 1.2；</span><br><span class="line">同理，第三个特征（3个5）                       计算结果：running_mean=(1-0.3)*0+0.3 * 5 = 1.5；</span><br></pre></td></tr></table></figure><p>下面看第二次迭代的时候：momentum = 0.3，mean_t = 1、2、3、4、5<br><strong>pre_running_mean = 上一个阶段计算出来的running_mean。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">     第一个特征（3个1）                    计算结果：running_mean=(1-0.3)*0.3+0.3 * 1 = 0.51；</span><br><span class="line">同理，第二个特征（3个2）                    计算结果：running_mean=(1-0.3)*0.6+0.3 * 2 = 1.02；</span><br><span class="line">同理，第三个特征（3个3）                    计算结果：running_mean=(1-0.3)*0.9+0.3 * 3 = 1.53；</span><br><span class="line">同理，第二个特征（3个4）                    计算结果：running_mean=(1-0.3)*1.2+0.3 * 4 = 2.04；</span><br><span class="line">同理，第三个特征（3个5）                    计算结果：running_mean=(1-0.3)*1.5+0.3 * 5 = 2.55；</span><br></pre></td></tr></table></figure><h3 id="方差计算"><a href="#方差计算" class="headerlink" title="方差计算"></a>方差计算</h3><p>根据公式：running_var=(1-momentum)* pre_running_var+ momentum * var_t</p><p>由于是第一次迭代，上一次的方差）没有，默认是pre_running_var = 1，当前方差var_t 为0</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">     第一个特征（3个1）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br><span class="line">同理，第二个特征（3个2）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br><span class="line">同理，第三个特征（3个3）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br><span class="line">同理，第二个特征（3个4）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br><span class="line">同理，第三个特征（3个5）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br></pre></td></tr></table></figure><p>下面看第二次迭代的时候：momentum = 0.3，pre_running_var = 0.7，当前方差var_t 为0</p><pre><code>     第一个特征（3个1）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；同理，第二个特征（3个2）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；同理，第三个特征（3个3）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；同理，第二个特征（3个4）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；同理，第三个特征（3个5）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；</code></pre><h2 id="2D"><a href="#2D" class="headerlink" title="2D"></a>2D</h2><p> ·nn.BatchNorm2d input=B* 特征数* 2d特征 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630223117775.png" alt="1630223117775" style="zoom:67%;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">batch_size = 3               # X轴长度</span><br><span class="line">num_features = 3             # Y轴长度</span><br><span class="line">momentum = 0.3   </span><br><span class="line">features_shape = (2, 2)  #   每个图形大小</span><br></pre></td></tr></table></figure><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224409278.png" alt="1630224409278" style="zoom:60%;"><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224422110.png" alt="1630224422110" style="zoom:80%;"><p>由于特征数num_features 是3，所以四个属性的shape也是3. 计算结果和1D一样。</p><h2 id="3D"><a href="#3D" class="headerlink" title="3D"></a>3D</h2><p> ·nn.BatchNorm3d input=B* 特征数* 3d特征 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224639302.png" alt="1630224639302" style="zoom:67%;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">batch_size = 3</span><br><span class="line">num_features = 4</span><br><span class="line">momentum = 0.3</span><br><span class="line">features_shape = (2, 2, 3)     # 上图代码表示。</span><br></pre></td></tr></table></figure><p> 上述一个特征的维度是2 * 2 * 3，每个特征有4个特征数，总共有3个样本 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224866710.png" alt="1630224866710" style="zoom:85%;"><h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><h2 id="1-Layer-Normalization"><a href="#1-Layer-Normalization" class="headerlink" title="1.Layer Normalization"></a>1.Layer Normalization</h2><p> 起因：BN不适用于变长的网络，如RNN  ，特征数长短不一。</p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224982805.png" alt="1630224982805" style="zoom:80%;"><p> 思路：逐层计算均值和方差，按下图三个圈圈来计算 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225024395.png" alt="1630225024395" style="zoom:80%;"><h2 id="2-Instance-Normalization"><a href="#2-Instance-Normalization" class="headerlink" title="2.Instance Normalization"></a>2.Instance Normalization</h2><p> 起因：BN在图像生成（lmage Generation）中不适用 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225208910.png" alt="1630225208910" style="zoom:80%;"><p> 思路：逐Instance（channel）计算均值和方差 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225260732.png" alt="1630225260732" style="zoom:80%;"><p>nn.InstanceNorm主要参数（和bn一样，所以InstanceNorm也有1d，2d，3d，这里就不赘述了）：<br>·num_features：一个样本特征数量（最重要）<br>·eps：分母修正项<br>·momentum：指数加权平均估计当前mean/var<br>·affine：是否需要affine transform<br>·track_running_stats：是训练状态，还是测试状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import numpy as np</span><br><span class="line">import torch.nn as nn</span><br><span class="line">torch.manual_seed(9)  # 设置随机种子</span><br><span class="line"></span><br><span class="line"># ======================================== nn.layer norm</span><br><span class="line">flag = 1</span><br><span class="line">if flag:</span><br><span class="line">    batch_size = 3</span><br><span class="line">    num_features = 3</span><br><span class="line">    momentum = 0.3</span><br><span class="line"></span><br><span class="line">    features_shape = (2, 2)#设置这个大小是和上面图片一样</span><br><span class="line"></span><br><span class="line">    feature_map = torch.ones(features_shape)    # 2D</span><br><span class="line">    feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)  # 3D</span><br><span class="line">    feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)  # 4D</span><br><span class="line"></span><br><span class="line">    print(&quot;Instance Normalization&quot;)#打印输入数据</span><br><span class="line">    print(&quot;input data:\n&#123;&#125; \n shape is &#123;&#125;\n&quot;.format(feature_maps_bs, feature_maps_bs.shape))</span><br><span class="line"></span><br><span class="line">    instance_n = nn.InstanceNorm2d(num_features=num_features, momentum=momentum)</span><br><span class="line"></span><br><span class="line">    for i in range(1):</span><br><span class="line">        outputs = instance_n(feature_maps_bs)</span><br><span class="line"></span><br><span class="line">        print(outputs)</span><br><span class="line">        print(&quot;\niter:&#123;&#125;, running_mean.shape: &#123;&#125;&quot;.format(i, bn.running_mean.shape))</span><br><span class="line">        print(&quot;iter:&#123;&#125;, running_var.shape: &#123;&#125;&quot;.format(i, bn.running_var.shape))</span><br><span class="line">        print(&quot;iter:&#123;&#125;, weight.shape: &#123;&#125;&quot;.format(i, bn.weight.shape))</span><br><span class="line">        print(&quot;iter:&#123;&#125;, bias.shape: &#123;&#125;&quot;.format(i, bn.bias.shape))</span><br></pre></td></tr></table></figure><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225515365.png" alt="1630225515365" style="zoom: 67%;"><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225585148.png" alt="1630225585148" style="zoom:67%;">]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Batch-Normalization-概念&quot;&gt;&lt;a href=&quot;#Batch-Normalization-概念&quot; class=&quot;headerlink&quot; title=&quot;Batch Normalization 概念&quot;&gt;&lt;/a&gt;Batch Normalization </summary>
      
    
    
    
    <category term="深度学习（第一层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>归一化</title>
    <link href="http://example.com/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/"/>
    <id>http://example.com/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/</id>
    <published>2021-08-29T03:32:18.758Z</published>
    <updated>2021-08-29T04:50:08.738Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一-本文的内容包括："><a href="#一-本文的内容包括：" class="headerlink" title="一. 本文的内容包括："></a>一. 本文的内容包括：</h3><pre><code>   1. Batch Normalization，其论文：https://arxiv.org/pdf/1502.03167.pdf   2. Layer Normalizaiton，其论文：https://arxiv.org/pdf/1607.06450v1.pdf3. Instance Normalization，其论文：https://arxiv.org/pdf/1607.08022.pdf4. Group Normalization，其论文：https://arxiv.org/pdf/1803.08494.pdf5. Switchable Normalization，其论文：https://arxiv.org/pdf/1806.10779.pdf</code></pre><h3 id="二-介绍"><a href="#二-介绍" class="headerlink" title="二. 介绍"></a>二. 介绍</h3><p>​    在介绍各个算法之前，我们先引进一个问题：为什么要做归一化处理？</p><p>神经网络学习过程的本质就是为了学习数据分布，如果我们没有做归一化处理，那么每一批次训练数据的分布不一样，从大的方向上看，神经网络则需要在这多个分布中找到平衡点，从小的方向上看，由于每层网络输入数据分布在不断变化，这也会导致每层网络在找平衡点，显然，神经网络就很难收敛了。当然，如果我们只是对输入的数据进行归一化处理（比如将输入的图像除以255，将其归到0到1之间），只能保证输入层数据分布是一样的，并不能保证每层网络输入数据分布是一样的，所以也需要在神经网络的中间层加入归一化处理。</p><p>BN、LN、IN和GN这四个归一化的计算流程几乎是一样的，可以分为四步：</p><p>  1.计算出均值</p><p>  2.计算出方差</p><p>  3.归一化处理到均值为0，方差为1</p><p>  4.变化重构，恢复出这一层网络所要学到的分布           </p><p>​                 (尺度变换和偏移：将x_i乘以γ 调整数值大小，再加上β增加偏移后得到y_i ，这里的γ是尺度因子，β是平移因子。这一步是BN的精髓，由于归一化后的 x_i 基本会被限制在正态分布下，使得网络的表达能力下降。为解决该问题，我们引入两个新的参数：γ , β γ,β<em>γ</em>,<em>β</em>。 γ γ<em>γ</em>和β β<em>β</em>是在训练时网络自己学习得到的。)</p><img src="/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/1630208171755.png" alt="1630208171755" style="zoom:67%;"><p> 训练的时候，是根据输入的每一批数据来计算均值和方差，那么测试的时候，平均值和方差是怎么来的？</p><p>对于均值来说直接计算所有训练时batch 均值的平均值；然后对于标准偏差采用每个batch 方差的无偏估计</p><img src="/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/1630208372638.png" alt="1630208372638" style="zoom:67%;"><p>接下来，我们先用一个示意图来形象的表现BN、LN、IN和GN的区别（图片来自于GN这一篇论文），在输入图片的维度为（NCHW）中，HW是被合成一个维度，这个是方便画出示意图，C和N各占一个维度</p><p><img src="/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/1630208469512.png" alt="1630208469512"></p><p> Batch Normalization：</p><p>   1.BN的计算就是把每个通道的NHW单独拿出来归一化处理</p><p>   2.针对每个channel我们都有一组γ,β，所以可学习的参数为2*C</p><p>   3.当batch size越小，BN的表现效果也越不好，因为计算过程中所得到的均值和方差不能代表全局</p><p>Layer Normalizaiton：</p><p>   1.LN的计算就是把每个CHW单独拿出来归一化处理，不受batchsize 的影响</p><p>   2.常用在RNN网络，但如果输入的特征区别很大，那么就不建议使用它做归一化处理</p><p>Instance Normalization</p><p>   1.IN的计算就是把每个HW单独拿出来归一化处理，不受通道和batchsize 的影响</p><p>   2.常用在风格化迁移，但如果特征图可以用到通道之间的相关性，那么就不建议使用它做归一化处理</p><p>Group Normalization</p><p>1.GN的计算就是把先把通道C分成G组，然后把每个gHW单独拿出来归一化处理，最后把G组归一化之后的数据合并成CHW</p><p>2.GN介于LN和IN之间，当然可以说LN和IN就是GN的特列，比如G的大小为1或者为C</p><p>Switchable Normalization</p><p>1.将 BN、LN、IN 结合，赋予权重，让网络自己去学习归一化层应该使用什么方法</p><p>2.集万千宠爱于一身，但训练复杂</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一-本文的内容包括：&quot;&gt;&lt;a href=&quot;#一-本文的内容包括：&quot; class=&quot;headerlink&quot; title=&quot;一. 本文的内容包括：&quot;&gt;&lt;/a&gt;一. 本文的内容包括：&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;   1. Batch Normalization，其论</summary>
      
    
    
    
    <category term="深度学习（第一层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>在深度学习中Python常用模块</title>
    <link href="http://example.com/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/"/>
    <id>http://example.com/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/</id>
    <published>2021-08-20T07:20:00.000Z</published>
    <updated>2021-08-29T03:33:17.411Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1、OS模块"><a href="#1、OS模块" class="headerlink" title="1、OS模块"></a>1、OS模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">os.getcwd()//获取当前工作的目录，如：返回结果为：&#x27;C:\\Program Files\\Python36&#x27;</span><br><span class="line">os.listdir(path)//列出path目录下所有的文件和目录名。Path参数可以省略,如：os.listdir(&quot;.&quot;)</span><br><span class="line">os.remove(path)//删除path指定的文件，该参数不能省略。</span><br><span class="line">os.rmdir(path)//删除path指定的目录，该参数不能省略。</span><br><span class="line">os.mkdir(path)//创建path指定的目录，该参数不能省略。递归建立可用：os.makedirs()</span><br><span class="line">os.path.split(path)//返回路径的目录和文件名，即将目录和文件名分开，而不是一个整体。此处只是把前后两部分分开而已。就是找最后一个&#x27;/&#x27;。</span><br><span class="line">os.path.join(path, name)//连接目录和文件名，与os.path.split(path)相对。</span><br><span class="line">os.chdir(path)//&#x27;change dir&#x27;改变目录到指定目录</span><br><span class="line">os.path.basename(path)//返回文件名</span><br><span class="line">os.path.dirname(path)//返回文件路径</span><br><span class="line">os.walk(path)//返回的是一个三元组(root,dirs,files):</span><br><span class="line">&#123;root 所指的是当前正在遍历的这个文件夹的本身的地址</span><br><span class="line">dirs 是一个 list ，内容是该文件夹中所有的目录的名字(不包括子目录)</span><br><span class="line">files 同样是 list , 内容是该文件夹中所有的文件(不包括子目录)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2、sys模块"><a href="#2、sys模块" class="headerlink" title="2、sys模块"></a>2、sys模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sys.path.insert(0,path)//使用sys.path.insert()方法可以临时添加搜索路径，方便更简洁的import其他包和模块。</span><br></pre></td></tr></table></figure><h2 id="3、pandas模块"><a href="#3、pandas模块" class="headerlink" title="3、pandas模块"></a>3、pandas模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">df：任意的Pandas DataFrame对象，一个类似于一维数组的对象，它有一个数组标签，也称之为索引 (index)</span><br><span class="line">s：任意的Pandas Series对象，类似于一个表格</span><br><span class="line"></span><br><span class="line">导入数据----------pd</span><br><span class="line"></span><br><span class="line">pd.read_csv(filename)//从CSV文件导入数据</span><br><span class="line">pd.read_json(json_string)//从JSON格式的字符串导入数据</span><br><span class="line">pd.DataFrame(dict)//从字典对象导入数据，Key是列名，Value是数据</span><br><span class="line">pd.read_excel(filename)//从Excel文件导入数据</span><br><span class="line"></span><br><span class="line">导出数据----------df.to</span><br><span class="line"></span><br><span class="line">df.to_csv(filename)//导出数据到CSV文件</span><br><span class="line">df.to_excel(filename)//导出数据到Excel文件</span><br><span class="line">df.to_json(filename)//以Json格式导出数据到文本文件</span><br><span class="line"></span><br><span class="line">创建测试对象</span><br><span class="line"></span><br><span class="line">pd.DataFrame(np.random.rand(20,5))//创建20行5列的随机数组成的DataFrame对象</span><br><span class="line">pd.Series(my_list)//从可迭代对象my_list创建一个Series对象</span><br><span class="line"></span><br><span class="line">查看、检查数据</span><br><span class="line"></span><br><span class="line">df.head(n)//查看DataFrame对象的前n行</span><br><span class="line">df.tail(n)//查看DataFrame对象的最后n行</span><br><span class="line">df.shape()//查看行数和列数</span><br><span class="line">df.info()//查看索引、数据类型和内存信息</span><br><span class="line"></span><br><span class="line">数据选取</span><br><span class="line"></span><br><span class="line">df[col]//根据列名，并以Series的形式返回列</span><br><span class="line">df[[col1, col2]]//以DataFrame形式返回多列</span><br><span class="line">s.iloc[0]//按位置选取数据</span><br><span class="line">s.loc[&#x27;index_one&#x27;]//按索引选取数据</span><br><span class="line">df.iloc[0,:]//返回第一行</span><br><span class="line">df.iloc[0,0]//返回第一列的第一个元素</span><br><span class="line">df.values[:,:-1]//返回除了最后一列的其他列的所以数据</span><br><span class="line">df.query(&#x27;[1, 2] not in c&#x27;)//返回c列中不包含1，2的其他数据集</span><br><span class="line"></span><br><span class="line">数据处理</span><br><span class="line"></span><br><span class="line">df[df[col] &gt; 0.5]//选择col列的值大于0.5的行</span><br><span class="line">df.sort_values(col1)//按照列col1排序数据，默认升序排列</span><br><span class="line">df.sort_values(col2, ascending=False)//按照列col1降序排列数据</span><br><span class="line">df.sort_values([col1,col2], ascending=[True,False])//先按列col1升序排列，后按col2降序排列数据</span><br><span class="line">df1.append(df2)//将df2中的行添加到df1的尾部</span><br><span class="line">df.concat([df1, df2],axis=1)//将df2中的列添加到df1的尾部</span><br><span class="line">df1.join(df2,on=col1,how=&#x27;inner&#x27;)//对df1的列和df2的列执行SQL形式的join</span><br><span class="line"></span><br><span class="line">数据统计</span><br><span class="line"></span><br><span class="line">df.describe()//查看数据值列的汇总统计</span><br><span class="line">df.mean()//返回所有列的均值</span><br><span class="line">df.corr()//返回列与列之间的相关系数</span><br><span class="line">df.count()//返回每一列中的非空值的个数</span><br><span class="line">df.max()//返回每一列的最大值</span><br><span class="line">df.min()//返回每一列的最小值</span><br><span class="line">df.median()//返回每一列的中位数</span><br><span class="line">df.std()//返回每一列的标准差</span><br></pre></td></tr></table></figure><h2 id="4、Numpy模块"><a href="#4、Numpy模块" class="headerlink" title="4、Numpy模块"></a>4、Numpy模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line">创建数组array</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">a = np.array([1,2,3])   #创建数组</span><br><span class="line">b = np.array([(1.5,2,3), (4,5,6)],dtype=float)</span><br><span class="line">c = np.array([(1.5,2,3), (4,5,6)],[(3,2,1), (4,5,6) ] ], dtype=float)</span><br><span class="line"></span><br><span class="line">np.zeros((3,4))  #创建0数组</span><br><span class="line">np.ones((2,3,4), dtype=np.int16)  #创建1数组</span><br><span class="line">d = np.arrange(10,25,5)  #创建相同步数数组</span><br><span class="line">np.linspace(0,2,9)  #创建等差数组</span><br><span class="line"></span><br><span class="line">e = np.full((2,2), 7) #创建常数数组</span><br><span class="line">f = np.eye(2) #创建2x2矩阵</span><br><span class="line">np.random.random((2,2)) #创建随机数组</span><br><span class="line">np.empty((3,2)) #创建空数组</span><br><span class="line"></span><br><span class="line">复制数组</span><br><span class="line"></span><br><span class="line">h = a.view()</span><br><span class="line">np.copy(a)</span><br><span class="line">h = a.copy()</span><br><span class="line"></span><br><span class="line">输出数组</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">print(my_array) #打印数组</span><br><span class="line"></span><br><span class="line">#saving &amp;Loading on disk保存到磁盘</span><br><span class="line">np.save(&#x27;my_array&#x27;, a)</span><br><span class="line">np.savez(&#x27;array.npz&#x27;, a, b)</span><br><span class="line">np.load(&#x27;my_array.npy&#x27;)</span><br><span class="line"></span><br><span class="line">#saving &amp;Loading Text files保存到文件</span><br><span class="line">np.loadtxt(&quot;my file.txt&quot;)</span><br><span class="line">np.genfromtxt(&quot;my_file.csv&quot;, delimiter=&#x27;,&#x27;)</span><br><span class="line">np.savetxt(&quot;marry.txt&quot;, a, delimiter=&quot;&quot;)</span><br><span class="line"></span><br><span class="line">Numpy中的基本运算</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">#arithmetic operation算术运算</span><br><span class="line">g = a - b</span><br><span class="line">np.subtract(a,b) #减法</span><br><span class="line">b+a</span><br><span class="line">np.add(b,a) #加法</span><br><span class="line">a / b</span><br><span class="line">np.divide(a,b) #除法</span><br><span class="line">a * b</span><br><span class="line">np.multiple(a,b) #乘法</span><br><span class="line">np.exp(b) #指数</span><br><span class="line">np.sqrt(b) #开方</span><br><span class="line">np.sin(a) #sin函数</span><br><span class="line">np.cos(b) #cos函数</span><br><span class="line">np.log(a) #log函数</span><br><span class="line">e.dot(f) #内积</span><br><span class="line"></span><br><span class="line">#Comparison比较</span><br><span class="line">a == b #元素</span><br><span class="line">a &lt; 2 #元素</span><br><span class="line">np.array_equal(a,b) #数组</span><br><span class="line"></span><br><span class="line">#Aggregate Functions 函数</span><br><span class="line">a.sum() #求和</span><br><span class="line">b.min() #最小值</span><br><span class="line">b.max(axis=0) #最大值数组列</span><br><span class="line">b.cumsum(axis=1) #元素累加和</span><br><span class="line">a.mean() #平均值</span><br><span class="line">b.median() #中位数</span><br><span class="line">a.corrcoef() #相关系数</span><br><span class="line">np.std(b) #标准差</span><br><span class="line"></span><br><span class="line">数组处理</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">#Transposing Array</span><br><span class="line">I = np.transpose(b) #转置矩阵</span><br><span class="line">i.T #转置矩阵</span><br><span class="line"></span><br><span class="line">#Changing Array Shape</span><br><span class="line">b.ravel() #降为一维数组</span><br><span class="line">g.reshape(3,-2) #重组</span><br><span class="line"></span><br><span class="line">#Adding/Removing Elements</span><br><span class="line">h.resize((2,6)) #返回shape(2,6)</span><br><span class="line">np.append(h,g) #添加</span><br><span class="line">np.insert(a,1,5) #插入</span><br><span class="line">np.delete(a,[1]) #删除</span><br><span class="line"></span><br><span class="line">#Combining Arrays</span><br><span class="line">np.concatenate((a,d), axis=0) #连结</span><br><span class="line">np.vstack((a,b)) #垂直堆叠</span><br><span class="line">np.r_[e,f] #垂直堆叠</span><br><span class="line">np.hstack((e,f)) #水平堆叠</span><br><span class="line">np.column_stack((a,d)) #创建水平堆叠</span><br><span class="line">np.c_[a,d] ##创建水平堆叠</span><br><span class="line"></span><br><span class="line">#splitting arrays</span><br><span class="line">np.hsplit(a,3) #水平分离</span><br><span class="line">np.vsplit(c,2) #垂直分离</span><br><span class="line"></span><br><span class="line">数组索引</span><br><span class="line">import numpy as np</span><br><span class="line">#subsetting</span><br><span class="line">a[2] #选取数组第三个元素</span><br><span class="line">b[1,2] #选取2行3列元素</span><br><span class="line"></span><br><span class="line">#slicing</span><br><span class="line">a[0:2] #选1到3元素</span><br><span class="line">b[0:2,1] #选1到2行的2列元素</span><br><span class="line">b[:1] #选所有1行的元素</span><br><span class="line">c[1,...] #c[1,:,:]</span><br><span class="line">a[ : :-1]  #反转数组</span><br><span class="line"></span><br><span class="line">#Boolean Indexing</span><br><span class="line">a[a&lt;2] #选取数组中元素&lt;2的</span><br><span class="line"></span><br><span class="line">#Fancy Indexing</span><br><span class="line">b[[1,0,1,0], [0,1,2,0]]</span><br><span class="line">#选取[1,0],[0,1],[1,2],[0,0]</span><br><span class="line">b[[1,0,1,0][:, [0,1,2,0]]]</span><br><span class="line">#选取矩阵的一部分</span><br><span class="line"></span><br><span class="line">Numpy中的数据类型</span><br><span class="line"></span><br><span class="line">np.int64 #64位整数</span><br><span class="line">np.float32 #标准双精度浮点</span><br><span class="line">np.complex #复杂树已浮点128为代表</span><br><span class="line">np.bool #true&amp;false</span><br><span class="line">np.object #python object</span><br><span class="line">np.string_ #固定长度字符串</span><br><span class="line">np.unicode_ #固定长度统一码</span><br><span class="line"></span><br><span class="line">检查数组信息</span><br><span class="line">a.shape #数组维度</span><br><span class="line">len(a) #数组长度</span><br><span class="line">b.ndim #数组维度数量</span><br><span class="line">e.size #数组元素数量</span><br><span class="line">b.dtype #元素数据类型</span><br><span class="line">b.dtype.name #数据类型名</span><br><span class="line">b.astype(int) #改变数组类型</span><br><span class="line"></span><br><span class="line">#asking for help更多信息</span><br><span class="line">np.info(np.ndarray.dtype)</span><br><span class="line"></span><br><span class="line">对数组进行排序</span><br><span class="line"></span><br><span class="line">#对数组进行排序</span><br><span class="line">a.sort()</span><br><span class="line">c.sort(axis=0)</span><br></pre></td></tr></table></figure><h2 id="5、matplotlib模块"><a href="#5、matplotlib模块" class="headerlink" title="5、matplotlib模块"></a>5、matplotlib模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">plt.figure(num=None,</span><br><span class="line">figsize=None, </span><br><span class="line"> dpi=None,</span><br><span class="line"> facecolor=None, </span><br><span class="line">  edgecolor=None, </span><br><span class="line">  frameon=True, </span><br><span class="line">  FigureClass=&lt;class &#x27;matplotlib.figure.Figure&#x27;&gt;, </span><br><span class="line">  clear=False, **kwargs)</span><br><span class="line">  num：整数或字符串，可选，默认:无</span><br><span class="line">  figsize：(float, float), optional, default: None</span><br><span class="line">  dpi：图形分辨率，整数，可选，默认:无</span><br><span class="line">  facecolor：背景颜色</span><br><span class="line">  edgecolor：边框颜色</span><br><span class="line">  frameon：bool，可选，默认值:True//如果为False，则禁止绘制图形框</span><br><span class="line">  FigureClass：图的子类</span><br><span class="line">  clear：bool，可选，默认值:True如果为True且该图片已经存在，则清除它。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.imshow()</span><br><span class="line"></span><br><span class="line">plt.imshow(X, </span><br><span class="line">cmap=None,</span><br><span class="line"> norm=None, </span><br><span class="line"> aspect=None, </span><br><span class="line"> interpolation=None, </span><br><span class="line"> alpha=None, </span><br><span class="line"> vmin=None, </span><br><span class="line"> vmax=None, </span><br><span class="line"> origin=None, </span><br><span class="line"> extent=None, </span><br><span class="line"> shape=&lt;deprecated parameter&gt;, </span><br><span class="line"> filternorm=1, </span><br><span class="line"> filterrad=4.0,</span><br><span class="line"> imlim=&lt;deprecated parameter&gt;, </span><br><span class="line"> resample=None, </span><br><span class="line"> url=None, </span><br><span class="line"> *, </span><br><span class="line"> data=None, </span><br><span class="line"> **kwargs)</span><br><span class="line">X：图像数据</span><br><span class="line">cmap：str或Colormap，可选</span><br><span class="line">norm：正常化,可选</span><br><span class="line">aspect：&#123;&#x27;equal&#x27;， &#x27;auto&#x27;&#125;或float，可选‘equal’:确保长宽比为1；’auto‘：自动调整长宽</span><br><span class="line">interpolation：str,可选 &#x27;none&#x27;, &#x27;nearest&#x27;, &#x27;bilinear&#x27;, &#x27;bicubic&#x27;, &#x27;spline16&#x27;, &#x27;spline36&#x27;, &#x27;hanning&#x27;, &#x27;hamming&#x27;, </span><br><span class="line">&#x27;hermite&#x27;, &#x27;kaiser&#x27;, &#x27;quadric&#x27;, &#x27;catrom&#x27;, &#x27;gaussian&#x27;, &#x27;bessel&#x27;, &#x27;mitchell&#x27;, &#x27;sinc&#x27;, &#x27;lanczos&#x27;</span><br><span class="line">alpha：比例,可选介于0(透明)和1(不透明)之间</span><br><span class="line">vmin, vmax：比例,可选当使用标量数据而没有明确的norm时，vmin和vmax定义了颜色映射所涵盖的数据范围</span><br><span class="line">origin： &#123;&#x27;upper&#x27;, &#x27;lower&#x27;&#125;，可选的</span><br><span class="line"></span><br><span class="line">plt.subplot()</span><br><span class="line"></span><br><span class="line">plt.subplot(nrows,ncols,index,**kwargs)</span><br><span class="line">子图将在包含nrows行和ncols列的网格中占据索引位置。index从左上角的1开始，向右递增</span><br><span class="line"></span><br><span class="line">plt.plot()</span><br><span class="line"></span><br><span class="line">plt.plot(x,y,format_string,**kwargs)</span><br><span class="line">x轴数据，</span><br><span class="line">y轴数据，</span><br><span class="line">format_string控制曲线的格式字串 ，format_string由颜色字符，风格字符，和标记字符 </span><br><span class="line">&#x27;b&#x27;blue</span><br><span class="line">&#x27;g&#x27;green</span><br><span class="line">&#x27;r&#x27;red</span><br><span class="line">&#x27;c&#x27;cyan</span><br><span class="line">&#x27;m&#x27;magenta</span><br><span class="line">&#x27;y&#x27;yellow</span><br><span class="line">&#x27;k&#x27;black</span><br><span class="line">&#x27;w&#x27;white</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="6、argparse模块"><a href="#6、argparse模块" class="headerlink" title="6、argparse模块"></a>6、argparse模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">##创建解析器</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=&#x27;Process some integers.&#x27;)</span><br><span class="line"></span><br><span class="line">该ArgumentParser对象将保存将命令行解析为 Python 数据类型所需的所有信息。</span><br><span class="line"></span><br><span class="line">## 添加参数</span><br><span class="line"></span><br><span class="line">ArgumentParser通过调用add_argument() 方法来填充有关程序参数的信息。通常，这些调用告诉ArgumentParser 如何在命令行上获取字符串并将它们转换为对象。该信息在parse_args()被调用时被存储和使用。例如：</span><br><span class="line"> parser.add_argument(&#x27;integers&#x27;, metavar=&#x27;N&#x27;, type=int, nargs=&#x27;+&#x27;,</span><br><span class="line">                    help=&#x27;an integer for the accumulator&#x27;)</span><br><span class="line"> parser.add_argument(&#x27;--sum&#x27;, dest=&#x27;accumulate&#x27;, action=&#x27;store_const&#x27;,</span><br><span class="line">                     const=sum, default=max,</span><br><span class="line">                     help=&#x27;sum the integers (default: find the max)&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 解析参数</span><br><span class="line"></span><br><span class="line">ArgumentParser 通过parse_args()方法解析参数 。这将检查命令行，将每个参数转换为适当的类型，然后调用适当的操作。</span><br><span class="line"></span><br><span class="line"> config = parser.parse_args()</span><br><span class="line"></span><br><span class="line">在脚本中，parse_args()通常会不带参数地调用，并且将自动从确定命令行参数sys.argv</span><br><span class="line"></span><br><span class="line">## ArgumentParser 对象----代码只用到了三个</span><br><span class="line"></span><br><span class="line">argparse.addP_ArgumentParser( *prog=None* , *usage=None* , *description=None* , *epilog=None* , *parents=[]* , *formatter_class=argparse.HelpFormatter* , *prefix_chars=&#x27;-&#x27;* , *fromfile_prefix_chars=None* , *argument_default=None* , *conflict_handler=&#x27;error&#x27;* , *add_help =True* , *allow_abbrev=True* , *exit_on_error=True* ) </span><br><span class="line"></span><br><span class="line">  创建一个新ArgumentParser对象。所有参数都应作为关键字参数传递。每个参数在下面都有更详细的描述，但简而言之，它们是：</span><br><span class="line"></span><br><span class="line">  PROG -程序的名称（默认：`sys.argv[0]`）</span><br><span class="line"></span><br><span class="line">  description- 在参数帮助之前显示的文本（默认值：无）</span><br><span class="line"></span><br><span class="line">  argument_default -为参数的全局默认值（默认值：`None`）</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="7、PIL库—处理图像"><a href="#7、PIL库—处理图像" class="headerlink" title="7、PIL库—处理图像"></a>7、PIL库—处理图像</h2><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629444947068.png" alt="1629444947068"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629444960440.png" alt="1629444960440"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629444979009.png" alt="1629444979009"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629445020254.png" alt="1629445020254"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629445055246.png" alt="1629445055246"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629445103852.png" alt="1629445103852"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629445114582.png" alt="1629445114582"></p><h2 id="8、pytorch读取数据"><a href="#8、pytorch读取数据" class="headerlink" title="8、pytorch读取数据"></a>8、pytorch读取数据</h2><p>具体细节看—<a href="https://zhuanlan.zhihu.com/p/30934236">https://zhuanlan.zhihu.com/p/30934236</a></p><h2 id="9-itertools库"><a href="#9-itertools库" class="headerlink" title="9.itertools库"></a>9.itertools库</h2><p> &emsp;&emsp;迭代器（生成器）在Python中是一种很常用也很好用的数据结构，比起列表(list)来说，迭代器最大的优势就是延迟计算，按需使用，从而提高开发体验和运行效率，以至于在Python 3中map,filter等操作返回的不再是列表而是迭代器。 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line">itertools.accumulate</span><br><span class="line"></span><br><span class="line">简单来说就是累加。</span><br><span class="line">&gt;&gt;&gt; import itertools</span><br><span class="line">&gt;&gt;&gt; x = itertools.accumulate(range(10))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 1, 3, 6, 10, 15, 21, 28, 36, 45]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.chain</span><br><span class="line"></span><br><span class="line">连接多个列表或者迭代器。</span><br><span class="line">&gt;&gt;&gt; x = itertools.chain(range(3), range(4), [3,2,1])</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 1, 2, 0, 1, 2, 3, 3, 2, 1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.combinations</span><br><span class="line"></span><br><span class="line">求列表或生成器中指定数目的元素不重复的所有组合</span><br><span class="line">&gt;&gt;&gt; x = itertools.combinations(range(4), 3)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(0, 1, 2), (0, 1, 3), (0, 2, 3), (1, 2, 3)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.combinations_with_replacement</span><br><span class="line"></span><br><span class="line">允许重复元素的组合</span><br><span class="line">&gt;&gt;&gt; x = itertools.combinations_with_replacement(&#x27;ABC&#x27;, 2)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(&#x27;A&#x27;, &#x27;A&#x27;), (&#x27;A&#x27;, &#x27;B&#x27;), (&#x27;A&#x27;, &#x27;C&#x27;), (&#x27;B&#x27;, &#x27;B&#x27;), (&#x27;B&#x27;, &#x27;C&#x27;), (&#x27;C&#x27;, &#x27;C&#x27;)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.compress</span><br><span class="line">按照真值表筛选元素</span><br><span class="line">&gt;&gt;&gt; x = itertools.compress(range(5), (True, False, True, True, False))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 2, 3]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.count</span><br><span class="line"></span><br><span class="line">就是一个计数器,可以指定起始位置和步长</span><br><span class="line">&gt;&gt;&gt; x = itertools.count(start=20, step=-1)</span><br><span class="line">&gt;&gt;&gt; print(list(itertools.islice(x, 0, 10, 1)))</span><br><span class="line">[20, 19, 18, 17, 16, 15, 14, 13, 12, 11]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.cycle</span><br><span class="line"></span><br><span class="line">循环指定的列表和迭代器</span><br><span class="line">&gt;&gt;&gt; x = itertools.cycle(&#x27;ABC&#x27;)</span><br><span class="line">&gt;&gt;&gt; print(list(itertools.islice(x, 0, 10, 1)))</span><br><span class="line">[&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;A&#x27;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.dropwhile</span><br><span class="line"></span><br><span class="line">按照真值函数丢弃掉列表和迭代器前面的元素</span><br><span class="line">&gt;&gt;&gt; x = itertools.dropwhile(lambda e: e &lt; 5, range(10))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[5, 6, 7, 8, 9]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.filterfalse</span><br><span class="line"></span><br><span class="line">保留对应真值为False的元素</span><br><span class="line">&gt;&gt;&gt; x = itertools.filterfalse(lambda e: e &lt; 5, (1, 5, 3, 6, 9, 4))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[5, 6, 9]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.groupby</span><br><span class="line"></span><br><span class="line">按照分组函数的值对元素进行分组</span><br><span class="line">&gt;&gt;&gt; x = itertools.groupby(range(10), lambda x: x &lt; 5 or x &gt; 8)                                                                                                </span><br><span class="line">&gt;&gt;&gt; for condition, numbers in x:                                                  </span><br><span class="line">...     print(condition, list(numbers))                                                                                                        </span><br><span class="line">True [0, 1, 2, 3, 4]                                                              </span><br><span class="line">False [5, 6, 7, 8]                                                                </span><br><span class="line">True [9]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.islice</span><br><span class="line">上文使用过的函数，对迭代器进行切片</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x = itertools.islice(range(10), 0, 9, 2)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 2, 4, 6, 8]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.permutations</span><br><span class="line">产生指定数目的元素的所有排列(顺序有关)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x = itertools.permutations(range(4), 3)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(0, 1, 2), (0, 1, 3), (0, 2, 1), (0, 2, 3), (0, 3, 1), (0, 3, 2), (1, 0, 2), (1, 0, 3), (1, 2, 0), (1, 2, 3), (1, 3, 0), (1, 3, 2), (2, 0, 1), (2, 0,3), (2, 1, 0), (2, 1, 3), (2, 3, 0), (2, 3, 1), (3, 0, 1), (3, 0, 2), (3, 1, 0), (3, 1, 2), (3, 2, 0), (3, 2, 1)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.product</span><br><span class="line"></span><br><span class="line">产生多个列表和迭代器的(积)</span><br><span class="line">&gt;&gt;&gt; x = itertools.product(&#x27;ABC&#x27;, range(3))</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(&#x27;A&#x27;, 0), (&#x27;A&#x27;, 1), (&#x27;A&#x27;, 2), (&#x27;B&#x27;, 0), (&#x27;B&#x27;, 1), (&#x27;B&#x27;, 2), (&#x27;C&#x27;, 0), (&#x27;C&#x27;, 1), (&#x27;C&#x27;, 2)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.repeat</span><br><span class="line"></span><br><span class="line">简单的生成一个拥有指定数目元素的迭代器</span><br><span class="line">&gt;&gt;&gt; x = itertools.repeat(0, 5)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 0, 0, 0, 0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.starmap</span><br><span class="line"></span><br><span class="line">类似map</span><br><span class="line">&gt;&gt;&gt; x = itertools.starmap(str.islower, &#x27;aBCDefGhI&#x27;)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[True, False, False, False, True, True, False, True, False]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.takewhile</span><br><span class="line"></span><br><span class="line">与dropwhile相反，保留元素直至真值函数值为假。</span><br><span class="line">&gt;&gt;&gt; x = itertools.takewhile(lambda e: e &lt; 5, range(10))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 1, 2, 3, 4]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.tee</span><br><span class="line"></span><br><span class="line">生成指定数目的迭代器</span><br><span class="line">&gt;&gt;&gt; x = itertools.tee(range(10), 2)</span><br><span class="line">&gt;&gt;&gt; for letters in x:</span><br><span class="line">...     print(list(letters))</span><br><span class="line">...</span><br><span class="line">[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span><br><span class="line">[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.zip_longest</span><br><span class="line">类似于zip，不过已较长的列表和迭代器的长度为准</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x = itertools.zip_longest(range(3), range(5))</span><br><span class="line">&gt;&gt;&gt; y = zip(range(3), range(5))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(0, 0), (1, 1), (2, 2), (None, 3), (None, 4)]</span><br><span class="line">&gt;&gt;&gt; print(list(y))</span><br><span class="line">[(0, 0), (1, 1), (2, 2)]</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1、OS模块&quot;&gt;&lt;a href=&quot;#1、OS模块&quot; class=&quot;headerlink&quot; title=&quot;1、OS模块&quot;&gt;&lt;/a&gt;1、OS模块&lt;/h2&gt;&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=</summary>
      
    
    
    
    <category term="深度学习（第一层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="常用模块（第二层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>解读第四阶段素描GAN代码</title>
    <link href="http://example.com/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/"/>
    <id>http://example.com/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/</id>
    <published>2021-08-14T08:20:25.707Z</published>
    <updated>2021-09-01T05:47:35.578Z</updated>
    
    <content type="html"><![CDATA[<h1 id="填充和归一化"><a href="#填充和归一化" class="headerlink" title="填充和归一化"></a>填充和归一化</h1><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629449069633.png" alt="1629449069633"></p><p> **nn.ReflectionPad2d，使用输入边界的反射填充输入张量，与常规的零填充相比， 填充内容来自输入， 在GAN中使用比较常见。 **</p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629448984899.png" alt="1629448984899"></p><p> <code>torch.nn.Conv2d</code>( <em>in_channels</em> , <em>out_channels</em> , <em>kernel_size</em> , <em>stride=1</em> , <em>padding=0</em> , <em>dilation=1</em> , <em>groups=1</em> , <em>bias=True</em> , <em>padding_mode=’zeros’</em> , <em>device=None</em> , <em>dtype=None</em> ) </p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629449268090.png" alt="1629449268090"></p><p> <code>torch.nn.InstanceNorm2d</code>( <em>num_features</em> , <em>eps=1e-05</em> , <em>Momentum=0.1</em> , <em>affine=False</em> , <em>track_running_stats=False</em> , <em>device=None</em> , <em>dtype=None</em> ) ——第一个值：预期输入的大小。</p><p> 对于一个4D（N, C, H, W）张量，对于每个mini-batch (N)， 在每个通道 ( C ) 对每个二维张量 (H, W) 单独进行计算均值和方差。即对于一个（16，256， 128，128）的张量，计算16*256次均值方差。 </p><p> 对 4D 输入（具有附加通道维度的小批量 2D 输入）应用实例标准化 ，均值和标准差是针对小批量中的每个对象分别按维度计算的。 γ<em>γ</em> 和 β<em>β</em>是大小为C（其中C是输入大小）的可学习参数向量 </p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629450185909.png" alt="1629450185909"></p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629450464658.png" alt="1629450464658"></p><h1 id="生成器和判别器"><a href="#生成器和判别器" class="headerlink" title="生成器和判别器"></a>生成器和判别器</h1><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629461869476.png" alt="1629461869476"></p><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;生成器结构为上图。</p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629460495243.png" alt="1629460495243"></p><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;判别器结构为上图。</p><h2 id="生成器具体结构"><a href="#生成器具体结构" class="headerlink" title="生成器具体结构"></a>生成器具体结构</h2><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630393690709.png" alt="1630393690709"></p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630393705838.png" alt="1630393705838"></p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630393723184.png" alt="1630393723184"></p><h3 id="判别器具体结构"><a href="#判别器具体结构" class="headerlink" title="判别器具体结构"></a>判别器具体结构</h3><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630393831249.png" alt="1630393831249"></p><p>&emsp;&emsp;普通的GAN判别器最终输出一个向量，只需要输出一个表示整个图像评估的真或假，但PatchGAN的输出是一个N *N矩阵，每个元素如只有两个选择True或False，结果通常通过卷积层来实现。鉴别器对每个补丁进行真假判别，并取平均值作为最终鉴别器输出的图片结果。</p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629462224062.png" alt="1629462224062" style="zoom:50%;"><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;ResNet结构</p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629466487764.png" alt="1629466487764"></p><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;完整流程图</p><h1 id="优化器-Optimizer"><a href="#优化器-Optimizer" class="headerlink" title="优化器 Optimizer"></a>优化器 Optimizer</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prediction = wx + b             # b 是偏置量</span><br></pre></td></tr></table></figure><p>训练的过程，其实就是计算合适的w和b的过程。那么，什么样的w和b是“合适”的呢？答案就是预测值与真实值相差不大。例如定义损失函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = sum(|(y_ - prediction)|)</span><br></pre></td></tr></table></figure><p>即，真实值减去预测值，取绝对值后求和。训练的过程，可以粗略的理解成：调节 w 和 b， 使 loss 尽可能小。对w和b参数的调节，就是优化器（optimizer）需要做的，这就是优化器的作用。</p><p> <strong>在训练阶段， 每一次训练，神经网络参数都将得到一次拟合，达到一定次数后，才会收敛。而每次收敛的调整节奏，则取决于优化器</strong> </p><h2 id="优化器中的常用算法分为"><a href="#优化器中的常用算法分为" class="headerlink" title="优化器中的常用算法分为"></a>优化器中的常用算法分为</h2><p>（1）朴素梯度下降</p><ul><li><p>批量梯度下降法(Batch Gradient Descent )</p></li><li><p>随机梯度下降法（Stochastic Gradient Descent）</p></li><li><p>小批量随机梯度下降（Mini-Batch Gradient Descent）</p></li><li><p>带有动量的随机梯度下降(SGD with momentum)</p></li></ul><p>(2) 自适应梯度下降</p><ul><li> Adagrad （Adaptive gradient algorithm）</li><li> Adadelta/RMSProp</li><li> Adam（Adaptive Moment Estimation）</li><li> NAdam </li></ul><h3 id="Pytorch的十种优化器"><a href="#Pytorch的十种优化器" class="headerlink" title="Pytorch的十种优化器"></a>Pytorch的十种优化器</h3><p>1、optim.SGD：随机梯度下降法<br>2、optim.Adagrad：自适应学习率梯度下降法（对每个可学习参数具有1个自适应学习率）<br>3、optim.RMSprop：Adagrad的改进<br>4、optim.Adadelta：Adagrad的改进<br>5、optim.Adam：RMSprop结合Momentum<br>6、optim.Adamax：Adam增加学习率上限<br>7、optim.SparseAdam：稀疏版Adam<br>8、optim.ASGD：随机平均梯度下降<br>9、optim.Rprop：弹性反向传播（优化器应用场景在所有样本full_batch 一起计算梯度）<br>10、optim.LBFGS：BFGS的改进<br>原文链接：<a href="https://blog.csdn.net/qq_43784940/article/details/107955191">https://blog.csdn.net/qq_43784940/article/details/107955191</a></p><p><a href="https://www.cnblogs.com/peachtea/p/13532190.html">https://www.cnblogs.com/peachtea/p/13532190.html</a></p><p>torch为什么要使用optimizer.zero_grad() <a href="https://blog.csdn.net/scut_salmon/article/details/82414730">https://blog.csdn.net/scut_salmon/article/details/82414730</a></p><h3 id="1-批量梯度下降法-Batch-gradient-descent）"><a href="#1-批量梯度下降法-Batch-gradient-descent）" class="headerlink" title="1. 批量梯度下降法(Batch gradient descent）"></a><strong>1. 批量梯度下降法(Batch gradient descent</strong>）</h3><p><strong>更新规则</strong>：采用整个训练集的数据来计算loss函数对参数的梯度： </p><p><strong>优点</strong>：对于凸函数可以收敛到全局极小值，对于非凸函数可以收敛到局部极小值<br><strong>缺点</strong>：在一次更新中，对整个数据集计算梯度，计算速度很慢；如果数据集过大，则内存无法容纳；在模型训练过程中，无法使用新的数据更新模型。 </p><h3 id="2-随机梯度下降Stochastic-gradient-descent"><a href="#2-随机梯度下降Stochastic-gradient-descent" class="headerlink" title="2.随机梯度下降Stochastic gradient descent"></a><strong>2.随机梯度下降Stochastic gradient descent</strong></h3><p><strong>更新规则</strong>：SGD每次更新时对每个样本进行梯度下降。 </p><p> <strong>优点</strong>：对于很大的数据集来说，可能有很相似的样本，导致BGD在计算梯度时会出现冗余，而SGD一次只进行单样本更新，所以针对一次更新来说没有冗余，而且速度快<br><strong>缺点</strong>：更新频繁，造成loss函数严重震荡。  </p><p> BGD可以收敛到局部最小值，SGD的震荡也可能跳到更优的局部最小值。稍微减少learning rate，SGD和BGD收敛性一致，对凸函数和非凸函数能分别收敛到全局最优和局部最优。 </p><h3 id="3-小批量梯度下降Mini-batch-Stochastic-gradient-descent"><a href="#3-小批量梯度下降Mini-batch-Stochastic-gradient-descent" class="headerlink" title="3.小批量梯度下降Mini-batch Stochastic gradient descent"></a><strong>3.小批量梯度下降Mini-batch Stochastic gradient descent</strong></h3><p><strong>梯度更新规则</strong>：每一次更新使用一小批样本进行更新</p><p>和 SGD 的区别是每一次循环不是作用于每个样本，而是具有 n 个样本的批次。</p><p>优点：降低参数更新时的方差，收敛更稳定；可利用深度学习库中高度优化的矩阵操作来更有效的梯度计算<br><strong>缺点：</strong>MBSGD不能保证很好的收敛性，提供了一系列的挑战需要去解决：<br>1.选择合适的学习率十分困难。如果选择太小，收敛速度太慢；如果太大，loss函数会在极小值出震荡甚至发散。<br>2.学习率在训练过程中退火调整，学习率的减少根据提前确定好的计划或者当目标在两个轮次之间的变化低于一个阈值，计划和阈值必须要提前确定，因此不能适应数据集的特征。<br>3.对所有参数更新时应用同样的学习率，如果数据是稀疏的，更希望对出现频率低的特征进行大一点的更新。<br>4.对于非凸的误差函数，要避免陷入局部极小值以及鞍点处。鞍点周围的梯度都一样并且趋近于0，SGD不容易突破。</p><h3 id="4-含有动量的随机梯度下降法SGD-with-momentum"><a href="#4-含有动量的随机梯度下降法SGD-with-momentum" class="headerlink" title="4.含有动量的随机梯度下降法SGD with momentum"></a><strong>4.含有动量的随机梯度下降法SGD with momentum</strong></h3><p>SGD在山谷的情况下不容易导向，会多走一些弯路，山谷的曲面在某一个参数维度会比另外一个参数维度更陡峭，这种情况在局部最优解附近很常见。在这种场景下，SGD穿过山谷的斜坡时会震荡。 </p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630378142301.png" alt="1630378142301"></p><p>momentum能帮助加速SGD在确定方向的下降并且抑制震荡。<br>超参数一般设为0.9左右，意味着参数更新方向不仅由当前梯度决定，也与此前累计的下降方向有关，这使得momentum会增加更新某个维度下降方向不变的梯度，减少更新某个维度下降方向改变的梯度。因此获得了更快的收敛性和减少了震荡。</p><h3 id="5-AdaGrad"><a href="#5-AdaGrad" class="headerlink" title="5.AdaGrad"></a>5.AdaGrad</h3><p>针对SGD及Momentum存在的问题，2011年John Duchi等发布了AdaGrad（Adaptive Gradient，自适应梯度）优化算法，<strong>能够对每个不同参数调整不同的学习率，对频繁变化的参数以更小的步长进行更新，而稀疏的参数以更大的步长更新。</strong>对稀疏的数据表现很好，提高了SGD的鲁棒性。<br><strong>优点：</strong>能够为不同参数应不同的学习率，大多数学习率（<strong>η</strong>）使用0.01为默认值可实现较好的效果。<br><strong>缺点：</strong>分母项对梯度平方进行不断的累加，分母项越来越大，最终学习率收缩到无穷小使得无法进行有效更新。 </p><h3 id="6-Adadelta-RMSProp"><a href="#6-Adadelta-RMSProp" class="headerlink" title="6.Adadelta/RMSProp"></a>6.Adadelta/RMSProp</h3><p>为了解决AdaGrad单调递减的学习率急速下降的问题，考虑一个改变二阶动量计算方法的策略：不累积全部梯度，而只关注过去一段时间窗口的下降梯度，这就是delta中的来历。<br>采用计算梯度的指数移动平均数（Exponential Moving Average） ， 这个算法是对 Adagrad 的改进， </p><h3 id="7-Adam"><a href="#7-Adam" class="headerlink" title="7.Adam"></a><strong>7.Adam</strong></h3><p>可以认为是RMSprop和Momentum的结合。对一阶动量和二阶动量都采用指数移动平均计算。<br>默认为0.9,默认为0,999。在迭代初始阶段，和有一个向初值的偏移（过多偏向0），因此需要对一阶和二阶动量进行偏置校正（bias correction） </p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630378505616.png" alt="1630378505616"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;填充和归一化&quot;&gt;&lt;a href=&quot;#填充和归一化&quot; class=&quot;headerlink&quot; title=&quot;填充和归一化&quot;&gt;&lt;/a&gt;填充和归一化&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A</summary>
      
    
    
    
    <category term="深度学习（第一层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="代码解读（第二层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>Residual Attention Network</title>
    <link href="http://example.com/2021/08/04/Residual%20Attention%20Network/"/>
    <id>http://example.com/2021/08/04/Residual%20Attention%20Network/</id>
    <published>2021-08-04T04:16:21.000Z</published>
    <updated>2021-09-04T04:03:09.185Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1、论文全名-—-Residual-Attention-Network-for-Image-Classification"><a href="#1、论文全名-—-Residual-Attention-Network-for-Image-Classification" class="headerlink" title="1、论文全名 — Residual Attention Network for Image Classification"></a>1、论文全名 — Residual Attention Network for Image Classification</h1><h1 id="2、-emsp-整体结构"><a href="#2、-emsp-整体结构" class="headerlink" title="2、&emsp;整体结构"></a>2、&emsp;整体结构</h1><p><img src="/2021/08/04/Residual%20Attention%20Network/1628056822799.png" alt="1628056822799"></p><p>左图:一个例子展示了特征和注意力面具之间的相互作用。</p><p>右图:举例说明在我们的网络中，不同的特征有不同的对应注意面具。</p><p><img src="/2021/08/04/Residual%20Attention%20Network/1628066487666.png" alt="1628066487666"></p><center>软掩码分支结构</center>&emsp;&emsp;&emsp;掩码分支包含**快速前馈扫描**和**自上而下的反馈**步骤。**前者快速采集整幅图像的全局信息，后者将全局信息与原始特征图相结合**。在卷积神经网络中，这两个步骤展开为自下而上、自上而下的全卷积结构。从输入来看，在少量剩余单位后，**进行几次最大池化以快速增加感受野**。在达到最低分辨率后，全局信息通过**对称**的自上而下架构进行扩展，以指导每个位置的输入特征。**线性插值在一些残差单位后向上采样输出**。**双线性插值的数量与最大池化相同，以保持输出大小与输入要素图相同**。然后，连续两个1 × 1卷积层后，sigmoid层对输出进行归一化，范围为[0，1]。我们还在自下而上和自上而下的零件之间添加了跳跃连接，以从不同的比例捕获信息。<p><img src="/2021/08/04/Residual%20Attention%20Network/1628065657226.png" alt="1628065657226"></p><center>残差注意力网络结构</center>超参数p表示在分成主干分支和掩码分支**之前预处理剩余单元的数量**。t表示**主干分支**中剩余单元的数量。r表示**掩码分支**中相邻汇集层之间的剩余单元数。<center>软掩码分支结构</center># 3、 残差注意力网络分析<p>我们的剩余注意力网络是通过堆叠多个注意力模块构建的。每个注意模块分为两个分支:掩码分支和主干分支。主干分支执行特征处理，并且可以适应任何最先进的网络结构。</p><p>使用pre-activation Residual Unit、ResNeXt 和Inception 作为剩余注意网络的基本单元来构建注意模块</p><h2 id="3-1-emsp-注意力剩余学习"><a href="#3-1-emsp-注意力剩余学习" class="headerlink" title="3.1&emsp;注意力剩余学习"></a>3.1&emsp;注意力剩余学习</h2><p>给定输入为x的主干分支输出T(x)，掩码分支使用自下而上自上而下的结构来学习相同大小的掩码M(x)，该掩码对输出特征T(x)进行软加权。</p><p>注意模块H的输出为：     &emsp;&emsp;&emsp;&emsp;</p><img src="/2021/08/04/Residual%20Attention%20Network/1628066609969.png" alt="1628066609969"><p>在Attention Modules 中，attention mask不仅可以在前向推理过程中充当特征选择器，还可以在反向传播过程中充当梯度更新过滤器。在软遮罩分支中，输入要素的遮罩梯度为:</p><p><img src="/2021/08/04/Residual%20Attention%20Network/1628129507416.png" alt="1628129507416"></p><p>θ是掩码分支参数，φ是主干分支参数。此属性使注意力模块对有噪声的标签具有鲁棒性。遮罩分支可以防止错误的渐变(来自有噪声的标签)来更新主干参数。</p><h2 id="3-2-emsp-软掩码分支（Soft-Mask-Branch）"><a href="#3-2-emsp-软掩码分支（Soft-Mask-Branch）" class="headerlink" title="3.2&emsp;软掩码分支（Soft Mask Branch）"></a>3.2&emsp;软掩码分支（Soft Mask Branch）</h2><p>掩码分支目的是改进主干分支特征，而不是直接解决复杂的问题</p><p><img src="/2021/08/04/Residual%20Attention%20Network/1628131500040.png" alt="1628131500040"></p><center>掩蔽分支和主干分支的感受野比较</center>注意力模块的输出修改为：&emsp;&emsp;&emsp;<p><img src="/2021/08/04/Residual%20Attention%20Network/1628130312831.png" alt="1628130312831"></p><p><img src="/2021/08/04/Residual%20Attention%20Network/1628130471469.png" alt="1628130471469" style="zoom:85%;">是由深度卷积网络生成的特征mask分支M(x)，它们充当特征选择器，增强好的特征并抑制来自主干特征的噪声。</p><h2 id="3-3-emsp-遮罩分支提供的注意力随着主干分支特征而自适应地改变"><a href="#3-3-emsp-遮罩分支提供的注意力随着主干分支特征而自适应地改变" class="headerlink" title="3.3&emsp;遮罩分支提供的注意力随着主干分支特征而自适应地改变"></a>3.3&emsp;遮罩分支提供的注意力随着主干分支特征而自适应地改变</h2><p><img src="/2021/08/04/Residual%20Attention%20Network/1628133676240.png" alt="1628133676240"></p><p>xi表示第I个空间位置的特征向量。I在所有空间位置范围内，c在所有通道范围内</p><p>无附加限制的混合注意f1对每个通道和空间位置使用简单的sigmoid。</p><p>通道注意力f2在所有通道内对每个空间位置执行L2归一化，以去除空间信息。</p><p>空间注意力f3在来自每个通道的特征图内执行标准化，然后sigmoid以获得仅与空间信息相关的软掩模。</p><h1 id="4、-emsp-总结"><a href="#4、-emsp-总结" class="headerlink" title="4、&emsp;总结"></a>4、&emsp;总结</h1><p>普通注意力模型的缺点：</p><p>1、<strong>具有杂乱背景、复杂场景和大的外观变化的图像需要通过不同类型的关注来建模</strong>。在这种情况下，来自不同层的特征需要由不同的注意力遮罩来建模。使用单个掩码分支将需要指数数量的通道来捕获不同因素的所有组合。</p><p>2、<strong>单个注意模块只修改一次特征。如果映像的某些部分修改失败，以下网络模块将没有第二次机会。</strong></p><p><strong>本文提出的残余注意力网络缓解了上述问题</strong>。在注意力模块中，每个主干分支都有自己的掩码分支来学习专门针对其特征的注意力。</p><p><strong>1.堆叠网络结构:我们的剩余注意力网络是通过堆叠多个注意力模块来构建的。不同类型的注意力能够在不同的注意力模块中被捕获。改变 f（x）即可</strong></p><p><strong>2.整个soft mask branch 才是重点，输出的M当做残差加一以后再去卷积主干的特征</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1、论文全名-—-Residual-Attention-Network-for-Image-Classification&quot;&gt;&lt;a href=&quot;#1、论文全名-—-Residual-Attention-Network-for-Image-Classification</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="论文阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="注意力模型（第三层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B%EF%BC%88%E7%AC%AC%E4%B8%89%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="注意力模型" scheme="http://example.com/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>MUNIT</title>
    <link href="http://example.com/2021/08/03/MUNIT/"/>
    <id>http://example.com/2021/08/03/MUNIT/</id>
    <published>2021-08-03T08:45:44.000Z</published>
    <updated>2021-09-04T04:02:13.894Z</updated>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer">  <h1 id="1、论文全名-—-Multimodal-Unsupervised-Image-to-Image-Translation"><a href="#1、论文全名-—-Multimodal-Unsupervised-Image-to-Image-Translation" class="headerlink" title="1、论文全名 — Multimodal Unsupervised Image-to-Image Translation"></a>1、论文全名 — Multimodal Unsupervised Image-to-Image Translation</h1><h1 id="emsp-emsp-多模态无监督图像到图像翻译"><a href="#emsp-emsp-多模态无监督图像到图像翻译" class="headerlink" title="&emsp;&emsp;(多模态无监督图像到图像翻译)"></a>&emsp;&emsp;(多模态无监督图像到图像翻译)</h1><h1 id="2、整体结构"><a href="#2、整体结构" class="headerlink" title="2、整体结构"></a>2、整体结构</h1><p><img src="/2021/08/03/MUNIT/1627986033107.png" alt="1627986033107"></p><p><img src="/2021/08/03/MUNIT/1627980504738.png" alt="1627980504738"></p><h1 id="3、过程"><a href="#3、过程" class="headerlink" title="3、过程"></a>3、过程</h1><p>&emsp;&emsp;如图1 (a)所示，我们的框架做了几个假设。我们首先假设图像的潜在空间可以分解为内容空间C和风格空间S。我们进一步假设不同领域的图像共享一个共同的内容空间，但不共享样式空间。为了将图像翻译到目标域，我们将其内容代码与目标样式空间中的随机样式代码重新组合(图1(b))。</p><p>&emsp;&emsp;内容代码对翻译过程中应该保留的信息进行编码，而样式代码表示输入图像中不包含的其余变体。通过采样不同的风格代码，我们的模型能够产生不同的多模态输出。</p><p><img src="/2021/08/03/MUNIT/1627981675082.png" alt="1627981675082"></p><p>&emsp;&emsp;如图2(a)所示，每个自动编码器的潜在代码被分解成内容代码ci和样式代码si。如图2(b)所示，通过交换编码器-解码器对来执行图像到图像的转换。</p><p>&emsp;&emsp;为了将图像x1∈x1翻译成X2，我们首先提取其内容潜在代码<img src="/2021/08/03/MUNIT/1627982033272.png" alt="1627982033272" style="zoom:60%;">，并从先验分布<img src="/2021/08/03/MUNIT/1627982067523.png" alt="1627982067523" style="zoom:50%;">中随机绘制一个风格潜在代码s2。然后，我们使用G2产生最终输出图像<img src="/2021/08/03/MUNIT/1627982112763.png" alt="1627982112763" style="zoom:60%;">。</p><h2 id="4、损失函数设计"><a href="#4、损失函数设计" class="headerlink" title="4、损失函数设计"></a>4、损失函数设计</h2><h2 id="4-1-emsp-双向重建损失"><a href="#4-1-emsp-双向重建损失" class="headerlink" title="4.1&emsp;双向重建损失"></a>4.1&emsp;双向重建损失</h2><p><strong>图像重建损失:</strong> </p><p><img src="/2021/08/03/MUNIT/1627986277230.png" alt="1627986277230"></p><p><strong>潜在的重建损失：</strong>（内容重建损失和风格重建损失）</p><p><img src="/2021/08/03/MUNIT/1627986328694.png" alt="1627986328694"></p><p>在给定不同风格代码的情况下，风格重建损失具有鼓励不同输出的效果，内容重构损失重新鼓励翻译图像以保留输入图像的语义内容。</p><h2 id="4-2-emsp-对抗损失"><a href="#4-2-emsp-对抗损失" class="headerlink" title="4.2&emsp;对抗损失"></a>4.2&emsp;对抗损失</h2><p>先验分布<img src="/2021/08/03/MUNIT/1627987418253.png" alt="1627987418253" style="zoom:50%;">，边缘分布p(x）</p><p><img src="/2021/08/03/MUNIT/1627986915469.png" alt="1627986915469"></p><h2 id="4-3-emsp-总损失"><a href="#4-3-emsp-总损失" class="headerlink" title="4.3&emsp;总损失"></a>4.3&emsp;总损失</h2><img src="/2021/08/03/MUNIT/1627987289574.png" alt="1627987289574" style="zoom:75%;"><img src="/2021/08/03/MUNIT/1627987296909.png" alt="1627987296909" style="zoom:75%;"><h1 id="5、总结"><a href="#5、总结" class="headerlink" title="5、总结"></a>5、总结</h1><p>&emsp;&emsp;<strong>网络设计有点复杂，思路很容易理解。将图片分成风格编码器和内容编码器，然后拆开编码，最后再进行组合，同一个内容可以混合不同的风格。设计损失函数的时候也有重建风格损失，重建内容损失。</strong></p><hr>]]></content>
    
    
      
      
    <summary type="html"> &lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;  

&lt;h1 id=&quot;1、论文全名-—-Multimodal-Unsupervised-Image-to-Image-Translation&quot;&gt;&lt;a href=&quot;#1、论文全名-—-Mul</summary>
      
    
    
    
    <category term="GAN（第一层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="论文阅读（第二层级）" scheme="http://example.com/categories/GAN%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN，论文阅读" scheme="http://example.com/tags/GAN%EF%BC%8C%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>lllllcy</title>
  
  <subtitle>2020.7</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-09-03T08:31:05.798Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>George</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>有三AI文章阅读10---详解一致优化</title>
    <link href="http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/"/>
    <id>http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB10/</id>
    <published>2021-09-03T08:20:00.000Z</published>
    <updated>2021-09-03T08:31:05.798Z</updated>
    
    <content type="html"><![CDATA[<h1 id="—–剩下几篇太难、明天再仔细看…"><a href="#—–剩下几篇太难、明天再仔细看…" class="headerlink" title="—–剩下几篇太难、明天再仔细看…"></a>—–剩下几篇太难、明天再仔细看…</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;—–剩下几篇太难、明天再仔细看…&quot;&gt;&lt;a href=&quot;#—–剩下几篇太难、明天再仔细看…&quot; class=&quot;headerlink&quot; title=&quot;—–剩下几篇太难、明天再仔细看…&quot;&gt;&lt;/a&gt;—–剩下几篇太难、明天再仔细看…&lt;/h1&gt;</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN训练" scheme="http://example.com/tags/GAN%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读9---几个训练小技巧</title>
    <link href="http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/"/>
    <id>http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/</id>
    <published>2021-09-03T07:47:00.000Z</published>
    <updated>2021-09-03T08:22:03.145Z</updated>
    
    <content type="html"><![CDATA[<p>今天这篇小文将从博弈论的角度出发来审视一下GAN训练时的问题，并给出了3个稳定训练的小技巧。 </p><h2 id="1-博弈论与GAN"><a href="#1-博弈论与GAN" class="headerlink" title="1. 博弈论与GAN"></a>1. 博弈论与GAN</h2><p>先从博弈论的角度来重新描述GAN模型。游戏中有两个玩家：D（判别器）和G（生成器），D试图在判别器的参数空间上寻找最好的解使得它的损失函数最小：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630655364940.svg" alt="[公式]"></p><p>G也试图在生成器的参数空间上寻找最好的解使得它的损失函数最小：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation.svg" alt="[公式]"></p><p>需要说明，D和G并不是彼此独立的，对于GAN，整个博弈是“交替进行决策”的。例如先确定生成器G的参数，则D会在给定的G的参数的条件下更新判别器的参数以此最小化D的损失函数，如下面中蓝线过程（提升D的辨别能力）；接着G会在给定的D的参数的条件下更新判别器的参数以此来最小化G的损失函数，如下面中绿线过程（提升G的生成能力）……直到达到一个稳定的状态：纳什均衡。</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/1630655383491.png" alt="1630655383491" style="zoom: 67%;"><p>在纳什均衡点，两者的参数到达一种“制衡”状态。在给定G的参数情况下，D当前的参数便对应了D损失函数的最小值，同样在给定D的参数情况下，G当前的参数便对应了G损失函数的最小值，也就是说在交替更新过程中，D和G均不可能单独做出任何改变。</p><p>解空间中可能存在多个纳什均衡点，而且纳什均衡点并不意味着全局最优解，但是是一种经过多次博弈后的稳定状态，所以说<strong>GAN的任务是并非寻找全局最优解，而是寻找一个纳什均衡状态，损失函数收敛即可</strong>。在损失函数非凸、参数连续、参数空间维度很高的情况下，不可能通过严格的数学计算去更新参数从而找到纳什均衡，在GAN中，每次参数更新（对应蓝线、绿线表示的过程）使用的是梯度下降法；另外，每次D或者G对自身参数更新都会减少自身的损失函数同时加大对方的损失函数，这导致了寻找GAN的纳什均衡是比较困难的。</p><p><strong>针对于GAN训练的收敛性问题，我们接下来将介绍几种启发式的技巧。</strong></p><h2 id="2-特征匹配"><a href="#2-特征匹配" class="headerlink" title="2. 特征匹配"></a>2. 特征匹配</h2><p>在GAN中，<strong>判别器D输出一个0到1之间的标量表示接受的样本来源于真实数据集的概率</strong>，而<strong>生成器的训练目标就是努力使得该标量值最大</strong>。如果从特征匹配(feature matching)的角度来看，整个判别器D(x)由两部分功能组成，先通过前半部分f(x)提取到样本的抽象特征，后半部分的神经网络根据抽象特征进行判定分类，即</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/v2-e36ec9a4f13c36a22ae88ce9a1844580_720w.jpg" alt="img" style="zoom:50%;"><p>f(x)表示判别器中截止到中间某层神经元激活函数的输出。在训练判别器时，我们试图找到一种能够区分两类样本的特征提取方式f(x)，而在训练生成器的时候，我们可以不再关注D(x)的概率输出，我们可以关注：<strong>从生成器生成样本的中用f(x)提取的抽象特征是否与在真实样本中用f(x)提取的抽象特征相匹配</strong>，另外，为了匹配这两个抽象特征的分布，考虑其一阶统计特征：均值，即可将生成器的目标函数改写为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862789.svg" alt="[公式]"></p><p>采用这样的方式，我们可以让生成器不过度训练，让训练过程相对稳定一些。</p><h2 id="3-历史均值"><a href="#3-历史均值" class="headerlink" title="3. 历史均值"></a>3. 历史均值</h2><p>历史均值(historical averaging)是一个非常简单方法，就是在生成器或者判别器的<strong>损失函数中添加一项</strong>：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862874.svg" alt="[公式]"></p><p><strong>这样做使得判别器或者生成器的参数不会突然产生较大的波动</strong>，直觉上看，在快要达到纳什均衡点时，参数会在纳什均衡点附近不断调整而不容易跑出去。这个技巧在处理低维问题时确实有助于进入纳什均衡状态从而使损失函数收敛， <font color="red"><strong>但是GAN中面临的是高维问题，助力可能有限。</strong></font>  </p><h2 id="4-单侧标签平滑—————-没看懂"><a href="#4-单侧标签平滑—————-没看懂" class="headerlink" title="4.单侧标签平滑—————-没看懂"></a>4.单侧标签平滑—————-没看懂</h2><p>标签平滑(label smoothing)方法最开始在1980s就提出过，它在分类问题上具有非常广泛的应用，主要是为了解决过拟合问题。一般的，我们的分类器最后一层使用softmax层输出分类概率（Sigmoid只是softmax的特殊情况），我们用二分类softmax函数来说明一下标签平滑的效果。</p><p>对于给定的样本x，其类别为1，则标签为[1,0]，如果不用标签平滑，只使用“硬”标签，其交叉熵损失函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862866.svg" alt="[公式]"></p><p>这时候通过最小化交叉熵损失函数来训练分类器，本质上是使得：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862941.svg" alt="[公式]"> </p><p>其实也就是使得：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862790.svg" alt="[公式]"></p><p>对于给定的样本x，使z1的值无限大（当然这在实际中是不可能的）而使z2趋于0，无休止拟合该标签1，便产生了过拟合、降低了分类器的泛化能力。如果使用标签平滑手段，对给定的样本x，其类别为1，例如平滑标签为[1-ε ,ε]，交叉损失函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862813.svg" alt="[公式]"></p><p>当损失函数达到最小值时，有：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862801.svg" alt="[公式]"></p><p>选择合适的参数，理论上的最优解z1与z2存在固定的常数差值（此差值由ε决定），便不会出现z1无限大，远大于z2的情况了。 如果将此技巧用在GAN的判别器中，即对生成器生成的样本输出概率值0变为β ，则生成器生成的单样本交叉熵损失函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862835.svg" alt="[公式]"></p><p>而对数据集中的样本打标签由1降为α，则数据集中的单样本交叉熵损失函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862834.svg" alt="[公式]"></p><p>总交叉损失函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862834.svg" alt="[公式]"></p><p>其最优解D(x)为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB9/equation-1630656862933.svg" alt="[公式]"></p><p>实际训练中，有大量这样的x：其在训练数据集中概率分布为0，而在生成器生成的概率分布不为0，他们经过判别器后输出为β。为了能迅速“识破”该样本，最好将β降为0，这就是所谓的单侧标签平滑。</p><p>训练GAN时，我们对它的要求并不是找到全局最优解，能进入一个纳什均衡状态、损失函数收敛就可以了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;今天这篇小文将从博弈论的角度出发来审视一下GAN训练时的问题，并给出了3个稳定训练的小技巧。 &lt;/p&gt;
&lt;h2 id=&quot;1-博弈论与GAN&quot;&gt;&lt;a href=&quot;#1-博弈论与GAN&quot; class=&quot;headerlink&quot; title=&quot;1. 博弈论与GAN&quot;&gt;&lt;/a&gt;1. </summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN训练" scheme="http://example.com/tags/GAN%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读8---GAN训练遇到的问题</title>
    <link href="http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/"/>
    <id>http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/</id>
    <published>2021-09-03T07:19:00.000Z</published>
    <updated>2021-09-03T07:48:14.935Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-梯度消失问题"><a href="#1-梯度消失问题" class="headerlink" title="1.梯度消失问题"></a>1.梯度消失问题</h2><p>在早期的GAN中，有一条经验：<strong>不要把判别器训练得太好，以避免后期梯度消失导致无法训练生成器</strong>。在第三期中，我们曾谈论过类似的问题，只不过是从f-divergence的角度来探讨的，简而言之，判别器的任务是辅助学习数据集的本质概率分布和生成器定义的隐式概率分布之间的某种距离，生成器的任务是使该距离达到最小。<strong>当两个概率分布没有重合或者重合部分可忽略时，其f散度值为常数；当两者完全重合时，f散度值突变成0</strong>，<strong>f散度距离无法为生成器提供可以减少损失函数的梯度信息，生成器无法训练获得优化方向。</strong></p><p>这次我们从GAN的训练过程的角度再一次来谈论这个问题。通过理论和大量的实践，我们几乎可以认为数据集的本质概率分布和生成器定义的隐式概率分布均是高维数据空间中的低维流形，几乎不存在重叠部分（重叠部分测度为0），可以证明此时必然存在一个最优判别器D*可以将两个分布完全分开，它在数据集的分布上置1而在生成分布上置0，即：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630653729743.svg" alt="[公式]"></p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630653729736.svg" alt="[公式]"></p><p>而且在x的邻域内，其导数为0，即</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation.svg" alt="[公式]"></p><p>此时，我们无法使用反向传播算法来使生成器进行学习，因为我们可以证明出：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630653729714.svg" alt="[公式]"></p><p>即不断训练判别器D(x)使其逼近最优判别器的代价是：梯度消失！生成器无法获得任何信息来进行更新，两个分布之间的距离并没有被缩小，整个迭代过程变成无用的循环过程。</p><h2 id="2-采样计算距离问题"><a href="#2-采样计算距离问题" class="headerlink" title="2.采样计算距离问题"></a>2.采样计算距离问题</h2><p>WGAN是解决上述梯度消失问题的一个好办法， 现在我们来看在实际训练GAN时候的第二个问题：</p><p>首先来看一个小例子，我们定义一个标准的正态分布：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295100.svg" alt="[公式]"></p><p>从该分布中采样出m个样本组成一个均匀分布：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295108.svg" alt="[公式]"></p><p>那么可以有一个结论：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295102.svg" alt="[公式]"></p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295110.svg" alt="[公式]"></p><p>也就是说，在有限个采样个数的情况下（实际中样本数m足够大是不可能成立的），均匀分布的样本并不能等同于源分布，两者还有一定的“距离”。那么对于两个正态分布，很可能“采样”分布之间距离并不等于两个分布之间的真实距离。</p><p>实际的结论确实如此：对于两个标准正态分布  <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654345451.svg" alt="[公式]">   和 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295222.svg" alt="[公式]"> 以及两个分别从中采样得到的样本的均匀分布 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295182.svg" alt="[公式]"> 和 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295256.svg" alt="[公式]"> ，有非常大的概率认为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295135.svg" alt="[公式]"></p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295137.svg" alt="[公式]"></p><p>在GAN中，我们也是通过采样来近似计算分布之间的距离的，最理想下状态，两个概率分布之间的距离等于两个“采样”分布的距离，或者相差很小：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654295153.svg" alt="[公式]"></p><p>但考虑到上述简单的正态分布的例子中尚且存在这样的问题，<strong>有理由认为在GAN中，依靠采样来估计的分布之间的距离并不等于两个分布的真实的距离</strong>。如果生成器接受到的距离信息是有偏差的，则很可能无法将生成器定义的隐式概率分布逼近到数据集的本质概率分布。</p><h2 id="3-minmax问题"><a href="#3-minmax问题" class="headerlink" title="3.minmax问题"></a>3.minmax问题</h2><p>GAN的理想训练模式是这样的：固定生成器G，迭代k次训练判别器D；然后固定判别器D，训练生成器G，两者依次交替使用梯度下降法进行更新。这里会造成一种困惑，我们到底是在解决一个minmax问题还是maxmin问题？而且，通常情况下：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654521104.svg" alt="[公式]"></p><p>在maxmin的角度来看，<strong>GAN的训练过程会产生mode collapse问题，就是指生成器生成的样本有大量的重复，多样性非常差</strong>（这是一个在实践中经常出现的问题，在之后的文章中，我们将花许多精力来介绍mode collapse问题的解决方案）。</p><p>真实数据集的本质概率密度函数通常是多峰函数，也就是具有很多模式(mode)，我们用一个非常简洁、极端的例子来说明一下。假设真实数据集的本质概率密度函数有3个峰。首先，对于固定的判别器D，生成器面临min问题，会努力将概率集值中放置到一个或几个高概率的点(mode)上，例如x=5.0，希望以这种“偷懒”的方式来欺骗判别器D。</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/v2-6318f833259542cc0089d09a13811873_720w.jpg" alt="img" style="zoom:80%;"><p>对判别器进行更新，根据最优判别器的表达式：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/equation-1630654521123.svg" alt="[公式]" style="zoom: 80%;"><p>更新后D(x)为：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/1630654845573.png" alt="1630654845573" style="zoom: 80%;"><p>可以看出，训练后的D会对x=5.0及其周围点的“极其不信任”。接下来再更新生成器时，为了取得最小值，生成器会将概率放置到其他的高概率的、判别器信任的点(mode)上，例如x=0，即：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB8/v2-70a2dfe00801e1aea42ba44f73a2611b_720w.jpg" alt="img" style="zoom:80%;"><p>再次更新判别器D(x)，其函数图像为：</p><p><img src="https://pic4.zhimg.com/80/v2-0a8d650d974ffc2f522006115df9583b_720w.jpg" alt="img"></p><p>这时判别器识别降低了x=0的信任程度，但是同时又恢复了对x=5.0的信任程度，那么接下来再更新生成器时，生成器其又会将高概率点放置在x=-5.0或者x=5.0的点周围······</p><p><strong>在实践中，我们发现生成器往往不能包涵所有的mode，通常只包含一个或几个mode。在训练过程中，生成器的概率放置不断地从一个mode转换到另一个mode中。</strong></p><h2 id="4-参数空间与函数空间问题"><a href="#4-参数空间与函数空间问题" class="headerlink" title="4.参数空间与函数空间问题"></a>4.参数空间与函数空间问题</h2><p>理论上，GAN确实可以收敛，但是该优化过程是在函数空间中完成的。实践操作中，我们的优化操作是在参数空间中进行的，理论上的保证在现实中并不成立。对于有限个参数的判别器，GAN的平衡状态很可能是不存在的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-梯度消失问题&quot;&gt;&lt;a href=&quot;#1-梯度消失问题&quot; class=&quot;headerlink&quot; title=&quot;1.梯度消失问题&quot;&gt;&lt;/a&gt;1.梯度消失问题&lt;/h2&gt;&lt;p&gt;在早期的GAN中，有一条经验：&lt;strong&gt;不要把判别器训练得太好，以避免后期梯度消失导致</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN训练" scheme="http://example.com/tags/GAN%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读7---IPM与xGAN</title>
    <link href="http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/"/>
    <id>http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/</id>
    <published>2021-09-03T06:19:00.000Z</published>
    <updated>2021-09-03T08:02:46.446Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-IPM（积分概率度量）"><a href="#1-IPM（积分概率度量）" class="headerlink" title="1.IPM（积分概率度量）"></a>1.IPM（积分概率度量）</h2><p> IPM  (integral probability metric)  是一种对于两个概率分布之间的距离的度量。在IPM技术中，首先定义了满足某种限制条件的某一类函数的集合F，然后寻找一个最优的f(x)∈F使得两个分布之间的差异最大，该最大的差异值即为两个分布之间的距离： </p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630650157961.svg" alt="[公式]"></p><p>这里要求 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation.svg" alt="[公式]"> 是可测、有界的实值函数，且函数空间 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630650157951.svg" alt="[公式]"> 是对称的。</p><p>正是由于不同的 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630650157951.svg" alt="[公式]"> ，决定了两种分布之间的各种各样的距离度量以及他们的性质。这点与f-divergence很像，例如在WGAN中：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation.svg" alt="[公式]"> WGAN将判别器函数限定为满足1-Lipschitz条件，则对应了Wasserstein距离：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630650157846.svg" alt="[公式]"></p><p>另外需要说明，这样定义的距离度量虽然满足对称性、非负性、三角不等式，但是当该距离为0时，并不能严格证明两个分布相等，故为一种伪度量。</p><p>在这样的框架下，GAN的判别器(critic)的<strong>先学习某种两个分布之间的距离</strong>，其目标函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630650157973.svg" alt="[公式]"></p><p>接着，优化生成器使得该距离最小：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630650158006.svg" alt="[公式]"></p><h2 id="2-IPM-vs-f-divergence"><a href="#2-IPM-vs-f-divergence" class="headerlink" title="2. IPM vs f-divergence"></a>2. IPM vs f-divergence</h2><p><strong>一般在生成模型中，往往先计算生成模型的概率分布和真实数据集的概率分布之间的距离，再以此距离作为目标函数来训练生成模型。而在GAN的框架中，需要先利用数学技巧将距离转化成可以通过采样来计算的形式，再使用神经网络（也就是判别器）来帮助逼近两个概率分布的距离，最后距离作为目标函数来训练生成模型。</strong></p><p>GAN中的概率分布之间的距离度量大概分为两类，在f-divergence中，通过<strong>选择不同的f(x)来制造不同的GAN</strong>：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630651872059.svg" alt="[公式]"></p><p>在IPM中，通过选择不同的函数空间来制造不同的GAN：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630651872070.svg" alt="[公式]"></p><p>正如之前所说，f-divergence的问题是：随着数据空间维数增加，距离难以计算；由于两个概率分布的支撑集未对齐，会出现无穷值。而IPM定义的距离，数学性质更好，其值并不受数据维度的影响。</p><hr><h2 id="个人对GAN理解："><a href="#个人对GAN理解：" class="headerlink" title="个人对GAN理解："></a>个人对GAN理解：</h2><h4 id="1-GAN有一个生成器一个判别器，判别器的作用是在高维概率密度空间寻找两个概率分布的距离，生成器的作用是生成一种概率分布去逼近真实的概率分布。"><a href="#1-GAN有一个生成器一个判别器，判别器的作用是在高维概率密度空间寻找两个概率分布的距离，生成器的作用是生成一种概率分布去逼近真实的概率分布。" class="headerlink" title="1.GAN有一个生成器一个判别器，判别器的作用是在高维概率密度空间寻找两个概率分布的距离，生成器的作用是生成一种概率分布去逼近真实的概率分布。"></a>1.GAN有一个生成器一个判别器，判别器的作用是在高维概率密度空间寻找两个概率分布的距离，生成器的作用是生成一种概率分布去逼近真实的概率分布。</h4><h4 id="2-虽然图片在高维空间是一个点、但是在比它低一个维度的空是由很多的点组成，而不是单独一个点。例如三维空间一个点对应二维空间是一个平面。"><a href="#2-虽然图片在高维空间是一个点、但是在比它低一个维度的空是由很多的点组成，而不是单独一个点。例如三维空间一个点对应二维空间是一个平面。" class="headerlink" title="2.虽然图片在高维空间是一个点、但是在比它低一个维度的空是由很多的点组成，而不是单独一个点。例如三维空间一个点对应二维空间是一个平面。"></a>2.虽然图片在高维空间是一个点、但是在比它低一个维度的空是由很多的点组成，而不是单独一个点。例如三维空间一个点对应二维空间是一个平面。</h4><h4 id="3-G和D两者，个人觉得D是最重要的核心、D决定了什么类型的距离、什么类型的概率空间。D更新一次、G更新好几次。"><a href="#3-G和D两者，个人觉得D是最重要的核心、D决定了什么类型的距离、什么类型的概率空间。D更新一次、G更新好几次。" class="headerlink" title="3.G和D两者，个人觉得D是最重要的核心、D决定了什么类型的距离、什么类型的概率空间。D更新一次、G更新好几次。"></a>3.G和D两者，个人觉得D是最重要的核心、D决定了什么类型的距离、什么类型的概率空间。D更新一次、G更新好几次。</h4><h4 id="4-D和G并是独立训练的，所以几乎不会生成完全相同的数据分布。"><a href="#4-D和G并是独立训练的，所以几乎不会生成完全相同的数据分布。" class="headerlink" title="4.D和G并是独立训练的，所以几乎不会生成完全相同的数据分布。"></a>4.D和G并是独立训练的，所以几乎不会生成完全相同的数据分布。</h4><p>GAN中的概率分布之间的距离度量大概分为两类，在f-divergence中，通过<strong>选择不同的f(x)来制造不同的GAN</strong>：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630651872059.svg" alt="[公式]"></p><p>在IPM中，通过选择不同的函数空间来制造不同的GAN：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB7/equation-1630651872070.svg" alt="[公式]"></p><h2 id="IPM太复杂、、了解即可，具体使用到了再看一遍。"><a href="#IPM太复杂、、了解即可，具体使用到了再看一遍。" class="headerlink" title="IPM太复杂、、了解即可，具体使用到了再看一遍。"></a>IPM太复杂、、了解即可，具体使用到了再看一遍。</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-IPM（积分概率度量）&quot;&gt;&lt;a href=&quot;#1-IPM（积分概率度量）&quot; class=&quot;headerlink&quot; title=&quot;1.IPM（积分概率度量）&quot;&gt;&lt;/a&gt;1.IPM（积分概率度量）&lt;/h2&gt;&lt;p&gt; IPM  (integral probabilit</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读6---奇异值和SNGAN</title>
    <link href="http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/"/>
    <id>http://example.com/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/</id>
    <published>2021-09-03T03:30:00.000Z</published>
    <updated>2021-09-03T07:57:53.364Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/1630640020039.png" alt="1630640020039"></p><p>在GAN中，<strong>Wasserstein距离比f散度拥有更好的数学性质，它处处连续，几乎处处可导且导数不为0</strong>，所以我们更多的使用Wasserstein距离。在上一期的结尾，我们得到critic（判别器）的目标函数为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation.svg" alt="[公式]"></p><p><strong>1-Lipschitz限制即要求在任意点，函数的一阶导数在[-1,1]的范围内，这个限制在神经网络中并不容易实现，之后的许多工作便是围绕这点来展开的。</strong></p><p>本篇所讲的SNGAN便是一种“严格”地解决了1-Lipshcitz约束的方法。</p><h2 id="1-Lipshcitz限制"><a href="#1-Lipshcitz限制" class="headerlink" title="1.Lipshcitz限制"></a>1.Lipshcitz限制</h2><p>所谓Lipshcitz限制，在最简单的一元函数中，即</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630647493192.svg" alt="[公式]"></p><p>或者也可以写成</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630647493206.svg" alt="[公式]"></p><p>直观上看，它要求任意两点之间连线的“斜率”绝对值小于Lipshcitz常数k。在WGAN中要求k=1，1-Lipshcitz限制要求对于f(x)，输入的微小变化不会导致输出产生较大变化。我们常见的函数，比如|x|，sin(x)都显而易见的满足该限制：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/1630647515431.png" alt="1630647515431" style="zoom:80%;"><p>我们以一个最简单的例子来展示一下，如何使用谱范数施加1-Lipshcitz限制。考虑f(x)=Wx，其中</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630647493082.svg" alt="[公式]" style="zoom: 80%;"><p>显然，f(x)=Wx不满足1-Lipshcitz限制，考虑到</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630647493078.svg" alt="[公式]" style="zoom: 80%;"><p>那么若将W整体缩小4倍，</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630647493187.svg" alt="[公式]" style="zoom: 80%;"><p>即可以得到：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630647493200.svg" alt="[公式]" style="zoom: 80%;"><p>可以看出，虽然线性函数f(x)=Wx不满足1-Lipshcitz限制，但是使用谱范数处理后的f*(x)可以满足1-Lipshcitz限制。接下来，我们将对这条思路进行补充、推广，最后得到SNGAN将是显而易见的事情了。</p><h2 id="2-SNGAN"><a href="#2-SNGAN" class="headerlink" title="2. SNGAN"></a>2. SNGAN</h2><p>通常在神经网络中的每一层，先进行输入乘权重的线性运算，再将其送入激活函数，由于通常选用ReLU作为激活函数，因此，一般而言，即使神经网络的输出是非线性的，但是在x的一个足够小的邻域内，它一个表现为线性函数Wx，W的具体形式与x有关。真实的判别器f(x)的函数图像应该是类似这种：</p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/1630648071657.png" alt="1630648071657" style="zoom: 67%;"><p>考虑到对于任意给定的x，均有</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648046563.svg" alt="[公式]"></p><p>ReLu激活函数可以用对角方阵D表示，如果Wx的第i维大于0，则D的第i个对角元素为1，否则为0，需要注意D的具体形式与W,x均有关系，但是D的最大奇异值必然是1。</p><p>整体标记各层的权值、偏置项：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648046578.svg" alt="[公式]"></p><p>那么可以得到</p><p><img src="https://www.zhihu.com/equation?tex=W_%7B%5CTheta,x%7D=D_%7B%5CTheta,x%7D%5E%7BL%7DW_x%5E%7BL%7DD_%7B%5CTheta,x%7D%5E%7BL-1%7DW_x%5E%7BL-1%7D%C2%B7%C2%B7%C2%B7D_%7B%5CTheta,x%7D%5E%7B1%7DW_x%5E%7B1%7D%5C%5C" alt="[公式]"></p><p>根据：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648046583.svg" alt="[公式]"></p><p>可得到：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Csigma(W_%7B%5CTheta,x%7D)+&%5Cle%5Csigma(D_%7B%5CTheta,x%7D%5E%7BL%7D)%5Csigma(W_x%5E%7BL%7D)%5Csigma(D_%7B%5CTheta,x%7D%5E%7BL-1%7D)%5Csigma(W_x%5E%7BL-1%7D)%C2%B7%C2%B7%C2%B7%5Csigma(D_%7B%5CTheta,x%7D%5E%7B1%7D)%5Csigma(W%5E%7B1%7D_x)%5C%5C+&%5Cle+%5Cprod_%7Bl=1%7D%5E%7BL%7D%5Csigma(W%5El_x)+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"></p><p>不必像第二部分所描述办法整体求解W的谱范数，充分利用上述不等式，我们<strong>只需要计算每层的权值矩阵的最大奇异值，即可完成1-Lipshcitz限制。</strong></p><p>对于每层的权值矩阵，处理为：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648046559.svg" alt="[公式]"></p><p>则会有结果：对于任意x，</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Ccfrac%7B%5Cparallel+f_%7B%7D(x+%5Cdelta)-f_%7B%7D(x)%5Cparallel_2%7D%7B%5Cparallel+%5Cdelta+%5Cparallel+_2%7D+&=%5Ccfrac%7B%5Cparallel+%5Chat%7BW%7D_%7Bx%7D%5Cdelta+%5Cparallel_2%7D%7B%5Cparallel+%5Cdelta+%5Cparallel+_2%7D%5C%5C+&%5Cle+%5Csigma(%5Chat%7BW%7D_%7Bx%7D)%5C%5C+&%5Cle+%5Ccfrac%7B%5Csigma(D_%7B%5CTheta,x%7D%5E%7BL%7D)%5Csigma(W_x%5E%7BL%7D)%5Csigma(D_%7B%5CTheta,x%7D%5E%7BL-1%7D)%5Csigma(W_x%5E%7BL-1%7D)%C2%B7%C2%B7%C2%B7%5Csigma(D_%7B%5CTheta,x%7D%5E%7B1%7D)%5Csigma(W_x%5E%7B1%7D)%7D%7B%5Csigma(W_x%5E%7BL%7D)%5Csigma(W_x%5E%7BL-1%7D)%C2%B7%C2%B7%C2%B7%5Csigma(W_x%5E%7B1%7D)%7D%5C%5C+&%5Cle+1+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"></p><p>为了严格起见，需要说明，<strong>f(x)在x的任意邻域内都满足1-Lipshcitz限制，则f(x)在定义域上满足1-Lipshcitz限制</strong>。</p><p>这里通过对真正的解决判别器f(x)的1-Lipshcitz限制问题，方法非常朴素且巧妙。</p><h2 id="个人理解："><a href="#个人理解：" class="headerlink" title="个人理解："></a>个人理解：</h2><p>首先需要计算出来每一层权值矩阵的最大特征值、然后用该层的权值矩阵去除以这个数，把整体缩小k倍，</p><p>这样特征值就会小于等于1，所有特征值乘起来肯定也是小于等于 1的。这样就满足了1-Lipshcitz限制。</p><h2 id="扩展：-谱归一化（SPECTRAL-NORMALIZATION）"><a href="#扩展：-谱归一化（SPECTRAL-NORMALIZATION）" class="headerlink" title="扩展： 谱归一化（SPECTRAL NORMALIZATION）"></a>扩展： 谱归一化（SPECTRAL NORMALIZATION）</h2><p> 谱归一化约束，通过约束 GAN 的 Discriminator 的每一层网络的权重矩阵(weight matrix)的谱范数来约束 Discriminator 的 Lipschitz 常数， 从而增强 GAN 在训练过程中的稳定性。 </p><p>我们知道向量的<code>1-范数</code>、<code>2-范数</code>等等，<code>1-范数</code>表示向量元素绝对值之和，<code>2-范数</code>表示向量元素绝对值的平方和再开方。 扩展开来，<strong>向量的<code>p-范数</code>表示的意思是向量所有元素绝对值的<code>p</code>次方和的<code>1/p</code>次幂。</strong><br>了解了向量的范数的概念，其实矩阵的范数就是在向量的基础上推广开来而已，不过因为矩阵多了一维，所以定义看起来复杂了一些。<br>矩阵的<code>1-范数</code>，则是列和范数，即矩阵的所有列向量绝对值之和的最大值，矩阵的<code>2-范数</code>，是<code>A*A</code><strong>矩阵的最大特征值的开平方</strong>，即：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715529.svg" alt="[公式]"></p><p>式中， <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715545.svg" alt="[公式]"> 为 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715524.svg" alt="[公式]"> 的特征值的绝对值的最大值。<br>其实，矩阵的诱导<code>p-范数</code>也可以类似向量的<code>p-范数</code>推广开来：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715524.svg" alt="[公式]"></p><p>那么，啥又是矩阵的谱范数？<br>就是矩阵的<code>2-范数</code>！<strong>。其值为矩阵<code>A</code>的最大的奇异值或者半正定矩阵<code>A*A</code>的最大特征值的平方根</strong>。</p><p>好了，解释完了矩阵的谱范数的概念，我们继续说谱归一化。</p><p>对于网络的一个layer： <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715552.svg" alt="[公式]"> ，从定义上来说，其<code>Lipscchitz norm</code> <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715568.svg" alt="[公式]"> <em>的值等于</em> <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715577.svg" alt="[公式]"> <em>，其中</em> <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715559.svg" alt="[公式]"> <em>即指矩阵<code>A</code>的谱范数。</em><br><em>那么，</em> <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715459.svg" alt="[公式]"> ， 则根据Lipschitz 定义的不等式，有：</p><p><img src="https://www.zhihu.com/equation?tex=%5Cleft+%5C%7Cf++%5Cright+%5C%7C%7BLip%7D+%E2%89%A4%5Cleft+%5C%7C+(h_L+%E2%86%92+W%5E%7BL+1%7Dh_L)%5Cright+%5C%7C%7BLip%7D%C2%B7+%5Cleft+%5C%7Ca_L%5Cright+%5C%7C%7BLip%7D++%C2%B7+%5Cleft+%5C%7C+(h%7BL-1%7D+%E2%86%92+W%5E%7BL%7Dh_%7BL-1%7D)%5Cright+%5C%7C%7BLip%7D...+%5Cleft+%5C%7Ca_1%5Cright+%5C%7C%7BLip%7D%C2%B7++%5Cleft+%5C%7C+(h_%7B0%7D+%E2%86%92+W%5E%7B1%7Dh_%7B0%7D)%5Cright+%5C%7C_%7BLip%7D" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=++++%E3%80%80%E3%80%80+=%5Cprod_%7Bl=1%7D%5E%7BL+1%7D%5Cleft+%5C%7C(h_%7Bl%E2%88%921%7D%E2%86%92+W%5Elh_%7Bl%E2%88%921%7D)+%5Cright+%5C%7C%7BLip%7D++=%5Cprod_%7Bl=1%7D%5E%7BL+1%7D%5Csigma+(W%5El)" alt="[公式]"></p><p>于是，当约束权重矩阵 <code>W</code>使其<code>LIpschitz constraint</code> <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715583.svg" alt="[公式]"> ，则有：</p><p><img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715571.svg" alt="[公式]"></p><p>那么，当我们这样约束的时候，带入上一个不等式，便可得到 <img src="/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/equation-1630648715588.svg" alt="[公式]"> <code>is bounded from above by 1</code>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/2021/09/03/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB6/1630640020039.png&quot; alt=&quot;1630640020039&quot;&gt;&lt;/p&gt;
&lt;p&gt;在GAN中，&lt;str</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读3---度量和fGAN</title>
    <link href="http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/"/>
    <id>http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/</id>
    <published>2021-09-02T09:10:00.000Z</published>
    <updated>2021-09-02T13:16:40.738Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-分布间的距离"><a href="#1-分布间的距离" class="headerlink" title="1.分布间的距离"></a>1.分布间的距离</h2><p>最初提出的GAN是基于博弈论角度的，它包括一个判别器和一个生成器，判别器会给出输入的样本来源于训练集的概率，而生成器会努力产生可以欺骗判别器的样本。整个GAN的流程稍微复杂却非常具象，甚至可以将其拟人化来理解。其实，更一般地，我们应该从样本概率分布的角度去理解GAN，从这里入手虽然略微抽象，但是能触碰到GAN的本质。</p><p>GAN的生成器隐式地<strong>定义了一个概率分布，并依此概率分布来生成样本</strong>，而训练样本集也是在某一个概率分布上连续独立采样获得的，故GAN的目标就是：<strong>驱使生成器定义的隐式的概率分布接近训练样本集的本质概率分布。</strong></p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/1630574460321.png" alt="1630574460321" style="zoom:80%;"><p> 不同的概率密度函数之间距离有“远近之分”，如下图中黄色分布和蓝色分布的距离比较近，而红色分布和蓝色分布的距离比较远，我们需要定义度量函数来量化分布之间的距离（将两个概率密度函数映射为一个实数）。 </p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/1630574717452.png" alt="1630574717452" style="zoom:67%;"><p> <strong>在向量空间中，将每一个向量视为一个元素，存在许多种两个元素间距离的度量方式</strong>，比如闵科夫斯基距离、欧式距离、曼哈顿距离、切比雪夫距离等。<strong>类似的，将每一个概率分布视为概率密度函数空间中的一个元素，则可以定义元素之间的距离</strong>。需要注意定义的距离需要满足<strong>非负性、对称性、三角不等式</strong>。 </p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/1630578559510.png" alt="1630578559510" style="zoom:80%;"><h2 id="2-f-divergence"><a href="#2-f-divergence" class="headerlink" title="2.f-divergence"></a><strong>2.f-divergence</strong></h2><p>f-divergence则提供了一套“距离”，对于数据集的本质概率分布和生成器隐式的概率分布，我们用以下公式来定义它们的距离：</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630578582159.svg" alt="[公式]"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630578582181.svg" alt="[公式]"></p><p>其中要求，<strong>f(u)为凸函数，且f(1)=0。f(1)=0保证了当两个分布完全重合时，f散度为0</strong>。<strong>f(u)为凸函数保证了f-divergence的值非负</strong>。我们用Jensen不等式来简单证明一下：</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation.svg" alt="[公式]" style="zoom:80%;"><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630578582210.svg" alt="[公式]" style="zoom:80%;"><p>f散度中f(u)的具体形式如下图所示：</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/v2-7eb64e734be348f3b452bd6e4d5fac3e_720w.jpg" alt="img" style="zoom: 58%;"><h2 id="3-共轭函数"><a href="#3-共轭函数" class="headerlink" title="3.共轭函数"></a>3.共轭函数</h2><p>即使知道了f散度的一般表达式，我们也无法精确计算其值。</p><p>我们利用共轭函数将f散度转变成可以计算的形式。<strong>共轭（或对偶）通常指成对出现的两个具有很强关系的实体，它们具有相同的结构和意义</strong>。<strong>无论原函数是否是凸函数，其共轭函数必为凸函数</strong>（凸函数在做优化时拥有非常好的数学性质）。</p><p>定义共轭函数为</p><p><img src="https://www.zhihu.com/equation?tex=f(u)=%5Cmax_%7Bt%5Cin+f%27(D)%7D%5C%7Btu-g(t)%5C%7D%5C%5C" alt="[公式]"> </p><p> t的定义域为f(u)的一阶导数的值域。即对于任意给定的u，要遍历所有可能的t代入计算，然后寻找最大值。 </p><p>此时f散度可转化为</p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+D_f(p_%7Bdata%7D%5Cparallel+p_g)&=%5Cint_x+p_g(x)f(%5Cfrac%7Bp_%7Bdata%7D(x)%7D%7Bp_g(x)%7D)dx%5C%5C+&=%5Cint_x+p_g(x)%5B%5Cmax_%7Bt%5Cin+f%27(D)%7D%5C%7Bt%5Cfrac%7Bp_%7Bdata%7D(x)%7D%7Bp_g(x)%7D-g(t)%5C%7D%5Ddx%5C%5C+&=%5Cint_x%5Cmax_%7Bt%5Cin+f%27(D)%7D%5Btp_%7Bdata%7D(x)-g(t)p_g(x)%5Ddx%5C%5C+&%5Cgeq%5Cmax_%7Bt%5Cin+f%27(D)%7D%5Cint_x%5Btp_%7Bdata%7D(x)-g(t)p_g(x)%5Ddx%5C%5C+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"></p><p> t和u具有非常复杂的数学解析关系，则t和x也具有非常复杂的数学解析关系，即使用共轭函数给出了f散度的一个下界，依然无法写成解析式而利用蒙特卡洛方法求解。利用神经网络强大的函数拟合能力，可以构造一个神经网络来拟合t和x的复杂函数关系，即 <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630579742308.svg" alt="[公式]"> ，这里要注意通过设置最后一层的激活函数以保证神经网络的输出在f(u)的一阶导数的值域中。 </p><p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+&%5Cmax_%7Bt%5Cin+f%27(D)%7D%5Cint_x%5Btp_%7Bdata%7D(x)-g(t)p_g(x)%5Ddx%5C%5C+=&%5Cmax_%7B%5Ctheta%7D%5Cint_xp_%7Bdata%7D(x)T_%7B%5Ctheta%7D(x)-p_g(x)g(T_%7B%5Ctheta%7D(x))dx%5C%5C+=&%5Cmax_%7B%5Ctheta%7D%5Cmathbb%7BE%7D_%7Bx%5Csim+p_%7Bdata%7D%7D%5BT_%7B%5Ctheta%7D(x)%5D-%5Cmathbb%7BE%7D_%7Bx%5Csim+p_g%7D%5Bg(T_%7B%5Ctheta%7D(x))%5D+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"> </p><p>所以，对于这个神经网络T，我们应该以</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630579839033.svg" alt="[公式]"></p><p>为目标函数通过采样的方式进行训练，将求极值的问题转化成训练神经网络的问题，理论上，经过完美的训练，上述目标函数即转化成了f散度。所以在fGAN的框架下来看，训练判别器本质上是为了逼近一个f散度，然后利用f散度去指示生成器的学习。从现在开始，判别器已经不再像最原始的GAN拥有具象的意义了。</p> <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/v2-f9310de8170c172ddcc336725f64f5b0_720w.jpg" alt="img" style="zoom:80%;"> <h2 id="4-几个小问题"><a href="#4-几个小问题" class="headerlink" title="4.几个小问题"></a>4.几个小问题</h2><p>KL散度和逆KL散度在严格意义上并不是一种度量，因为不符合对称性，即</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630581634007.svg" alt="[公式]"></p><p>非对称性意味着使用KL散度或者逆KL散度作为优化目标，其得到结果将具有显著差异。例如，用分布Q去拟合分布P，选择KL散度，Q会将诸多高概率的峰模糊化，</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/1630581689827.png" alt="1630581689827" style="zoom: 50%;"><p>如若使用逆KL散度，则会导致Q去拟合高概率的单峰。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/1630581711341.png" alt="1630581711341" style="zoom:50%;"><p>另一个需要解释的问题，为什么JS散度效果不好。因为训练集的概率分布和生成器隐式定义的概率分布往往只是高维空间的低维流形，例如在三维空间中，两个分布均是二维流形，其交集最多为一条直线，以至于在计算JS散度时可以忽略。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/1630581740276.png" alt="1630581740276" style="zoom:50%;"><p>即对于任意x，在绝大部分情况下，两个概率分布至少有一个为0。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB4/equation-1630581634060.svg" alt="[公式]" style="zoom: 67%;"><p>显然，这样计算得来的JS散度为常数。所以如果将判别器训练的太好（即学习到了JS散度）但JS散度为一个常数，无法提供任何梯度信息供生成器训练，就是大家常说的“学不动”。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-分布间的距离&quot;&gt;&lt;a href=&quot;#1-分布间的距离&quot; class=&quot;headerlink&quot; title=&quot;1.分布间的距离&quot;&gt;&lt;/a&gt;1.分布间的距离&lt;/h2&gt;&lt;p&gt;最初提出的GAN是基于博弈论角度的，它包括一个判别器和一个生成器，判别器会给出输入的样本来源</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读3---对偶与WGAN</title>
    <link href="http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/"/>
    <id>http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/</id>
    <published>2021-09-02T09:10:00.000Z</published>
    <updated>2021-09-02T13:16:57.239Z</updated>
    
    <content type="html"><![CDATA[<p> 说到对GAN的理解，我们不能简单停留在“生成器产生样本，判别器分辨样本真假”的阶段了，在经过上一篇文章后，对GAN的理解应该是：先学习一个关于生成器定义的隐式概率分布和训练数据集的本质概率分布之间的距离度量，然后优化生成器来缩减这个距离度量。今天的主要内容依旧围绕这个距离度量来展开。 </p><h2 id="1-度量连续性的问题"><a href="#1-度量连续性的问题" class="headerlink" title="1.度量连续性的问题"></a>1.度量连续性的问题</h2><p>在第二篇文章的最后，我们简要讨论了f散度的问题。实际中，生成器定义的隐式概率分布和训练数据集的本质概率分布几乎不存在重叠部分，而且随着数据维度增加，这个趋势会更加严重，那么采样计算得来的f散度距离不仅不连续，而且几乎处处导数为0。</p><p>用一个非常简单的例子来解释一下，在二维空间有两个无任何重合的均匀分布，其中</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation.svg" alt="[公式]"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630584299151.svg" alt="[公式]"></p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/1630584313712.png" alt="1630584313712" style="zoom:50%;"><p>计算一下两个分布的KL散度，JS散度</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630584430067.svg" alt="[公式]" style="zoom:70%;"><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630584430074.svg" alt="[公式]" style="zoom:70%;"><p>可以看出，当P和Q没有重合或者重合部分可忽略时，其f散度值为常数；当两者完全重合时，f散度值为0，即f散度无法为生成器提供可以减少损失函数的梯度信息，生成器无法训练获得优化方向。</p><p>对于此问题的一种解决方案是：通过对数据集中的样本和生成器生成的样本增加噪声，使得原本的两个低维概率分布“弥散”到整个高维空间，强行让它们产生不可忽略的重叠，此时的f散度便能“指示”出两个分布的距离。在训练过程中，我们可以先添加方差比较大的噪声，以尽可能使两个分布产生较大重叠部分，随着两个分布距离的拉近，可以逐渐降低噪声的方差，直至最后可以去掉噪声完全靠JS散度来指示生成器的学习。</p><p>但是为了本质地解决问题，我们需要寻找一种更合理的距离度量。直观上，该距离最好处处连续，在两个分布不重合的位置处处可导且导数不为0。</p><h2 id="2-Wasserstein距离"><a href="#2-Wasserstein距离" class="headerlink" title="2.Wasserstein距离"></a>2.Wasserstein距离</h2><p>Wasserstein距离是一个数学性质非常良好距离度量，数学形式稍微有点复杂。我们用一个小例子来引入，定义两个离散概率分布P和Q，其随机变量取值只能为1,2,3,4。如何对P调整使其等于Q？</p><img src="https://pic4.zhimg.com/80/v2-5845beb5f4231be76408b23ef9228c0b_720w.jpg" alt="img" style="zoom:67%;"> <p>其实是很简单的一个问题，我们逐位置来分解计算，</p><ol><li> 对于P的1位置，其值为0.25，我们将这0.25保持在1位置 </li><li> 对于P的2位置，其值为0.25，我们也将这0.25保持在2位置 </li><li> 对于P的3位置，其值为0.5，我们将其中的0.25放置到1位置，将0.25放置到2位置</li><li> P的4位置为0，不用做任何分解和移动 </li></ol><p>即可有如下分解矩阵</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/1630585750932.png" alt="1630585750932" style="zoom:67%;"><p> 然后，我们再考虑关于路程的移动耗费问题。如果定义从1位置到2位置路程为1，从1位置到3位置路程为2……对P的1位置，将0.25保留在1位置不产生耗费，对P的2位置，将0.25保留在2位置不产生耗费，但是将对P的3位置，将0.25移动到1位置，需要耗费：0.25*(3-1)=0.5；将0.25移动到2位置，需要耗费：0.25*(2-1)=0.25，故整个方案将产生0.75的耗费。当然，我们也可以有其他方案，例如： </p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/1630586082108.png" alt="1630586082108" style="zoom: 67%;"><p> 可以证明的是总存在一个耗费最小的方案。Wasserstein距离便是选择某一种最小消耗方案对应的总消耗值。 </p><h3 id="在数学形式上，"><a href="#在数学形式上，" class="headerlink" title="在数学形式上，"></a><strong>在数学形式上，</strong></h3><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377332.svg" alt="[公式]"></p><p>其中， <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377295.svg" alt="[公式]"> 是两个分布构成全部可能的联合分布的集合。而 <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377265.svg" alt="[公式]"></p><p>是该集合中的一个联合分布，且该联合分布要求</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377308.svg" alt="[公式]"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377310.svg" alt="[公式]"></p><p>简而言之就是， <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377265.svg" alt="[公式]"> 定义一个传输方案， <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377285.svg" alt="[公式]"> 定义了路程函数（ <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377185.svg" alt="[公式]"> 的每个位置传输到 <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377342.svg" alt="[公式]"> 每个位置的传输路程），求双重积分计算总传输耗费值，最后在所有这些方案中取最小耗费值的传输方案，其对应的总耗费值即为距离。</p><p>在WGAN中，</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377216.svg" alt="[公式]"></p><p>当然也可以定义2-Wasserstein距离：</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377282.svg" alt="[公式]"></p><p>或者k-Wasserstein距离：</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377344.svg" alt="[公式]"></p><p>针对于刚开始提出的小例子，我们用Wasserstein则可得到：</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/equation-1630586377223.svg" alt="[公式]"></p><p>可以看出Wasserstein距离处处连续，而且几乎处处可导，数学性质非常好，能够在两个分布没有重叠部分的时候，依旧给出合理的距离度量。</p><h2 id="3-对偶问题"><a href="#3-对偶问题" class="headerlink" title="3.对偶问题"></a>3.对偶问题</h2><p>如果要计算Wasserstein距离，那需要遍历所有满足条件的联合概率分布，然后计算每个联合概率分布下的总消耗值，最后取最小的总消耗值，在维度较高时，该问题几乎不可解决。与之前fGAN有点类似，当一个优化问题难以求解时，可以考虑将其转化为比较容易求解的对偶问题。关于对偶理论，其最早源于求解线性规划问题，每个线性规划问题都有一个与之对应的对偶问题，对偶问题是以原问题的约束条件和目标函数为基础构造而来的，对偶问题也是一个线性规划问题，且当求解成功对偶问题时，其原问题也自然解决。</p><p> 我们先将Wasserstein距离表示成线性规划的形式，定义向量： </p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/1630587362224.png" alt="1630587362224" style="zoom:80%;"><p> 定义向量： </p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/1630587382579.png" alt="1630587382579" style="zoom:80%;"><h2 id="后面没看懂…………………不过自己的理解如下"><a href="#后面没看懂…………………不过自己的理解如下" class="headerlink" title="后面没看懂…………………不过自己的理解如下"></a>后面没看懂…………………不过自己的理解如下</h2><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB5/1630587880480.png" alt="1630587880480"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt; 说到对GAN的理解，我们不能简单停留在“生成器产生样本，判别器分辨样本真假”的阶段了，在经过上一篇文章后，对GAN的理解应该是：先学习一个关于生成器定义的隐式概率分布和训练数据集的本质概率分布之间的距离度量，然后优化生成器来缩减这个距离度量。今天的主要内容依旧围绕这个距离</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读3---生成模型和GAN</title>
    <link href="http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/"/>
    <id>http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/</id>
    <published>2021-09-02T07:30:00.000Z</published>
    <updated>2021-09-03T03:31:50.060Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-生成模型"><a href="#1-生成模型" class="headerlink" title="1 生成模型"></a><strong>1 生成模型</strong></h2><p>在机器学习或者深度学习领域，生成模型具有非常广泛的应用，它可以用于测试模型的高维概率分布的表达能力，可以用于强化学习、半监督学习，可以用于处理多模输出问题，以及最常见的产生“真实”数据问题。</p><p><strong>简单而言，有监督学习与无监督学习的区别之处在于是否存在标签信息。</strong>在有监督学习生成方法中，我们学得联合概率分布P(X,Y)，然后求出生成模型P(Y|X)，其重点在于学习联合分布。例如，在朴素贝叶斯方法中，我们通过数据集学习到先验概率分布P(Y)和条件概率分布P(X|Y)，即可得到联合概率分布P(X,Y)；在隐马尔可夫模型中，我们通过数据集学习到初始概率分布、状态转移概率矩阵和观测概率矩阵，即得到了一个可以表示状态序列和观测序列的联合分布的马尔可夫模型。<strong>而在GAN、VAE等无监督生成模型中，只存在关于X的数据集，我们的目标或者近似得到P(X)的概率密度函数，或者直接产生符合X本质分布的样本。</strong></p><h2 id="2-极大似然估计"><a href="#2-极大似然估计" class="headerlink" title="2 极大似然估计"></a><strong>2 极大似然估计</strong></h2><p>我们从最简单的生成模型开始说起。考虑这样一个问题，依概率P(X)在X中独立采样n次构建一个包含n样本的数据集，如何根据这个数据集来求得X的概率密度函数P(X)。其实这个问题并不容易解决，可是如果再额外提供一些关于X的先验知识，比如X服从正态分布，那这个问题便可以使用极大似然法轻松搞定。</p><p>如若X服从正态分布，则概率密度函数P(X)的表达式形式已知，只需要再确定均值、方差两个参数值便可以得到P(X)。接下来便是计算数据集的似然函数，对似然函数取负对数，然后最小化即可，即</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/equation.svg" alt="[公式]"> </p><p>其实，对随机变量X的概率密度函数的建模源于先验知识，极大似然估计只是一个参数估计的方法。容易证明，<strong>极大似然法本质上是在最小化数据集的经验性分布和模型分布之间的KL散度</strong>，而且当具备某些条件时，参数的极大似然估计值会趋近于真实值。</p><h2 id="3-GAN-—-具体可看周总结9-8"><a href="#3-GAN-—-具体可看周总结9-8" class="headerlink" title="3 GAN —-具体可看周总结9.8"></a><strong>3 GAN</strong> —-具体可看周总结9.8</h2><p>全程没有任何显式地出现过概率密度函数，直接做一个end-to-end的模型。g(z)的本质是一个参数化计算过程，它能很好地学习到z排布情况以及从z到x的映射。我们所做的就是根据训练数据来推断参数，然后选择合适的g，其代表便是GAN。 </p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/1630573743479.png" alt="1630573743479"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/1630573759342.png" alt="1630573759342"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/1630573767836.png" alt="1630573767836"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/1630573808796.png" alt="1630573808796"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB3/1630573844467.png" alt="1630573844467"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-生成模型&quot;&gt;&lt;a href=&quot;#1-生成模型&quot; class=&quot;headerlink&quot; title=&quot;1 生成模型&quot;&gt;&lt;/a&gt;&lt;strong&gt;1 生成模型&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;在机器学习或者深度学习领域，生成模型具有非常广泛的应用，它可以用于测试模型</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读1---GAN原理</title>
    <link href="http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/"/>
    <id>http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/</id>
    <published>2021-09-02T04:10:00.000Z</published>
    <updated>2021-09-02T13:16:08.285Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-生成器判别器比较："><a href="#1-生成器判别器比较：" class="headerlink" title="1.生成器判别器比较："></a>1.生成器判别器比较：</h2><p>判别式模型 ，优点是分类边界灵活 ，学习简单，性能较好；缺点是不能得到概率分布 。<br>生成式模型 ，优点是收敛速度快，可学习分布，可应对隐变量 ；缺点是学习复杂 ，分类性能较差。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/1630555982895.png" alt="1630555982895" style="zoom:67%;"><p> 上面是一个分类例子，可知判别式模型，有清晰的分界面，而生成式模型，有清晰的概率密度分布。生成式模型，可以转换为判别式模型，反之则不能。 </p><h2 id="2-判别器优化目标与求解"><a href="#2-判别器优化目标与求解" class="headerlink" title="2.判别器优化目标与求解"></a>2.判别器优化目标与求解</h2><p>下面是它的优化目标。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/1630556912745.png" alt="1630556912745" style="zoom:67%;"><p>D是判别器，它的学习目标，是最大化上面的式子，而G是生成器，它的学习目标，是最小化上面的式子。上面问题的求解，通过迭代求解D和G来完成。<br>要求解上面的式子，等价于求解下面的式子。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-8cd69f7686525dabfef9dcfc70e70f24_720w.jpg" alt="img" style="zoom: 80%;"><p>其中D(x)属于(0,1)，上式是alog(y) + blog(1−y)的形式，取得最大值的条件是D(x)=a/(a+b)，此时等价于下面式子。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-d1c432ebece6171fcbc44a409e60e5a1_720w.jpg" alt="img" style="zoom:75%;"><p>如果用KL散度来描述，上面的式子等于下面的式子。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/1630556947010.png" alt="1630556947010" style="zoom:67%;">当且仅当pdata(x)=pg(x)时，取得极小值-log4，此时d=0.5，无法分辨真实样本和假样本。<p>GAN从理论上，被证实存在全局最优解。</p><h2 id="3-JS散度和KL散度理解"><a href="#3-JS散度和KL散度理解" class="headerlink" title="3. JS散度和KL散度理解"></a>3. JS散度和KL散度理解</h2><h4 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h4><ul><li>用来衡量两个分布之间的差异，等于一个交叉熵减去一个信息熵（交叉熵损失函数的由来）<img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/20200501153718560.png" alt="在这里插入图片描述" style="zoom:80%;"></li></ul><p> 请问KL散度的不对称性在训练中会产生的问题 ： 如果两个分布没有重叠部分，KL散度直接为∞，这样就一旦没有重叠的话就无法判断两个分布的距离 </p><h4 id="JS-Jenson’s-Shannon-散度"><a href="#JS-Jenson’s-Shannon-散度" class="headerlink" title="JS(Jenson’s Shannon)散度"></a>JS(Jenson’s Shannon)散度</h4><p>一般地，JS散度是对称的，其取值是 0 到 1 之间。如果两个分布 P,Q 离得很远，完全没有重叠的时候，那么KL散度值是没有意义的，而JS散度值是一个常数。这在学习算法中是比较致命的，这就意味这这一点的梯度为 0。梯度消失了。</p><p> <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/20200501154128640.png" alt="在这里插入图片描述"> </p><p> <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/20200501154147675.png" alt="在这里插入图片描述"><br><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/2020050115420360.png" alt="在这里插入图片描述"> </p><h2 id="为什么会出现两个分布没有重叠的现象"><a href="#为什么会出现两个分布没有重叠的现象" class="headerlink" title="为什么会出现两个分布没有重叠的现象"></a>为什么会出现两个分布没有重叠的现象</h2><p> <img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/2020050115431689.png" alt="在这里插入图片描述"> </p><h2 id="GAN的主要问题"><a href="#GAN的主要问题" class="headerlink" title="GAN的主要问题"></a>GAN的主要问题</h2><p>​       GAN的训练是依次迭代D和G，如果判别器D学的不好，生成器G得不到正确反馈，就无法稳定学习。如果判别器D学的太好，整个loss迅速下降，G就无法继续学习。</p><p>​       GAN的优化需要生成器和判别器达到纳什均衡，但是因为判别器D和生成器G是分别训练的，纳什平衡并不一定能达到，这是早期GAN难以训练的主要原因。</p><h2 id="风格迁移"><a href="#风格迁移" class="headerlink" title="风格迁移"></a>风格迁移</h2><p> 【20】Isola P, Zhu J Y, Zhou T, et al. Image-to-Image Translation with Conditional Adversarial Networks[J]. 2016:5967-5976. </p><p>实现了像素级别的风格转换，它的关键是<strong>提供了两个域中有相同数据的成对训练样本</strong>，本质上，是一个CGAN。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-6d616d7f501b73ddc31afd4d97c80719_720w.jpg" alt="img"></p><p>【 21】Zhu J Y, Park T, Isola P, et al. Unpaired image-to-image translation using cycle-consistent adversarial networks[J]. arXiv preprint, 2017.<br>【22】Yi Z, Zhang H, Tan P, et al. Dualgan: Unsupervised dual learning for image-to-image translation[J]. arXiv preprint, 2017. </p><p>cycle-gan/dual-gan则更胜一筹，<strong>不需要配对的数据集，可以实现源域和目标域的相互转换。</strong></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-28658b2356813059fdb271f07ff0ecaa_720w.jpg" alt="img"></p><p> 【23】Chang H, Lu J, Yu F, et al. Pairedcyclegan: Asymmetric style transfer for applying and removing makeup[C]//2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2018. </p><p>pairedcycle    将源域和目标域的相互转换用到化妆和去妆，很有趣的应用。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-c5d1d348e16f78e0db1b2f267476f01b_720w.jpg" alt="img"></p><p> 【24】Wei L, Zhang S, Gao W, et al. Person Transfer GAN to Bridge Domain Gap for Person Re-Identification[J]. arXiv preprint arXiv:1711.08565, 2017. </p><p>学习了一个数据集到另一个数据集的迁移，可以用于迁移学习，如实现漫画风格。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-d751021c8d244e7ee35537164cb875d0_720w.jpg" alt="img"></p><p> 【28】Chen Y, Lai Y K, Liu Y J. CartoonGAN: Generative Adversarial Networks for Photo Cartoonization[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 9465-9474. </p><p>【28】实现了卡通风格的转换。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/v2-2b34fc469389b4271e1eafb742b7c8ff_720w.jpg" alt="img"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-生成器判别器比较：&quot;&gt;&lt;a href=&quot;#1-生成器判别器比较：&quot; class=&quot;headerlink&quot; title=&quot;1.生成器判别器比较：&quot;&gt;&lt;/a&gt;1.生成器判别器比较：&lt;/h2&gt;&lt;p&gt;判别式模型 ，优点是分类边界灵活 ，学习简单，性能较好；缺点是不能得</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>有三AI文章阅读2---GAN五个基本结构</title>
    <link href="http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/"/>
    <id>http://example.com/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/</id>
    <published>2021-09-02T04:10:00.000Z</published>
    <updated>2021-09-02T13:16:24.469Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-单判别器单生成器"><a href="#1-单判别器单生成器" class="headerlink" title="1.单判别器单生成器"></a>1.单判别器单生成器</h2><p>个基本的用于生成图像的GAN的结构就是这样的。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-7876af8591afba7209c84f4dffef9019_720w.jpg" alt="img"></p><p>Generator就是生成器，它输入噪声，输出产生的图像。通常噪声就是一个一维的向量，经过reshape为二维图像，然后利用若干个反卷积层来学习上采样。</p><p>如全卷积的DCGAN模型[1]，输入就是1<em>100的向量，然后经过一个全连接层学习，reshape到4</em>4<em>1024的张量，再经过4个上采样的反卷积网络，生成64</em>64的图。</p><p>Discrimator就是普通的CNN分类器，输入真实样本或者生成的假样本进行分类，在DCGAN中也是4个卷积层。</p><h2 id="2-多判别器单生成器"><a href="#2-多判别器单生成器" class="headerlink" title="2 多判别器单生成器"></a>2 多判别器单生成器</h2><p>采用多个判别器[2]的好处带来了类似于boosting的优势，训练一个过于好的判别器，会损坏生成器的性能，这是GAN面临的一个大难题。如果能够训练多个没有那么强的判别器，然后进行boosting，可以取得不错的效果，甚至连dropout技术都可以应用进来。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-c074556ea6de9a92825594b8bac79d7d_720w.jpg" alt="img"></p><p>多个判别器还可以相互进行分工，比如在图像分类中，一个进行粗粒度的分类，一个进行细粒度的分类。在语音任务中，各自用于不同声道的处理。</p><h2 id="3-单判别器多生成器"><a href="#3-单判别器多生成器" class="headerlink" title="3 单判别器多生成器"></a>3 单判别器多生成器</h2><p>一般来说，生成器相比判别器要完成的任务更难，因为它要完成数据概率密度的拟合，而判别器只需要进行判别，导致影响GAN性能的一个问题就是模式坍塌，即生成高度相似的样本。</p><p>采用多个生成器单个判别器的方法，可以有效地缓解这个问题。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-afe2bc28e5eef370ad7706e526ad6d5f_720w.jpg" alt="img"></p><p>从上图结构可以看出，多个生成器采用同样的结构，在网络的浅层还共享权重。</p><h2 id="4-增加分类器"><a href="#4-增加分类器" class="headerlink" title="4 增加分类器"></a>4 增加分类器</h2><p>在利用GAN进行半监督的图像分类任务时，判别器需要同时担任两个角色，即判别生成的假样本，以及预测类别，这对判别器提出了较高的要求。通过增加一个分类器可以分担判别器的工作量，即将捕捉样本和标签的条件分布这一任务交给生成器和分类器，而判别器只专注于区分真实样本和生成的样本。</p><p>这一类结构以Triple Generative Adversarial Nets为代表，下图是它的网络结构。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-607f83bf70d07214dc0ea70bc13539e8_720w.jpg" alt="img"></p><h2 id="5-多个生成器多个判别器"><a href="#5-多个生成器多个判别器" class="headerlink" title="5 多个生成器多个判别器"></a>5 多个生成器多个判别器</h2><h4 id="5-1-级联结构"><a href="#5-1-级联结构" class="headerlink" title="5.1 级联结构"></a>5.1 级联结构</h4><p>早期以DCGAN为代表的网络生成的图片分辨率太低，质量不够好，都不超过100×100，在32×32或者64×64左右。这是因为难以一次性学习到生成高分辨率的样本，收敛过程容易不稳定。</p><p>类似的问题在图像分割，目标检测中都存在。在目标检测中，级联网络被广泛使用，即采用从粗到精的方法依次改进检测器的性能。在图像分割中进行上采样时也采用学习小倍率的放大而不是大倍率的方法，如利用两个2倍上采样替换一个4倍的上采样，不仅可以增强网络的表达能力，还降低了学习难度。</p><p>基于此，金字塔GAN结构被提出并广泛使用，它参考图像领域里面的金字塔结构由粗到精一步一步生成图像，并添加残差进行学习。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-22a2cf287efb97ca459710749b44d0f1_720w.jpg" alt="img"></p><p>上图就是它的结构，从低分辨率z3开始，逐级提升，最终生成I0，这是一个金字塔形状的结构，以下符号较多用图片代替。</p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-08e2f8c505c51c00025e36233857062b_720w.jpg" alt="img" style="zoom: 67%;"><h4 id="5-2-并行与循环结构"><a href="#5-2-并行与循环结构" class="headerlink" title="5.2 并行与循环结构"></a><strong>5.2 并行与循环结构</strong></h4><p>GAN有一大应用就是风格化，实现两个域之间的风格互换，以CycleGAN[6]为典型代表。它包含了多个生成器和多个判别器。Cycle的典型结构如下：</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-39005682b78d5c336a39d2adc69d4a6d_720w.jpg" alt="img"></p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-f7b6760003bd274c6304186fc0bf627e_720w.jpg" alt="img"></p><p>X和Y分别表示两个域的图像，可知这里存在两个生成器G和F，分别用于从X到Y的生成和Y到X到生成，包含两个判别器，分别是Dx和Dy。而损失本身也增加了一个循环损失。</p><p>另外在cross domain学习中也常用到多判别器多生成器多结构，分别学习不同的域。而且各个域的判别器和生成器通常会共享一些权重，如下图是CoGAN[7]的网络结构。</p><p><img src="/2021/09/02/%E6%9C%89%E4%B8%89AI%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB2/v2-fcc0f005574f85f377cc8df9eed0b9aa_720w.jpg" alt="img"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-单判别器单生成器&quot;&gt;&lt;a href=&quot;#1-单判别器单生成器&quot; class=&quot;headerlink&quot; title=&quot;1.单判别器单生成器&quot;&gt;&lt;/a&gt;1.单判别器单生成器&lt;/h2&gt;&lt;p&gt;个基本的用于生成图像的GAN的结构就是这样的。&lt;/p&gt;
&lt;p&gt;&lt;img sr</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>详细解读batch norm</title>
    <link href="http://example.com/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/"/>
    <id>http://example.com/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/</id>
    <published>2021-08-29T04:50:02.000Z</published>
    <updated>2021-08-31T02:38:13.438Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Batch-Normalization-概念"><a href="#Batch-Normalization-概念" class="headerlink" title="Batch Normalization 概念"></a>Batch Normalization 概念</h1><p>Batch Normalization：批标准化<br>批：一批数据，通常为mini-batch<br>标准化：0均值，1方差</p><p>计算方式：<br>mini-batch中有x 1 , x 2 , . . . x m x_1,x_2,…x_m个数据，有两个待学习的参数 γ , β 然后通过这两个参数对x进行BN变化。 </p><p> 1.计算均值。    2.计算方差。     3.归一化处理到均值为0，方差为1。    4.恢复出这一层网络所要学到的分布   </p><p>具体计算公式看下图：</p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630212948797.png" alt="1630212948797" style="zoom:60%;"><p>在公式中求normalize这步中，为了防止分母为0的情况出现，加了一个修正系数ϵ ，得到的x ^ i  是一个服从0均值，1标准差的分布。最后对x ^ i  进行scale和shift操作就是通过两个超参数进行的。</p><h1 id="PyTorch的Batch-Nomalzaton-1d-2d-3d实现"><a href="#PyTorch的Batch-Nomalzaton-1d-2d-3d实现" class="headerlink" title="PyTorch的Batch Nomalzaton 1d/2d/3d实现"></a>PyTorch的Batch Nomalzaton 1d/2d/3d实现</h1><p><strong>_BatchNorm（基类）</strong><br>·nn.BatchNorm1d<br>·nn.BatchNorm2d<br>·nn.BatchNorm3d</p><p><strong>基类的参数：</strong><br>·num_features：一个样本特征数量（最重要）<br>·eps：分母修正项，一般是1e-5<br>·momentum：指数加权平均估计当前mean/var<br>·affine：是否需要affine transform，默认是true<br>·track_running_stats：是训练状态，还是测试状态</p><p><strong>主要属性：</strong><br>·running_mean：均值就是图片公式中的μ<br>·running_Var：方差图片公式中的σ<br>·weight:affine transform中的γ （可学习）<br>·bias:affine transform中的β（可学习）<br>上面四个属性中，后面两个是可学习的，前面两个呢？<br>在训练阶段：均值和方差采用<strong>指数加权平均</strong>计算<br>running_mean=(1-momentum)* pre_running_mean +momentum * mean_t<br>running_var=(1-momentum)* pre_running_var+ momentum * var_t<br>在测试阶段：当前统计值（已经估计好的值）</p><h2 id="1D"><a href="#1D" class="headerlink" title="1D"></a>1D</h2><p>·nn.BatchNorm1d input=B* 特征数* 1d特征<br>看下图可知，有3个batch，每个batch的特征数量是5个，特征的维度是1.所以大小是3<em>5</em>1，有时候1省略不写变成3 * 5.<br>那如何计算BatchNorm1d 的四个属性呢？<br>对每个特征横着看，对1.1.1求均值方差，学习γ 和β可得到第一个特征的四个属性，<br>同样对2.2.2求均值方差，学习γ 和β 可得到第二个特征的四个属性<br>同样对3.3.3求均值方差，学习γ 和β 可得到第三个特征的四个属性</p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630220059607.png" alt="1630220059607" style="zoom:67%;"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">9</span>)  <span class="comment"># 设置随机种子</span></span><br><span class="line">flag = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> flag:</span><br><span class="line">    batch_size = <span class="number">3</span></span><br><span class="line">    num_features = <span class="number">5</span><span class="comment">#特征数5个</span></span><br><span class="line">    momentum = <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line">    features_shape = (<span class="number">1</span>)<span class="comment">#1d，就是图中的每个特征维度为1</span></span><br><span class="line"></span><br><span class="line">    feature_map = torch.ones(features_shape) <span class="comment">#得到一个为1的张量                                                   </span></span><br><span class="line">    feature_maps = torch.stack([feature_map*(i+<span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_features)], dim=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 然后在特征数量方向进行扩展，就是图中的y轴        </span></span><br><span class="line">    feature_maps_bs = torch.stack([feature_maps <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size)], dim=<span class="number">0</span>)  </span><br><span class="line">    <span class="comment"># 在batch方向上进行扩展，就是图中的x轴          </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;input data:\n&#123;&#125; \n  shape is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(feature_maps_bs, feature_maps_bs.shape))<span class="comment">#打印出来应该是3*5*1</span></span><br><span class="line">    </span><br><span class="line">    bn = nn.BatchNorm1d(num_features=num_features, momentum=momentum)</span><br><span class="line"></span><br><span class="line">    running_mean, running_var = <span class="number">0</span>, <span class="number">1</span>          <span class="comment">## 均值和方差初始化</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        outputs = bn(feature_maps_bs)              <span class="comment">## running_mean=(1-momentum)* pre_running_mean +momentum * mean_t</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\niteration:&#123;&#125;, running mean: &#123;&#125; &quot;</span>.<span class="built_in">format</span>(i, bn.running_mean))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;iteration:&#123;&#125;, running var:&#123;&#125; &quot;</span>.<span class="built_in">format</span>(i, bn.running_var))</span><br><span class="line"></span><br><span class="line">        running_mean = (<span class="number">1</span> - momentum) * running_mean + momentum * mean_t</span><br><span class="line">        running_var = (<span class="number">1</span> - momentum) * running_var + momentum * var_t</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;iteration:&#123;&#125;, 第二个特征的running mean: &#123;&#125; &quot;</span>.<span class="built_in">format</span>(i, running_mean))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;iteration:&#123;&#125;, 第二个特征的running var:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i, running_var))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出结果：</p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630222648383.png" alt="1630222648383" style="zoom:77%;"><h3 id="均值计算"><a href="#均值计算" class="headerlink" title="均值计算"></a>均值计算</h3><p>根据公式：running_mean=(1-momentum)* pre_running_mean +momentum * mean_t</p><p>由于是第一次迭代，pre_running_mean （上一次的均值）没有，默认是0，</p><p>当前均值mean_t = 1、2、3、4、5</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">     第一个特征（3个1）                       计算结果：running_mean=(1-0.3)*0+0.3 * 1 = 0.3；</span><br><span class="line">同理，第二个特征（3个2）                       计算结果：running_mean=(1-0.3)*0+0.3 * 2 = 0.6；</span><br><span class="line">同理，第三个特征（3个3）                       计算结果：running_mean=(1-0.3)*0+0.3 * 3 = 0.9；</span><br><span class="line">同理，第二个特征（3个4）                       计算结果：running_mean=(1-0.3)*0+0.3 * 4 = 1.2；</span><br><span class="line">同理，第三个特征（3个5）                       计算结果：running_mean=(1-0.3)*0+0.3 * 5 = 1.5；</span><br></pre></td></tr></table></figure><p>下面看第二次迭代的时候：momentum = 0.3，mean_t = 1、2、3、4、5<br><strong>pre_running_mean = 上一个阶段计算出来的running_mean。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">     第一个特征（3个1）                    计算结果：running_mean=(1-0.3)*0.3+0.3 * 1 = 0.51；</span><br><span class="line">同理，第二个特征（3个2）                    计算结果：running_mean=(1-0.3)*0.6+0.3 * 2 = 1.02；</span><br><span class="line">同理，第三个特征（3个3）                    计算结果：running_mean=(1-0.3)*0.9+0.3 * 3 = 1.53；</span><br><span class="line">同理，第二个特征（3个4）                    计算结果：running_mean=(1-0.3)*1.2+0.3 * 4 = 2.04；</span><br><span class="line">同理，第三个特征（3个5）                    计算结果：running_mean=(1-0.3)*1.5+0.3 * 5 = 2.55；</span><br></pre></td></tr></table></figure><h3 id="方差计算"><a href="#方差计算" class="headerlink" title="方差计算"></a>方差计算</h3><p>根据公式：running_var=(1-momentum)* pre_running_var+ momentum * var_t</p><p>由于是第一次迭代，上一次的方差）没有，默认是pre_running_var = 1，当前方差var_t 为0</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">     第一个特征（3个1）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br><span class="line">同理，第二个特征（3个2）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br><span class="line">同理，第三个特征（3个3）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br><span class="line">同理，第二个特征（3个4）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br><span class="line">同理，第三个特征（3个5）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br></pre></td></tr></table></figure><p>下面看第二次迭代的时候：momentum = 0.3，pre_running_var = 0.7，当前方差var_t 为0</p><pre><code>     第一个特征（3个1）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；同理，第二个特征（3个2）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；同理，第三个特征（3个3）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；同理，第二个特征（3个4）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；同理，第三个特征（3个5）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；</code></pre><h2 id="2D"><a href="#2D" class="headerlink" title="2D"></a>2D</h2><p> ·nn.BatchNorm2d input=B* 特征数* 2d特征 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630223117775.png" alt="1630223117775" style="zoom:67%;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">batch_size = 3               # X轴长度</span><br><span class="line">num_features = 3             # Y轴长度</span><br><span class="line">momentum = 0.3   </span><br><span class="line">features_shape = (2, 2)  #   每个图形大小</span><br></pre></td></tr></table></figure><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224409278.png" alt="1630224409278" style="zoom:60%;"><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224422110.png" alt="1630224422110" style="zoom:80%;"><p>由于特征数num_features 是3，所以四个属性的shape也是3. 计算结果和1D一样。</p><h2 id="3D"><a href="#3D" class="headerlink" title="3D"></a>3D</h2><p> ·nn.BatchNorm3d input=B* 特征数* 3d特征 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224639302.png" alt="1630224639302" style="zoom:67%;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">batch_size = 3</span><br><span class="line">num_features = 4</span><br><span class="line">momentum = 0.3</span><br><span class="line">features_shape = (2, 2, 3)     # 上图代码表示。</span><br></pre></td></tr></table></figure><p> 上述一个特征的维度是2 * 2 * 3，每个特征有4个特征数，总共有3个样本 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224866710.png" alt="1630224866710" style="zoom:85%;"><h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><h2 id="1-Layer-Normalization"><a href="#1-Layer-Normalization" class="headerlink" title="1.Layer Normalization"></a>1.Layer Normalization</h2><p> 起因：BN不适用于变长的网络，如RNN  ，特征数长短不一。</p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224982805.png" alt="1630224982805" style="zoom:80%;"><p> 思路：逐层计算均值和方差，按下图三个圈圈来计算 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225024395.png" alt="1630225024395" style="zoom:80%;"><h2 id="2-Instance-Normalization"><a href="#2-Instance-Normalization" class="headerlink" title="2.Instance Normalization"></a>2.Instance Normalization</h2><p> 起因：BN在图像生成（lmage Generation）中不适用 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225208910.png" alt="1630225208910" style="zoom:80%;"><p> 思路：逐Instance（channel）计算均值和方差 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225260732.png" alt="1630225260732" style="zoom:80%;"><p>nn.InstanceNorm主要参数（和bn一样，所以InstanceNorm也有1d，2d，3d，这里就不赘述了）：<br>·num_features：一个样本特征数量（最重要）<br>·eps：分母修正项<br>·momentum：指数加权平均估计当前mean/var<br>·affine：是否需要affine transform<br>·track_running_stats：是训练状态，还是测试状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import numpy as np</span><br><span class="line">import torch.nn as nn</span><br><span class="line">torch.manual_seed(9)  # 设置随机种子</span><br><span class="line"></span><br><span class="line"># ======================================== nn.layer norm</span><br><span class="line">flag = 1</span><br><span class="line">if flag:</span><br><span class="line">    batch_size = 3</span><br><span class="line">    num_features = 3</span><br><span class="line">    momentum = 0.3</span><br><span class="line"></span><br><span class="line">    features_shape = (2, 2)#设置这个大小是和上面图片一样</span><br><span class="line"></span><br><span class="line">    feature_map = torch.ones(features_shape)    # 2D</span><br><span class="line">    feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)  # 3D</span><br><span class="line">    feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)  # 4D</span><br><span class="line"></span><br><span class="line">    print(&quot;Instance Normalization&quot;)#打印输入数据</span><br><span class="line">    print(&quot;input data:\n&#123;&#125; \n shape is &#123;&#125;\n&quot;.format(feature_maps_bs, feature_maps_bs.shape))</span><br><span class="line"></span><br><span class="line">    instance_n = nn.InstanceNorm2d(num_features=num_features, momentum=momentum)</span><br><span class="line"></span><br><span class="line">    for i in range(1):</span><br><span class="line">        outputs = instance_n(feature_maps_bs)</span><br><span class="line"></span><br><span class="line">        print(outputs)</span><br><span class="line">        print(&quot;\niter:&#123;&#125;, running_mean.shape: &#123;&#125;&quot;.format(i, bn.running_mean.shape))</span><br><span class="line">        print(&quot;iter:&#123;&#125;, running_var.shape: &#123;&#125;&quot;.format(i, bn.running_var.shape))</span><br><span class="line">        print(&quot;iter:&#123;&#125;, weight.shape: &#123;&#125;&quot;.format(i, bn.weight.shape))</span><br><span class="line">        print(&quot;iter:&#123;&#125;, bias.shape: &#123;&#125;&quot;.format(i, bn.bias.shape))</span><br></pre></td></tr></table></figure><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225515365.png" alt="1630225515365" style="zoom: 67%;"><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225585148.png" alt="1630225585148" style="zoom:67%;">]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Batch-Normalization-概念&quot;&gt;&lt;a href=&quot;#Batch-Normalization-概念&quot; class=&quot;headerlink&quot; title=&quot;Batch Normalization 概念&quot;&gt;&lt;/a&gt;Batch Normalization </summary>
      
    
    
    
    <category term="深度学习（第一层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>归一化</title>
    <link href="http://example.com/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/"/>
    <id>http://example.com/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/</id>
    <published>2021-08-29T03:32:18.758Z</published>
    <updated>2021-08-29T04:50:08.738Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一-本文的内容包括："><a href="#一-本文的内容包括：" class="headerlink" title="一. 本文的内容包括："></a>一. 本文的内容包括：</h3><pre><code>   1. Batch Normalization，其论文：https://arxiv.org/pdf/1502.03167.pdf   2. Layer Normalizaiton，其论文：https://arxiv.org/pdf/1607.06450v1.pdf3. Instance Normalization，其论文：https://arxiv.org/pdf/1607.08022.pdf4. Group Normalization，其论文：https://arxiv.org/pdf/1803.08494.pdf5. Switchable Normalization，其论文：https://arxiv.org/pdf/1806.10779.pdf</code></pre><h3 id="二-介绍"><a href="#二-介绍" class="headerlink" title="二. 介绍"></a>二. 介绍</h3><p>​    在介绍各个算法之前，我们先引进一个问题：为什么要做归一化处理？</p><p>神经网络学习过程的本质就是为了学习数据分布，如果我们没有做归一化处理，那么每一批次训练数据的分布不一样，从大的方向上看，神经网络则需要在这多个分布中找到平衡点，从小的方向上看，由于每层网络输入数据分布在不断变化，这也会导致每层网络在找平衡点，显然，神经网络就很难收敛了。当然，如果我们只是对输入的数据进行归一化处理（比如将输入的图像除以255，将其归到0到1之间），只能保证输入层数据分布是一样的，并不能保证每层网络输入数据分布是一样的，所以也需要在神经网络的中间层加入归一化处理。</p><p>BN、LN、IN和GN这四个归一化的计算流程几乎是一样的，可以分为四步：</p><p>  1.计算出均值</p><p>  2.计算出方差</p><p>  3.归一化处理到均值为0，方差为1</p><p>  4.变化重构，恢复出这一层网络所要学到的分布           </p><p>​                 (尺度变换和偏移：将x_i乘以γ 调整数值大小，再加上β增加偏移后得到y_i ，这里的γ是尺度因子，β是平移因子。这一步是BN的精髓，由于归一化后的 x_i 基本会被限制在正态分布下，使得网络的表达能力下降。为解决该问题，我们引入两个新的参数：γ , β γ,β<em>γ</em>,<em>β</em>。 γ γ<em>γ</em>和β β<em>β</em>是在训练时网络自己学习得到的。)</p><img src="/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/1630208171755.png" alt="1630208171755" style="zoom:67%;"><p> 训练的时候，是根据输入的每一批数据来计算均值和方差，那么测试的时候，平均值和方差是怎么来的？</p><p>对于均值来说直接计算所有训练时batch 均值的平均值；然后对于标准偏差采用每个batch 方差的无偏估计</p><img src="/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/1630208372638.png" alt="1630208372638" style="zoom:67%;"><p>接下来，我们先用一个示意图来形象的表现BN、LN、IN和GN的区别（图片来自于GN这一篇论文），在输入图片的维度为（NCHW）中，HW是被合成一个维度，这个是方便画出示意图，C和N各占一个维度</p><p><img src="/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/1630208469512.png" alt="1630208469512"></p><p> Batch Normalization：</p><p>   1.BN的计算就是把每个通道的NHW单独拿出来归一化处理</p><p>   2.针对每个channel我们都有一组γ,β，所以可学习的参数为2*C</p><p>   3.当batch size越小，BN的表现效果也越不好，因为计算过程中所得到的均值和方差不能代表全局</p><p>Layer Normalizaiton：</p><p>   1.LN的计算就是把每个CHW单独拿出来归一化处理，不受batchsize 的影响</p><p>   2.常用在RNN网络，但如果输入的特征区别很大，那么就不建议使用它做归一化处理</p><p>Instance Normalization</p><p>   1.IN的计算就是把每个HW单独拿出来归一化处理，不受通道和batchsize 的影响</p><p>   2.常用在风格化迁移，但如果特征图可以用到通道之间的相关性，那么就不建议使用它做归一化处理</p><p>Group Normalization</p><p>1.GN的计算就是把先把通道C分成G组，然后把每个gHW单独拿出来归一化处理，最后把G组归一化之后的数据合并成CHW</p><p>2.GN介于LN和IN之间，当然可以说LN和IN就是GN的特列，比如G的大小为1或者为C</p><p>Switchable Normalization</p><p>1.将 BN、LN、IN 结合，赋予权重，让网络自己去学习归一化层应该使用什么方法</p><p>2.集万千宠爱于一身，但训练复杂</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一-本文的内容包括：&quot;&gt;&lt;a href=&quot;#一-本文的内容包括：&quot; class=&quot;headerlink&quot; title=&quot;一. 本文的内容包括：&quot;&gt;&lt;/a&gt;一. 本文的内容包括：&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;   1. Batch Normalization，其论</summary>
      
    
    
    
    <category term="深度学习（第一层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>在深度学习中Python常用模块</title>
    <link href="http://example.com/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/"/>
    <id>http://example.com/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/</id>
    <published>2021-08-20T07:20:00.000Z</published>
    <updated>2021-08-29T03:33:17.411Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1、OS模块"><a href="#1、OS模块" class="headerlink" title="1、OS模块"></a>1、OS模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">os.getcwd()//获取当前工作的目录，如：返回结果为：&#x27;C:\\Program Files\\Python36&#x27;</span><br><span class="line">os.listdir(path)//列出path目录下所有的文件和目录名。Path参数可以省略,如：os.listdir(&quot;.&quot;)</span><br><span class="line">os.remove(path)//删除path指定的文件，该参数不能省略。</span><br><span class="line">os.rmdir(path)//删除path指定的目录，该参数不能省略。</span><br><span class="line">os.mkdir(path)//创建path指定的目录，该参数不能省略。递归建立可用：os.makedirs()</span><br><span class="line">os.path.split(path)//返回路径的目录和文件名，即将目录和文件名分开，而不是一个整体。此处只是把前后两部分分开而已。就是找最后一个&#x27;/&#x27;。</span><br><span class="line">os.path.join(path, name)//连接目录和文件名，与os.path.split(path)相对。</span><br><span class="line">os.chdir(path)//&#x27;change dir&#x27;改变目录到指定目录</span><br><span class="line">os.path.basename(path)//返回文件名</span><br><span class="line">os.path.dirname(path)//返回文件路径</span><br><span class="line">os.walk(path)//返回的是一个三元组(root,dirs,files):</span><br><span class="line">&#123;root 所指的是当前正在遍历的这个文件夹的本身的地址</span><br><span class="line">dirs 是一个 list ，内容是该文件夹中所有的目录的名字(不包括子目录)</span><br><span class="line">files 同样是 list , 内容是该文件夹中所有的文件(不包括子目录)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2、sys模块"><a href="#2、sys模块" class="headerlink" title="2、sys模块"></a>2、sys模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sys.path.insert(0,path)//使用sys.path.insert()方法可以临时添加搜索路径，方便更简洁的import其他包和模块。</span><br></pre></td></tr></table></figure><h2 id="3、pandas模块"><a href="#3、pandas模块" class="headerlink" title="3、pandas模块"></a>3、pandas模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">df：任意的Pandas DataFrame对象，一个类似于一维数组的对象，它有一个数组标签，也称之为索引 (index)</span><br><span class="line">s：任意的Pandas Series对象，类似于一个表格</span><br><span class="line"></span><br><span class="line">导入数据----------pd</span><br><span class="line"></span><br><span class="line">pd.read_csv(filename)//从CSV文件导入数据</span><br><span class="line">pd.read_json(json_string)//从JSON格式的字符串导入数据</span><br><span class="line">pd.DataFrame(dict)//从字典对象导入数据，Key是列名，Value是数据</span><br><span class="line">pd.read_excel(filename)//从Excel文件导入数据</span><br><span class="line"></span><br><span class="line">导出数据----------df.to</span><br><span class="line"></span><br><span class="line">df.to_csv(filename)//导出数据到CSV文件</span><br><span class="line">df.to_excel(filename)//导出数据到Excel文件</span><br><span class="line">df.to_json(filename)//以Json格式导出数据到文本文件</span><br><span class="line"></span><br><span class="line">创建测试对象</span><br><span class="line"></span><br><span class="line">pd.DataFrame(np.random.rand(20,5))//创建20行5列的随机数组成的DataFrame对象</span><br><span class="line">pd.Series(my_list)//从可迭代对象my_list创建一个Series对象</span><br><span class="line"></span><br><span class="line">查看、检查数据</span><br><span class="line"></span><br><span class="line">df.head(n)//查看DataFrame对象的前n行</span><br><span class="line">df.tail(n)//查看DataFrame对象的最后n行</span><br><span class="line">df.shape()//查看行数和列数</span><br><span class="line">df.info()//查看索引、数据类型和内存信息</span><br><span class="line"></span><br><span class="line">数据选取</span><br><span class="line"></span><br><span class="line">df[col]//根据列名，并以Series的形式返回列</span><br><span class="line">df[[col1, col2]]//以DataFrame形式返回多列</span><br><span class="line">s.iloc[0]//按位置选取数据</span><br><span class="line">s.loc[&#x27;index_one&#x27;]//按索引选取数据</span><br><span class="line">df.iloc[0,:]//返回第一行</span><br><span class="line">df.iloc[0,0]//返回第一列的第一个元素</span><br><span class="line">df.values[:,:-1]//返回除了最后一列的其他列的所以数据</span><br><span class="line">df.query(&#x27;[1, 2] not in c&#x27;)//返回c列中不包含1，2的其他数据集</span><br><span class="line"></span><br><span class="line">数据处理</span><br><span class="line"></span><br><span class="line">df[df[col] &gt; 0.5]//选择col列的值大于0.5的行</span><br><span class="line">df.sort_values(col1)//按照列col1排序数据，默认升序排列</span><br><span class="line">df.sort_values(col2, ascending=False)//按照列col1降序排列数据</span><br><span class="line">df.sort_values([col1,col2], ascending=[True,False])//先按列col1升序排列，后按col2降序排列数据</span><br><span class="line">df1.append(df2)//将df2中的行添加到df1的尾部</span><br><span class="line">df.concat([df1, df2],axis=1)//将df2中的列添加到df1的尾部</span><br><span class="line">df1.join(df2,on=col1,how=&#x27;inner&#x27;)//对df1的列和df2的列执行SQL形式的join</span><br><span class="line"></span><br><span class="line">数据统计</span><br><span class="line"></span><br><span class="line">df.describe()//查看数据值列的汇总统计</span><br><span class="line">df.mean()//返回所有列的均值</span><br><span class="line">df.corr()//返回列与列之间的相关系数</span><br><span class="line">df.count()//返回每一列中的非空值的个数</span><br><span class="line">df.max()//返回每一列的最大值</span><br><span class="line">df.min()//返回每一列的最小值</span><br><span class="line">df.median()//返回每一列的中位数</span><br><span class="line">df.std()//返回每一列的标准差</span><br></pre></td></tr></table></figure><h2 id="4、Numpy模块"><a href="#4、Numpy模块" class="headerlink" title="4、Numpy模块"></a>4、Numpy模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line">创建数组array</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">a = np.array([1,2,3])   #创建数组</span><br><span class="line">b = np.array([(1.5,2,3), (4,5,6)],dtype=float)</span><br><span class="line">c = np.array([(1.5,2,3), (4,5,6)],[(3,2,1), (4,5,6) ] ], dtype=float)</span><br><span class="line"></span><br><span class="line">np.zeros((3,4))  #创建0数组</span><br><span class="line">np.ones((2,3,4), dtype=np.int16)  #创建1数组</span><br><span class="line">d = np.arrange(10,25,5)  #创建相同步数数组</span><br><span class="line">np.linspace(0,2,9)  #创建等差数组</span><br><span class="line"></span><br><span class="line">e = np.full((2,2), 7) #创建常数数组</span><br><span class="line">f = np.eye(2) #创建2x2矩阵</span><br><span class="line">np.random.random((2,2)) #创建随机数组</span><br><span class="line">np.empty((3,2)) #创建空数组</span><br><span class="line"></span><br><span class="line">复制数组</span><br><span class="line"></span><br><span class="line">h = a.view()</span><br><span class="line">np.copy(a)</span><br><span class="line">h = a.copy()</span><br><span class="line"></span><br><span class="line">输出数组</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">print(my_array) #打印数组</span><br><span class="line"></span><br><span class="line">#saving &amp;Loading on disk保存到磁盘</span><br><span class="line">np.save(&#x27;my_array&#x27;, a)</span><br><span class="line">np.savez(&#x27;array.npz&#x27;, a, b)</span><br><span class="line">np.load(&#x27;my_array.npy&#x27;)</span><br><span class="line"></span><br><span class="line">#saving &amp;Loading Text files保存到文件</span><br><span class="line">np.loadtxt(&quot;my file.txt&quot;)</span><br><span class="line">np.genfromtxt(&quot;my_file.csv&quot;, delimiter=&#x27;,&#x27;)</span><br><span class="line">np.savetxt(&quot;marry.txt&quot;, a, delimiter=&quot;&quot;)</span><br><span class="line"></span><br><span class="line">Numpy中的基本运算</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">#arithmetic operation算术运算</span><br><span class="line">g = a - b</span><br><span class="line">np.subtract(a,b) #减法</span><br><span class="line">b+a</span><br><span class="line">np.add(b,a) #加法</span><br><span class="line">a / b</span><br><span class="line">np.divide(a,b) #除法</span><br><span class="line">a * b</span><br><span class="line">np.multiple(a,b) #乘法</span><br><span class="line">np.exp(b) #指数</span><br><span class="line">np.sqrt(b) #开方</span><br><span class="line">np.sin(a) #sin函数</span><br><span class="line">np.cos(b) #cos函数</span><br><span class="line">np.log(a) #log函数</span><br><span class="line">e.dot(f) #内积</span><br><span class="line"></span><br><span class="line">#Comparison比较</span><br><span class="line">a == b #元素</span><br><span class="line">a &lt; 2 #元素</span><br><span class="line">np.array_equal(a,b) #数组</span><br><span class="line"></span><br><span class="line">#Aggregate Functions 函数</span><br><span class="line">a.sum() #求和</span><br><span class="line">b.min() #最小值</span><br><span class="line">b.max(axis=0) #最大值数组列</span><br><span class="line">b.cumsum(axis=1) #元素累加和</span><br><span class="line">a.mean() #平均值</span><br><span class="line">b.median() #中位数</span><br><span class="line">a.corrcoef() #相关系数</span><br><span class="line">np.std(b) #标准差</span><br><span class="line"></span><br><span class="line">数组处理</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">#Transposing Array</span><br><span class="line">I = np.transpose(b) #转置矩阵</span><br><span class="line">i.T #转置矩阵</span><br><span class="line"></span><br><span class="line">#Changing Array Shape</span><br><span class="line">b.ravel() #降为一维数组</span><br><span class="line">g.reshape(3,-2) #重组</span><br><span class="line"></span><br><span class="line">#Adding/Removing Elements</span><br><span class="line">h.resize((2,6)) #返回shape(2,6)</span><br><span class="line">np.append(h,g) #添加</span><br><span class="line">np.insert(a,1,5) #插入</span><br><span class="line">np.delete(a,[1]) #删除</span><br><span class="line"></span><br><span class="line">#Combining Arrays</span><br><span class="line">np.concatenate((a,d), axis=0) #连结</span><br><span class="line">np.vstack((a,b)) #垂直堆叠</span><br><span class="line">np.r_[e,f] #垂直堆叠</span><br><span class="line">np.hstack((e,f)) #水平堆叠</span><br><span class="line">np.column_stack((a,d)) #创建水平堆叠</span><br><span class="line">np.c_[a,d] ##创建水平堆叠</span><br><span class="line"></span><br><span class="line">#splitting arrays</span><br><span class="line">np.hsplit(a,3) #水平分离</span><br><span class="line">np.vsplit(c,2) #垂直分离</span><br><span class="line"></span><br><span class="line">数组索引</span><br><span class="line">import numpy as np</span><br><span class="line">#subsetting</span><br><span class="line">a[2] #选取数组第三个元素</span><br><span class="line">b[1,2] #选取2行3列元素</span><br><span class="line"></span><br><span class="line">#slicing</span><br><span class="line">a[0:2] #选1到3元素</span><br><span class="line">b[0:2,1] #选1到2行的2列元素</span><br><span class="line">b[:1] #选所有1行的元素</span><br><span class="line">c[1,...] #c[1,:,:]</span><br><span class="line">a[ : :-1]  #反转数组</span><br><span class="line"></span><br><span class="line">#Boolean Indexing</span><br><span class="line">a[a&lt;2] #选取数组中元素&lt;2的</span><br><span class="line"></span><br><span class="line">#Fancy Indexing</span><br><span class="line">b[[1,0,1,0], [0,1,2,0]]</span><br><span class="line">#选取[1,0],[0,1],[1,2],[0,0]</span><br><span class="line">b[[1,0,1,0][:, [0,1,2,0]]]</span><br><span class="line">#选取矩阵的一部分</span><br><span class="line"></span><br><span class="line">Numpy中的数据类型</span><br><span class="line"></span><br><span class="line">np.int64 #64位整数</span><br><span class="line">np.float32 #标准双精度浮点</span><br><span class="line">np.complex #复杂树已浮点128为代表</span><br><span class="line">np.bool #true&amp;false</span><br><span class="line">np.object #python object</span><br><span class="line">np.string_ #固定长度字符串</span><br><span class="line">np.unicode_ #固定长度统一码</span><br><span class="line"></span><br><span class="line">检查数组信息</span><br><span class="line">a.shape #数组维度</span><br><span class="line">len(a) #数组长度</span><br><span class="line">b.ndim #数组维度数量</span><br><span class="line">e.size #数组元素数量</span><br><span class="line">b.dtype #元素数据类型</span><br><span class="line">b.dtype.name #数据类型名</span><br><span class="line">b.astype(int) #改变数组类型</span><br><span class="line"></span><br><span class="line">#asking for help更多信息</span><br><span class="line">np.info(np.ndarray.dtype)</span><br><span class="line"></span><br><span class="line">对数组进行排序</span><br><span class="line"></span><br><span class="line">#对数组进行排序</span><br><span class="line">a.sort()</span><br><span class="line">c.sort(axis=0)</span><br></pre></td></tr></table></figure><h2 id="5、matplotlib模块"><a href="#5、matplotlib模块" class="headerlink" title="5、matplotlib模块"></a>5、matplotlib模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">plt.figure(num=None,</span><br><span class="line">figsize=None, </span><br><span class="line"> dpi=None,</span><br><span class="line"> facecolor=None, </span><br><span class="line">  edgecolor=None, </span><br><span class="line">  frameon=True, </span><br><span class="line">  FigureClass=&lt;class &#x27;matplotlib.figure.Figure&#x27;&gt;, </span><br><span class="line">  clear=False, **kwargs)</span><br><span class="line">  num：整数或字符串，可选，默认:无</span><br><span class="line">  figsize：(float, float), optional, default: None</span><br><span class="line">  dpi：图形分辨率，整数，可选，默认:无</span><br><span class="line">  facecolor：背景颜色</span><br><span class="line">  edgecolor：边框颜色</span><br><span class="line">  frameon：bool，可选，默认值:True//如果为False，则禁止绘制图形框</span><br><span class="line">  FigureClass：图的子类</span><br><span class="line">  clear：bool，可选，默认值:True如果为True且该图片已经存在，则清除它。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.imshow()</span><br><span class="line"></span><br><span class="line">plt.imshow(X, </span><br><span class="line">cmap=None,</span><br><span class="line"> norm=None, </span><br><span class="line"> aspect=None, </span><br><span class="line"> interpolation=None, </span><br><span class="line"> alpha=None, </span><br><span class="line"> vmin=None, </span><br><span class="line"> vmax=None, </span><br><span class="line"> origin=None, </span><br><span class="line"> extent=None, </span><br><span class="line"> shape=&lt;deprecated parameter&gt;, </span><br><span class="line"> filternorm=1, </span><br><span class="line"> filterrad=4.0,</span><br><span class="line"> imlim=&lt;deprecated parameter&gt;, </span><br><span class="line"> resample=None, </span><br><span class="line"> url=None, </span><br><span class="line"> *, </span><br><span class="line"> data=None, </span><br><span class="line"> **kwargs)</span><br><span class="line">X：图像数据</span><br><span class="line">cmap：str或Colormap，可选</span><br><span class="line">norm：正常化,可选</span><br><span class="line">aspect：&#123;&#x27;equal&#x27;， &#x27;auto&#x27;&#125;或float，可选‘equal’:确保长宽比为1；’auto‘：自动调整长宽</span><br><span class="line">interpolation：str,可选 &#x27;none&#x27;, &#x27;nearest&#x27;, &#x27;bilinear&#x27;, &#x27;bicubic&#x27;, &#x27;spline16&#x27;, &#x27;spline36&#x27;, &#x27;hanning&#x27;, &#x27;hamming&#x27;, </span><br><span class="line">&#x27;hermite&#x27;, &#x27;kaiser&#x27;, &#x27;quadric&#x27;, &#x27;catrom&#x27;, &#x27;gaussian&#x27;, &#x27;bessel&#x27;, &#x27;mitchell&#x27;, &#x27;sinc&#x27;, &#x27;lanczos&#x27;</span><br><span class="line">alpha：比例,可选介于0(透明)和1(不透明)之间</span><br><span class="line">vmin, vmax：比例,可选当使用标量数据而没有明确的norm时，vmin和vmax定义了颜色映射所涵盖的数据范围</span><br><span class="line">origin： &#123;&#x27;upper&#x27;, &#x27;lower&#x27;&#125;，可选的</span><br><span class="line"></span><br><span class="line">plt.subplot()</span><br><span class="line"></span><br><span class="line">plt.subplot(nrows,ncols,index,**kwargs)</span><br><span class="line">子图将在包含nrows行和ncols列的网格中占据索引位置。index从左上角的1开始，向右递增</span><br><span class="line"></span><br><span class="line">plt.plot()</span><br><span class="line"></span><br><span class="line">plt.plot(x,y,format_string,**kwargs)</span><br><span class="line">x轴数据，</span><br><span class="line">y轴数据，</span><br><span class="line">format_string控制曲线的格式字串 ，format_string由颜色字符，风格字符，和标记字符 </span><br><span class="line">&#x27;b&#x27;blue</span><br><span class="line">&#x27;g&#x27;green</span><br><span class="line">&#x27;r&#x27;red</span><br><span class="line">&#x27;c&#x27;cyan</span><br><span class="line">&#x27;m&#x27;magenta</span><br><span class="line">&#x27;y&#x27;yellow</span><br><span class="line">&#x27;k&#x27;black</span><br><span class="line">&#x27;w&#x27;white</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="6、argparse模块"><a href="#6、argparse模块" class="headerlink" title="6、argparse模块"></a>6、argparse模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">##创建解析器</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=&#x27;Process some integers.&#x27;)</span><br><span class="line"></span><br><span class="line">该ArgumentParser对象将保存将命令行解析为 Python 数据类型所需的所有信息。</span><br><span class="line"></span><br><span class="line">## 添加参数</span><br><span class="line"></span><br><span class="line">ArgumentParser通过调用add_argument() 方法来填充有关程序参数的信息。通常，这些调用告诉ArgumentParser 如何在命令行上获取字符串并将它们转换为对象。该信息在parse_args()被调用时被存储和使用。例如：</span><br><span class="line"> parser.add_argument(&#x27;integers&#x27;, metavar=&#x27;N&#x27;, type=int, nargs=&#x27;+&#x27;,</span><br><span class="line">                    help=&#x27;an integer for the accumulator&#x27;)</span><br><span class="line"> parser.add_argument(&#x27;--sum&#x27;, dest=&#x27;accumulate&#x27;, action=&#x27;store_const&#x27;,</span><br><span class="line">                     const=sum, default=max,</span><br><span class="line">                     help=&#x27;sum the integers (default: find the max)&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 解析参数</span><br><span class="line"></span><br><span class="line">ArgumentParser 通过parse_args()方法解析参数 。这将检查命令行，将每个参数转换为适当的类型，然后调用适当的操作。</span><br><span class="line"></span><br><span class="line"> config = parser.parse_args()</span><br><span class="line"></span><br><span class="line">在脚本中，parse_args()通常会不带参数地调用，并且将自动从确定命令行参数sys.argv</span><br><span class="line"></span><br><span class="line">## ArgumentParser 对象----代码只用到了三个</span><br><span class="line"></span><br><span class="line">argparse.addP_ArgumentParser( *prog=None* , *usage=None* , *description=None* , *epilog=None* , *parents=[]* , *formatter_class=argparse.HelpFormatter* , *prefix_chars=&#x27;-&#x27;* , *fromfile_prefix_chars=None* , *argument_default=None* , *conflict_handler=&#x27;error&#x27;* , *add_help =True* , *allow_abbrev=True* , *exit_on_error=True* ) </span><br><span class="line"></span><br><span class="line">  创建一个新ArgumentParser对象。所有参数都应作为关键字参数传递。每个参数在下面都有更详细的描述，但简而言之，它们是：</span><br><span class="line"></span><br><span class="line">  PROG -程序的名称（默认：`sys.argv[0]`）</span><br><span class="line"></span><br><span class="line">  description- 在参数帮助之前显示的文本（默认值：无）</span><br><span class="line"></span><br><span class="line">  argument_default -为参数的全局默认值（默认值：`None`）</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="7、PIL库—处理图像"><a href="#7、PIL库—处理图像" class="headerlink" title="7、PIL库—处理图像"></a>7、PIL库—处理图像</h2><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629444947068.png" alt="1629444947068"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629444960440.png" alt="1629444960440"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629444979009.png" alt="1629444979009"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629445020254.png" alt="1629445020254"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629445055246.png" alt="1629445055246"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629445103852.png" alt="1629445103852"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629445114582.png" alt="1629445114582"></p><h2 id="8、pytorch读取数据"><a href="#8、pytorch读取数据" class="headerlink" title="8、pytorch读取数据"></a>8、pytorch读取数据</h2><p>具体细节看—<a href="https://zhuanlan.zhihu.com/p/30934236">https://zhuanlan.zhihu.com/p/30934236</a></p><h2 id="9-itertools库"><a href="#9-itertools库" class="headerlink" title="9.itertools库"></a>9.itertools库</h2><p> &emsp;&emsp;迭代器（生成器）在Python中是一种很常用也很好用的数据结构，比起列表(list)来说，迭代器最大的优势就是延迟计算，按需使用，从而提高开发体验和运行效率，以至于在Python 3中map,filter等操作返回的不再是列表而是迭代器。 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line">itertools.accumulate</span><br><span class="line"></span><br><span class="line">简单来说就是累加。</span><br><span class="line">&gt;&gt;&gt; import itertools</span><br><span class="line">&gt;&gt;&gt; x = itertools.accumulate(range(10))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 1, 3, 6, 10, 15, 21, 28, 36, 45]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.chain</span><br><span class="line"></span><br><span class="line">连接多个列表或者迭代器。</span><br><span class="line">&gt;&gt;&gt; x = itertools.chain(range(3), range(4), [3,2,1])</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 1, 2, 0, 1, 2, 3, 3, 2, 1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.combinations</span><br><span class="line"></span><br><span class="line">求列表或生成器中指定数目的元素不重复的所有组合</span><br><span class="line">&gt;&gt;&gt; x = itertools.combinations(range(4), 3)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(0, 1, 2), (0, 1, 3), (0, 2, 3), (1, 2, 3)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.combinations_with_replacement</span><br><span class="line"></span><br><span class="line">允许重复元素的组合</span><br><span class="line">&gt;&gt;&gt; x = itertools.combinations_with_replacement(&#x27;ABC&#x27;, 2)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(&#x27;A&#x27;, &#x27;A&#x27;), (&#x27;A&#x27;, &#x27;B&#x27;), (&#x27;A&#x27;, &#x27;C&#x27;), (&#x27;B&#x27;, &#x27;B&#x27;), (&#x27;B&#x27;, &#x27;C&#x27;), (&#x27;C&#x27;, &#x27;C&#x27;)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.compress</span><br><span class="line">按照真值表筛选元素</span><br><span class="line">&gt;&gt;&gt; x = itertools.compress(range(5), (True, False, True, True, False))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 2, 3]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.count</span><br><span class="line"></span><br><span class="line">就是一个计数器,可以指定起始位置和步长</span><br><span class="line">&gt;&gt;&gt; x = itertools.count(start=20, step=-1)</span><br><span class="line">&gt;&gt;&gt; print(list(itertools.islice(x, 0, 10, 1)))</span><br><span class="line">[20, 19, 18, 17, 16, 15, 14, 13, 12, 11]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.cycle</span><br><span class="line"></span><br><span class="line">循环指定的列表和迭代器</span><br><span class="line">&gt;&gt;&gt; x = itertools.cycle(&#x27;ABC&#x27;)</span><br><span class="line">&gt;&gt;&gt; print(list(itertools.islice(x, 0, 10, 1)))</span><br><span class="line">[&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;A&#x27;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.dropwhile</span><br><span class="line"></span><br><span class="line">按照真值函数丢弃掉列表和迭代器前面的元素</span><br><span class="line">&gt;&gt;&gt; x = itertools.dropwhile(lambda e: e &lt; 5, range(10))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[5, 6, 7, 8, 9]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.filterfalse</span><br><span class="line"></span><br><span class="line">保留对应真值为False的元素</span><br><span class="line">&gt;&gt;&gt; x = itertools.filterfalse(lambda e: e &lt; 5, (1, 5, 3, 6, 9, 4))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[5, 6, 9]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.groupby</span><br><span class="line"></span><br><span class="line">按照分组函数的值对元素进行分组</span><br><span class="line">&gt;&gt;&gt; x = itertools.groupby(range(10), lambda x: x &lt; 5 or x &gt; 8)                                                                                                </span><br><span class="line">&gt;&gt;&gt; for condition, numbers in x:                                                  </span><br><span class="line">...     print(condition, list(numbers))                                                                                                        </span><br><span class="line">True [0, 1, 2, 3, 4]                                                              </span><br><span class="line">False [5, 6, 7, 8]                                                                </span><br><span class="line">True [9]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.islice</span><br><span class="line">上文使用过的函数，对迭代器进行切片</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x = itertools.islice(range(10), 0, 9, 2)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 2, 4, 6, 8]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.permutations</span><br><span class="line">产生指定数目的元素的所有排列(顺序有关)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x = itertools.permutations(range(4), 3)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(0, 1, 2), (0, 1, 3), (0, 2, 1), (0, 2, 3), (0, 3, 1), (0, 3, 2), (1, 0, 2), (1, 0, 3), (1, 2, 0), (1, 2, 3), (1, 3, 0), (1, 3, 2), (2, 0, 1), (2, 0,3), (2, 1, 0), (2, 1, 3), (2, 3, 0), (2, 3, 1), (3, 0, 1), (3, 0, 2), (3, 1, 0), (3, 1, 2), (3, 2, 0), (3, 2, 1)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.product</span><br><span class="line"></span><br><span class="line">产生多个列表和迭代器的(积)</span><br><span class="line">&gt;&gt;&gt; x = itertools.product(&#x27;ABC&#x27;, range(3))</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(&#x27;A&#x27;, 0), (&#x27;A&#x27;, 1), (&#x27;A&#x27;, 2), (&#x27;B&#x27;, 0), (&#x27;B&#x27;, 1), (&#x27;B&#x27;, 2), (&#x27;C&#x27;, 0), (&#x27;C&#x27;, 1), (&#x27;C&#x27;, 2)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.repeat</span><br><span class="line"></span><br><span class="line">简单的生成一个拥有指定数目元素的迭代器</span><br><span class="line">&gt;&gt;&gt; x = itertools.repeat(0, 5)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 0, 0, 0, 0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.starmap</span><br><span class="line"></span><br><span class="line">类似map</span><br><span class="line">&gt;&gt;&gt; x = itertools.starmap(str.islower, &#x27;aBCDefGhI&#x27;)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[True, False, False, False, True, True, False, True, False]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.takewhile</span><br><span class="line"></span><br><span class="line">与dropwhile相反，保留元素直至真值函数值为假。</span><br><span class="line">&gt;&gt;&gt; x = itertools.takewhile(lambda e: e &lt; 5, range(10))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 1, 2, 3, 4]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.tee</span><br><span class="line"></span><br><span class="line">生成指定数目的迭代器</span><br><span class="line">&gt;&gt;&gt; x = itertools.tee(range(10), 2)</span><br><span class="line">&gt;&gt;&gt; for letters in x:</span><br><span class="line">...     print(list(letters))</span><br><span class="line">...</span><br><span class="line">[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span><br><span class="line">[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.zip_longest</span><br><span class="line">类似于zip，不过已较长的列表和迭代器的长度为准</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x = itertools.zip_longest(range(3), range(5))</span><br><span class="line">&gt;&gt;&gt; y = zip(range(3), range(5))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(0, 0), (1, 1), (2, 2), (None, 3), (None, 4)]</span><br><span class="line">&gt;&gt;&gt; print(list(y))</span><br><span class="line">[(0, 0), (1, 1), (2, 2)]</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1、OS模块&quot;&gt;&lt;a href=&quot;#1、OS模块&quot; class=&quot;headerlink&quot; title=&quot;1、OS模块&quot;&gt;&lt;/a&gt;1、OS模块&lt;/h2&gt;&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=</summary>
      
    
    
    
    <category term="深度学习（第一层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="常用模块（第二层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>解读第四阶段素描GAN代码</title>
    <link href="http://example.com/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/"/>
    <id>http://example.com/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/</id>
    <published>2021-08-14T08:20:25.707Z</published>
    <updated>2021-09-01T05:47:35.578Z</updated>
    
    <content type="html"><![CDATA[<h1 id="填充和归一化"><a href="#填充和归一化" class="headerlink" title="填充和归一化"></a>填充和归一化</h1><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629449069633.png" alt="1629449069633"></p><p> **nn.ReflectionPad2d，使用输入边界的反射填充输入张量，与常规的零填充相比， 填充内容来自输入， 在GAN中使用比较常见。 **</p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629448984899.png" alt="1629448984899"></p><p> <code>torch.nn.Conv2d</code>( <em>in_channels</em> , <em>out_channels</em> , <em>kernel_size</em> , <em>stride=1</em> , <em>padding=0</em> , <em>dilation=1</em> , <em>groups=1</em> , <em>bias=True</em> , <em>padding_mode=’zeros’</em> , <em>device=None</em> , <em>dtype=None</em> ) </p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629449268090.png" alt="1629449268090"></p><p> <code>torch.nn.InstanceNorm2d</code>( <em>num_features</em> , <em>eps=1e-05</em> , <em>Momentum=0.1</em> , <em>affine=False</em> , <em>track_running_stats=False</em> , <em>device=None</em> , <em>dtype=None</em> ) ——第一个值：预期输入的大小。</p><p> 对于一个4D（N, C, H, W）张量，对于每个mini-batch (N)， 在每个通道 ( C ) 对每个二维张量 (H, W) 单独进行计算均值和方差。即对于一个（16，256， 128，128）的张量，计算16*256次均值方差。 </p><p> 对 4D 输入（具有附加通道维度的小批量 2D 输入）应用实例标准化 ，均值和标准差是针对小批量中的每个对象分别按维度计算的。 γ<em>γ</em> 和 β<em>β</em>是大小为C（其中C是输入大小）的可学习参数向量 </p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629450185909.png" alt="1629450185909"></p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629450464658.png" alt="1629450464658"></p><h1 id="生成器和判别器"><a href="#生成器和判别器" class="headerlink" title="生成器和判别器"></a>生成器和判别器</h1><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629461869476.png" alt="1629461869476"></p><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;生成器结构为上图。</p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629460495243.png" alt="1629460495243"></p><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;判别器结构为上图。</p><h2 id="生成器具体结构"><a href="#生成器具体结构" class="headerlink" title="生成器具体结构"></a>生成器具体结构</h2><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630393690709.png" alt="1630393690709"></p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630393705838.png" alt="1630393705838"></p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630393723184.png" alt="1630393723184"></p><h3 id="判别器具体结构"><a href="#判别器具体结构" class="headerlink" title="判别器具体结构"></a>判别器具体结构</h3><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630393831249.png" alt="1630393831249"></p><p>&emsp;&emsp;普通的GAN判别器最终输出一个向量，只需要输出一个表示整个图像评估的真或假，但PatchGAN的输出是一个N *N矩阵，每个元素如只有两个选择True或False，结果通常通过卷积层来实现。鉴别器对每个补丁进行真假判别，并取平均值作为最终鉴别器输出的图片结果。</p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629462224062.png" alt="1629462224062" style="zoom:50%;"><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;ResNet结构</p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629466487764.png" alt="1629466487764"></p><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;完整流程图</p><h1 id="优化器-Optimizer"><a href="#优化器-Optimizer" class="headerlink" title="优化器 Optimizer"></a>优化器 Optimizer</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prediction = wx + b             # b 是偏置量</span><br></pre></td></tr></table></figure><p>训练的过程，其实就是计算合适的w和b的过程。那么，什么样的w和b是“合适”的呢？答案就是预测值与真实值相差不大。例如定义损失函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = sum(|(y_ - prediction)|)</span><br></pre></td></tr></table></figure><p>即，真实值减去预测值，取绝对值后求和。训练的过程，可以粗略的理解成：调节 w 和 b， 使 loss 尽可能小。对w和b参数的调节，就是优化器（optimizer）需要做的，这就是优化器的作用。</p><p> <strong>在训练阶段， 每一次训练，神经网络参数都将得到一次拟合，达到一定次数后，才会收敛。而每次收敛的调整节奏，则取决于优化器</strong> </p><h2 id="优化器中的常用算法分为"><a href="#优化器中的常用算法分为" class="headerlink" title="优化器中的常用算法分为"></a>优化器中的常用算法分为</h2><p>（1）朴素梯度下降</p><ul><li><p>批量梯度下降法(Batch Gradient Descent )</p></li><li><p>随机梯度下降法（Stochastic Gradient Descent）</p></li><li><p>小批量随机梯度下降（Mini-Batch Gradient Descent）</p></li><li><p>带有动量的随机梯度下降(SGD with momentum)</p></li></ul><p>(2) 自适应梯度下降</p><ul><li> Adagrad （Adaptive gradient algorithm）</li><li> Adadelta/RMSProp</li><li> Adam（Adaptive Moment Estimation）</li><li> NAdam </li></ul><h3 id="Pytorch的十种优化器"><a href="#Pytorch的十种优化器" class="headerlink" title="Pytorch的十种优化器"></a>Pytorch的十种优化器</h3><p>1、optim.SGD：随机梯度下降法<br>2、optim.Adagrad：自适应学习率梯度下降法（对每个可学习参数具有1个自适应学习率）<br>3、optim.RMSprop：Adagrad的改进<br>4、optim.Adadelta：Adagrad的改进<br>5、optim.Adam：RMSprop结合Momentum<br>6、optim.Adamax：Adam增加学习率上限<br>7、optim.SparseAdam：稀疏版Adam<br>8、optim.ASGD：随机平均梯度下降<br>9、optim.Rprop：弹性反向传播（优化器应用场景在所有样本full_batch 一起计算梯度）<br>10、optim.LBFGS：BFGS的改进<br>原文链接：<a href="https://blog.csdn.net/qq_43784940/article/details/107955191">https://blog.csdn.net/qq_43784940/article/details/107955191</a></p><p><a href="https://www.cnblogs.com/peachtea/p/13532190.html">https://www.cnblogs.com/peachtea/p/13532190.html</a></p><p>torch为什么要使用optimizer.zero_grad() <a href="https://blog.csdn.net/scut_salmon/article/details/82414730">https://blog.csdn.net/scut_salmon/article/details/82414730</a></p><h3 id="1-批量梯度下降法-Batch-gradient-descent）"><a href="#1-批量梯度下降法-Batch-gradient-descent）" class="headerlink" title="1. 批量梯度下降法(Batch gradient descent）"></a><strong>1. 批量梯度下降法(Batch gradient descent</strong>）</h3><p><strong>更新规则</strong>：采用整个训练集的数据来计算loss函数对参数的梯度： </p><p><strong>优点</strong>：对于凸函数可以收敛到全局极小值，对于非凸函数可以收敛到局部极小值<br><strong>缺点</strong>：在一次更新中，对整个数据集计算梯度，计算速度很慢；如果数据集过大，则内存无法容纳；在模型训练过程中，无法使用新的数据更新模型。 </p><h3 id="2-随机梯度下降Stochastic-gradient-descent"><a href="#2-随机梯度下降Stochastic-gradient-descent" class="headerlink" title="2.随机梯度下降Stochastic gradient descent"></a><strong>2.随机梯度下降Stochastic gradient descent</strong></h3><p><strong>更新规则</strong>：SGD每次更新时对每个样本进行梯度下降。 </p><p> <strong>优点</strong>：对于很大的数据集来说，可能有很相似的样本，导致BGD在计算梯度时会出现冗余，而SGD一次只进行单样本更新，所以针对一次更新来说没有冗余，而且速度快<br><strong>缺点</strong>：更新频繁，造成loss函数严重震荡。  </p><p> BGD可以收敛到局部最小值，SGD的震荡也可能跳到更优的局部最小值。稍微减少learning rate，SGD和BGD收敛性一致，对凸函数和非凸函数能分别收敛到全局最优和局部最优。 </p><h3 id="3-小批量梯度下降Mini-batch-Stochastic-gradient-descent"><a href="#3-小批量梯度下降Mini-batch-Stochastic-gradient-descent" class="headerlink" title="3.小批量梯度下降Mini-batch Stochastic gradient descent"></a><strong>3.小批量梯度下降Mini-batch Stochastic gradient descent</strong></h3><p><strong>梯度更新规则</strong>：每一次更新使用一小批样本进行更新</p><p>和 SGD 的区别是每一次循环不是作用于每个样本，而是具有 n 个样本的批次。</p><p>优点：降低参数更新时的方差，收敛更稳定；可利用深度学习库中高度优化的矩阵操作来更有效的梯度计算<br><strong>缺点：</strong>MBSGD不能保证很好的收敛性，提供了一系列的挑战需要去解决：<br>1.选择合适的学习率十分困难。如果选择太小，收敛速度太慢；如果太大，loss函数会在极小值出震荡甚至发散。<br>2.学习率在训练过程中退火调整，学习率的减少根据提前确定好的计划或者当目标在两个轮次之间的变化低于一个阈值，计划和阈值必须要提前确定，因此不能适应数据集的特征。<br>3.对所有参数更新时应用同样的学习率，如果数据是稀疏的，更希望对出现频率低的特征进行大一点的更新。<br>4.对于非凸的误差函数，要避免陷入局部极小值以及鞍点处。鞍点周围的梯度都一样并且趋近于0，SGD不容易突破。</p><h3 id="4-含有动量的随机梯度下降法SGD-with-momentum"><a href="#4-含有动量的随机梯度下降法SGD-with-momentum" class="headerlink" title="4.含有动量的随机梯度下降法SGD with momentum"></a><strong>4.含有动量的随机梯度下降法SGD with momentum</strong></h3><p>SGD在山谷的情况下不容易导向，会多走一些弯路，山谷的曲面在某一个参数维度会比另外一个参数维度更陡峭，这种情况在局部最优解附近很常见。在这种场景下，SGD穿过山谷的斜坡时会震荡。 </p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630378142301.png" alt="1630378142301"></p><p>momentum能帮助加速SGD在确定方向的下降并且抑制震荡。<br>超参数一般设为0.9左右，意味着参数更新方向不仅由当前梯度决定，也与此前累计的下降方向有关，这使得momentum会增加更新某个维度下降方向不变的梯度，减少更新某个维度下降方向改变的梯度。因此获得了更快的收敛性和减少了震荡。</p><h3 id="5-AdaGrad"><a href="#5-AdaGrad" class="headerlink" title="5.AdaGrad"></a>5.AdaGrad</h3><p>针对SGD及Momentum存在的问题，2011年John Duchi等发布了AdaGrad（Adaptive Gradient，自适应梯度）优化算法，<strong>能够对每个不同参数调整不同的学习率，对频繁变化的参数以更小的步长进行更新，而稀疏的参数以更大的步长更新。</strong>对稀疏的数据表现很好，提高了SGD的鲁棒性。<br><strong>优点：</strong>能够为不同参数应不同的学习率，大多数学习率（<strong>η</strong>）使用0.01为默认值可实现较好的效果。<br><strong>缺点：</strong>分母项对梯度平方进行不断的累加，分母项越来越大，最终学习率收缩到无穷小使得无法进行有效更新。 </p><h3 id="6-Adadelta-RMSProp"><a href="#6-Adadelta-RMSProp" class="headerlink" title="6.Adadelta/RMSProp"></a>6.Adadelta/RMSProp</h3><p>为了解决AdaGrad单调递减的学习率急速下降的问题，考虑一个改变二阶动量计算方法的策略：不累积全部梯度，而只关注过去一段时间窗口的下降梯度，这就是delta中的来历。<br>采用计算梯度的指数移动平均数（Exponential Moving Average） ， 这个算法是对 Adagrad 的改进， </p><h3 id="7-Adam"><a href="#7-Adam" class="headerlink" title="7.Adam"></a><strong>7.Adam</strong></h3><p>可以认为是RMSprop和Momentum的结合。对一阶动量和二阶动量都采用指数移动平均计算。<br>默认为0.9,默认为0,999。在迭代初始阶段，和有一个向初值的偏移（过多偏向0），因此需要对一阶和二阶动量进行偏置校正（bias correction） </p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630378505616.png" alt="1630378505616"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;填充和归一化&quot;&gt;&lt;a href=&quot;#填充和归一化&quot; class=&quot;headerlink&quot; title=&quot;填充和归一化&quot;&gt;&lt;/a&gt;填充和归一化&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A</summary>
      
    
    
    
    <category term="深度学习（第一层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="代码解读（第二层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>Residual Attention Network</title>
    <link href="http://example.com/2021/08/04/Residual%20Attention%20Network/"/>
    <id>http://example.com/2021/08/04/Residual%20Attention%20Network/</id>
    <published>2021-08-04T04:16:21.000Z</published>
    <updated>2021-08-05T04:26:17.350Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1、论文全名-—-Residual-Attention-Network-for-Image-Classification"><a href="#1、论文全名-—-Residual-Attention-Network-for-Image-Classification" class="headerlink" title="1、论文全名 — Residual Attention Network for Image Classification"></a>1、论文全名 — Residual Attention Network for Image Classification</h1><h1 id="2、-emsp-整体结构"><a href="#2、-emsp-整体结构" class="headerlink" title="2、&emsp;整体结构"></a>2、&emsp;整体结构</h1><p><img src="/2021/08/04/Residual%20Attention%20Network/1628056822799.png" alt="1628056822799"></p><p>左图:一个例子展示了特征和注意力面具之间的相互作用。</p><p>右图:举例说明在我们的网络中，不同的特征有不同的对应注意面具。</p><p><img src="/2021/08/04/Residual%20Attention%20Network/1628066487666.png" alt="1628066487666"></p><center>软掩码分支结构</center>&emsp;&emsp;&emsp;掩码分支包含**快速前馈扫描**和**自上而下的反馈**步骤。**前者快速采集整幅图像的全局信息，后者将全局信息与原始特征图相结合**。在卷积神经网络中，这两个步骤展开为自下而上、自上而下的全卷积结构。从输入来看，在少量剩余单位后，**进行几次最大池化以快速增加感受野**。在达到最低分辨率后，全局信息通过**对称**的自上而下架构进行扩展，以指导每个位置的输入特征。**线性插值在一些残差单位后向上采样输出**。**双线性插值的数量与最大池化相同，以保持输出大小与输入要素图相同**。然后，连续两个1 × 1卷积层后，sigmoid层对输出进行归一化，范围为[0，1]。我们还在自下而上和自上而下的零件之间添加了跳跃连接，以从不同的比例捕获信息。<p><img src="/2021/08/04/Residual%20Attention%20Network/1628065657226.png" alt="1628065657226"></p><center>残差注意力网络结构</center>超参数p表示在分成主干分支和掩码分支**之前预处理剩余单元的数量**。t表示**主干分支**中剩余单元的数量。r表示**掩码分支**中相邻汇集层之间的剩余单元数。<center>软掩码分支结构</center># 3、 残差注意力网络分析<p>我们的剩余注意力网络是通过堆叠多个注意力模块构建的。每个注意模块分为两个分支:掩码分支和主干分支。主干分支执行特征处理，并且可以适应任何最先进的网络结构。</p><p>使用pre-activation Residual Unit、ResNeXt 和Inception 作为剩余注意网络的基本单元来构建注意模块</p><h2 id="3-1-emsp-注意力剩余学习"><a href="#3-1-emsp-注意力剩余学习" class="headerlink" title="3.1&emsp;注意力剩余学习"></a>3.1&emsp;注意力剩余学习</h2><p>给定输入为x的主干分支输出T(x)，掩码分支使用自下而上自上而下的结构来学习相同大小的掩码M(x)，该掩码对输出特征T(x)进行软加权。</p><p>注意模块H的输出为：     &emsp;&emsp;&emsp;&emsp;</p><img src="/2021/08/04/Residual%20Attention%20Network/1628066609969.png" alt="1628066609969"><p>在Attention Modules 中，attention mask不仅可以在前向推理过程中充当特征选择器，还可以在反向传播过程中充当梯度更新过滤器。在软遮罩分支中，输入要素的遮罩梯度为:</p><p><img src="/2021/08/04/Residual%20Attention%20Network/1628129507416.png" alt="1628129507416"></p><p>θ是掩码分支参数，φ是主干分支参数。此属性使注意力模块对有噪声的标签具有鲁棒性。遮罩分支可以防止错误的渐变(来自有噪声的标签)来更新主干参数。</p><h2 id="3-2-emsp-软掩码分支（Soft-Mask-Branch）"><a href="#3-2-emsp-软掩码分支（Soft-Mask-Branch）" class="headerlink" title="3.2&emsp;软掩码分支（Soft Mask Branch）"></a>3.2&emsp;软掩码分支（Soft Mask Branch）</h2><p>掩码分支目的是改进主干分支特征，而不是直接解决复杂的问题</p><p><img src="/2021/08/04/Residual%20Attention%20Network/1628131500040.png" alt="1628131500040"></p><center>掩蔽分支和主干分支的感受野比较</center>注意力模块的输出修改为：&emsp;&emsp;&emsp;<p><img src="/2021/08/04/Residual%20Attention%20Network/1628130312831.png" alt="1628130312831"></p><p><img src="/2021/08/04/Residual%20Attention%20Network/1628130471469.png" alt="1628130471469" style="zoom:85%;">是由深度卷积网络生成的特征mask分支M(x)，它们充当特征选择器，增强好的特征并抑制来自主干特征的噪声。</p><h2 id="3-3-emsp-遮罩分支提供的注意力随着主干分支特征而自适应地改变"><a href="#3-3-emsp-遮罩分支提供的注意力随着主干分支特征而自适应地改变" class="headerlink" title="3.3&emsp;遮罩分支提供的注意力随着主干分支特征而自适应地改变"></a>3.3&emsp;遮罩分支提供的注意力随着主干分支特征而自适应地改变</h2><p><img src="/2021/08/04/Residual%20Attention%20Network/1628133676240.png" alt="1628133676240"></p><p>xi表示第I个空间位置的特征向量。I在所有空间位置范围内，c在所有通道范围内</p><p>无附加限制的混合注意f1对每个通道和空间位置使用简单的sigmoid。</p><p>通道注意力f2在所有通道内对每个空间位置执行L2归一化，以去除空间信息。</p><p>空间注意力f3在来自每个通道的特征图内执行标准化，然后sigmoid以获得仅与空间信息相关的软掩模。</p><h1 id="4、-emsp-总结"><a href="#4、-emsp-总结" class="headerlink" title="4、&emsp;总结"></a>4、&emsp;总结</h1><p>普通注意力模型的缺点：</p><p>1、<strong>具有杂乱背景、复杂场景和大的外观变化的图像需要通过不同类型的关注来建模</strong>。在这种情况下，来自不同层的特征需要由不同的注意力遮罩来建模。使用单个掩码分支将需要指数数量的通道来捕获不同因素的所有组合。</p><p>2、<strong>单个注意模块只修改一次特征。如果映像的某些部分修改失败，以下网络模块将没有第二次机会。</strong></p><p><strong>本文提出的残余注意力网络缓解了上述问题</strong>。在注意力模块中，每个主干分支都有自己的掩码分支来学习专门针对其特征的注意力。</p><p><strong>1.堆叠网络结构:我们的剩余注意力网络是通过堆叠多个注意力模块来构建的。不同类型的注意力能够在不同的注意力模块中被捕获。改变 f（x）即可</strong></p><p><strong>2.整个soft mask branch 才是重点，输出的M当做残差加一以后再去卷积主干的特征</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1、论文全名-—-Residual-Attention-Network-for-Image-Classification&quot;&gt;&lt;a href=&quot;#1、论文全名-—-Residual-Attention-Network-for-Image-Classification</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="注意力模型（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="注意力模型" scheme="http://example.com/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>MUNIT</title>
    <link href="http://example.com/2021/08/03/MUNIT/"/>
    <id>http://example.com/2021/08/03/MUNIT/</id>
    <published>2021-08-03T08:45:44.000Z</published>
    <updated>2021-08-05T04:27:00.452Z</updated>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer">  <h1 id="1、论文全名-—-Multimodal-Unsupervised-Image-to-Image-Translation"><a href="#1、论文全名-—-Multimodal-Unsupervised-Image-to-Image-Translation" class="headerlink" title="1、论文全名 — Multimodal Unsupervised Image-to-Image Translation"></a>1、论文全名 — Multimodal Unsupervised Image-to-Image Translation</h1><h1 id="emsp-emsp-多模态无监督图像到图像翻译"><a href="#emsp-emsp-多模态无监督图像到图像翻译" class="headerlink" title="&emsp;&emsp;(多模态无监督图像到图像翻译)"></a>&emsp;&emsp;(多模态无监督图像到图像翻译)</h1><h1 id="2、整体结构"><a href="#2、整体结构" class="headerlink" title="2、整体结构"></a>2、整体结构</h1><p><img src="/2021/08/03/MUNIT/1627986033107.png" alt="1627986033107"></p><p><img src="/2021/08/03/MUNIT/1627980504738.png" alt="1627980504738"></p><h1 id="3、过程"><a href="#3、过程" class="headerlink" title="3、过程"></a>3、过程</h1><p>&emsp;&emsp;如图1 (a)所示，我们的框架做了几个假设。我们首先假设图像的潜在空间可以分解为内容空间C和风格空间S。我们进一步假设不同领域的图像共享一个共同的内容空间，但不共享样式空间。为了将图像翻译到目标域，我们将其内容代码与目标样式空间中的随机样式代码重新组合(图1(b))。</p><p>&emsp;&emsp;内容代码对翻译过程中应该保留的信息进行编码，而样式代码表示输入图像中不包含的其余变体。通过采样不同的风格代码，我们的模型能够产生不同的多模态输出。</p><p><img src="/2021/08/03/MUNIT/1627981675082.png" alt="1627981675082"></p><p>&emsp;&emsp;如图2(a)所示，每个自动编码器的潜在代码被分解成内容代码ci和样式代码si。如图2(b)所示，通过交换编码器-解码器对来执行图像到图像的转换。</p><p>&emsp;&emsp;为了将图像x1∈x1翻译成X2，我们首先提取其内容潜在代码<img src="/2021/08/03/MUNIT/1627982033272.png" alt="1627982033272" style="zoom:60%;">，并从先验分布<img src="/2021/08/03/MUNIT/1627982067523.png" alt="1627982067523" style="zoom:50%;">中随机绘制一个风格潜在代码s2。然后，我们使用G2产生最终输出图像<img src="/2021/08/03/MUNIT/1627982112763.png" alt="1627982112763" style="zoom:60%;">。</p><h2 id="4、损失函数设计"><a href="#4、损失函数设计" class="headerlink" title="4、损失函数设计"></a>4、损失函数设计</h2><h2 id="4-1-emsp-双向重建损失"><a href="#4-1-emsp-双向重建损失" class="headerlink" title="4.1&emsp;双向重建损失"></a>4.1&emsp;双向重建损失</h2><p><strong>图像重建损失:</strong> </p><p><img src="/2021/08/03/MUNIT/1627986277230.png" alt="1627986277230"></p><p><strong>潜在的重建损失：</strong>（内容重建损失和风格重建损失）</p><p><img src="/2021/08/03/MUNIT/1627986328694.png" alt="1627986328694"></p><p>在给定不同风格代码的情况下，风格重建损失具有鼓励不同输出的效果，内容重构损失重新鼓励翻译图像以保留输入图像的语义内容。</p><h2 id="4-2-emsp-对抗损失"><a href="#4-2-emsp-对抗损失" class="headerlink" title="4.2&emsp;对抗损失"></a>4.2&emsp;对抗损失</h2><p>先验分布<img src="/2021/08/03/MUNIT/1627987418253.png" alt="1627987418253" style="zoom:50%;">，边缘分布p(x）</p><p><img src="/2021/08/03/MUNIT/1627986915469.png" alt="1627986915469"></p><h2 id="4-3-emsp-总损失"><a href="#4-3-emsp-总损失" class="headerlink" title="4.3&emsp;总损失"></a>4.3&emsp;总损失</h2><img src="/2021/08/03/MUNIT/1627987289574.png" alt="1627987289574" style="zoom:75%;"><img src="/2021/08/03/MUNIT/1627987296909.png" alt="1627987296909" style="zoom:75%;"><h1 id="5、总结"><a href="#5、总结" class="headerlink" title="5、总结"></a>5、总结</h1><p>&emsp;&emsp;<strong>网络设计有点复杂，思路很容易理解。将图片分成风格编码器和内容编码器，然后拆开编码，最后再进行组合，同一个内容可以混合不同的风格。设计损失函数的时候也有重建风格损失，重建内容损失。</strong></p><hr>]]></content>
    
    
      
      
    <summary type="html"> &lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;  


&lt;h1 id=&quot;1、论文全名-—-Multimodal-Unsupervised-Image-to-Image-Translation&quot;&gt;&lt;a href=&quot;#1、论文全名-—-Mu</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN，论文阅读" scheme="http://example.com/tags/GAN%EF%BC%8C%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>U-GAT-IT</title>
    <link href="http://example.com/2021/08/03/U-GAT-IT/"/>
    <id>http://example.com/2021/08/03/U-GAT-IT/</id>
    <published>2021-08-03T03:44:36.000Z</published>
    <updated>2021-08-04T04:19:42.969Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1、论文全名-—-U-GAT-IT-UNSUPERVISED-GENERATIVE-ATTENTIONAL-NETWORKS-WITH-ADAPTIVE-LAYERINSTANCE-NORMALIZATION-FOR-IMAGE-TO-IMAGE"><a href="#1、论文全名-—-U-GAT-IT-UNSUPERVISED-GENERATIVE-ATTENTIONAL-NETWORKS-WITH-ADAPTIVE-LAYERINSTANCE-NORMALIZATION-FOR-IMAGE-TO-IMAGE" class="headerlink" title="1、论文全名 — U-GAT-IT: UNSUPERVISED GENERATIVE ATTENTIONAL NETWORKS  WITH ADAPTIVE LAYERINSTANCE NORMALIZATION FOR IMAGE-TO-IMAGE"></a>1、论文全名 — U-GAT-IT: UNSUPERVISED GENERATIVE ATTENTIONAL NETWORKS  WITH ADAPTIVE LAYERINSTANCE NORMALIZATION FOR IMAGE-TO-IMAGE</h1><p>TRANSLATION（用于图像到图像翻译的具有自适应层度归一化的无监督生成注意网络）</p><h1 id="2、-emsp-整体结构"><a href="#2、-emsp-整体结构" class="headerlink" title="2、&emsp;整体结构"></a>2、&emsp;整体结构</h1><p><img src="/2021/08/03/U-GAT-IT/1627963121891.png" alt="1627963121891"></p><p>​                                <center><strong>U - GAT - IT结构图</strong></center></p><h1 id="2、-emsp-U-GAT-IT过程"><a href="#2、-emsp-U-GAT-IT过程" class="headerlink" title="2、&emsp;U - GAT - IT过程"></a>2、&emsp;U - GAT - IT过程</h1><p>&emsp;&emsp;目标是训练一个函数G_(s→t)，该函数仅使用从每个域提取的不成对样本将图像从源域Xs映射到目标域Xt。我们的框架由两个生成器G_(s→t)和G_(t→s)和两个鉴别器Ds 和 Dt 组成。我们将注意力模块集成到生成器和鉴别器中。<strong>鉴别器中的注意力模块引导生成器聚焦于对生成逼真图像至关重要的区域。生成器中的注意模块关注与其他域不同的区域。</strong></p><h2 id="2-1-生成器G-s→t"><a href="#2-1-生成器G-s→t" class="headerlink" title="2.1  生成器G_(s→t)"></a>2.1  生成器G_(s→t)</h2><p>组成成分：编码器Es，解码器Gt，辅助分类器 ηs，其中ηs(x)表示x来自Xs的概率，</p><p>通过使用全局平均池和全局最大池，<strong>辅助分类器被训练来学习源域的第k特征图的权重w^k_(s),</strong></p><p><img src="/2021/08/03/U-GAT-IT/1627965570665.png" alt="1627965570665"></p><p>利用w^k_(s)，们可以计算一组域特定注意特征图a_s(x)为：&emsp;&emsp;其中n为特征图的数量</p><img src="/2021/08/03/U-GAT-IT/1627965767793.png" alt="1627965767793" style="zoom:70%;"><p>然后，我们的翻译模型Gs→t变得等于G_t(a_s(x))。</p><p>**自适应层重要性归一化(AdaLIN)**，其参数在训练期间通过自适应地选择实例归一化(IN)和层归一化(LN)之间的适当比率从数据集学习。</p><p><img src="/2021/08/03/U-GAT-IT/1627965972979.png" alt="1627965972979"></p><p> µ_I,  µ_L, σ_I, σ_L分别是通道级均值、层级均值和标准差，γ和β是全连通层生成的参数，τ是学习率，△ρ表示优化器确定的参数更新向量(如梯度)。</p><p>LN 并不假设通道之间不相关，有时它不能很好地保持原始领域的内容结构，因为它只考虑了特征地图的全局统计。归一化技术AdaLIN通过选择性地保留或改变内容信息，结合了AdaIN和LN的优点，这有助于解决广泛的图像到图像翻译问题</p><h2 id="2-2-emsp-判别器Dt"><a href="#2-2-emsp-判别器Dt" class="headerlink" title="2.2 &emsp;判别器Dt"></a>2.2 &emsp;判别器Dt</h2><p>组成成分：是由编码器E_Dt、分类器C__Dt和辅助分类器  η_(Dt) 组成的多尺度模型。</p><p>x∞{  Xt，Gs→t(Xs) } 表示来自目标域和翻译后的源域的样本。与其他翻译模型不同，η_Dt(x)和D_t(x)都被训练来区分x是否来自 Xt 还是 Gs→t(Xs)。</p><p>给定一个样本x，Dt(x)使用编码特征图E_Dt(x)上面的权重w_Dt去寻找注意力特征图<img src="/2021/08/03/U-GAT-IT/1627973410325.png" alt="1627973410325" style="zoom:50%;">，这个编码特征图E_dT(x)由辅助分类器 ηDt(x)训练得来。然后，我们的鉴别器Dt(x)变得等于<img src="/2021/08/03/U-GAT-IT/1627973368892.png" alt="1627973368892" style="zoom:55%;"></p><h1 id="3、损失函数的设计"><a href="#3、损失函数的设计" class="headerlink" title="3、损失函数的设计"></a>3、损失函数的设计</h1><p>我们模型的全部目标包括四个损失函数。</p><p>这里，我们使用最小二乘GAN  (LSGAN)目标进行稳定训练，而不是使用普通的GAN目标。</p><h3 id="3-1-emsp-知识介绍-–-LSGAN"><a href="#3-1-emsp-知识介绍-–-LSGAN" class="headerlink" title="3.1 &emsp;知识介绍 – LSGAN"></a>3.1 &emsp;知识介绍 – LSGAN</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Least Squares GAN   这篇文章针对的是原始GAN生成的图片质量不高以及训练过程不稳定这两个缺陷进行改进。</span><br><span class="line"></span><br><span class="line">改进方法就是将GAN的目标函数由交叉熵损失换成最小二乘损失，而且这一个改变同时解决了两个缺陷。</span><br><span class="line">为以交叉熵作为损失，会使得生成器不会再优化那些被判别器识别为真实图片的生成图片，即使这些生成图片距离判别器的决策边界仍然很远，也就是距真实数据比较远。因为它已经成功欺骗了判别器，这导致了生成器的生成图片质量并不高。</span><br><span class="line"></span><br><span class="line">最小二乘损失函数会对处于判别成真的那些远离决策边界的样本进行惩罚，把远离决策边界的假样本拖进决策边界，从而提高生成图片的质量。</span><br></pre></td></tr></table></figure><p><img src="/2021/08/03/U-GAT-IT/1627975227737.png" alt="1627975227737"></p><p><img src="/2021/08/03/U-GAT-IT/1627975341016.png" alt="1627975341016"></p><h3 id="3-2-emsp-对抗损失"><a href="#3-2-emsp-对抗损失" class="headerlink" title="3.2&emsp;对抗损失"></a>3.2&emsp;对抗损失</h3><p><img src="/2021/08/03/U-GAT-IT/1627975505284.png" alt="1627975505284"></p><h3 id="3-3-emsp-循环损失"><a href="#3-3-emsp-循环损失" class="headerlink" title="3.3&emsp;循环损失"></a>3.3&emsp;循环损失</h3><h3 id="emsp-emsp-emsp-可以缓解模式崩溃问题"><a href="#emsp-emsp-emsp-可以缓解模式崩溃问题" class="headerlink" title="&emsp;&emsp;&emsp;可以缓解模式崩溃问题"></a>&emsp;&emsp;&emsp;可以缓解模式崩溃问题</h3><p><img src="/2021/08/03/U-GAT-IT/1627975587820.png" alt="1627975587820"></p><h3 id="3-4-emsp-身份损失"><a href="#3-4-emsp-身份损失" class="headerlink" title="3.4&emsp;身份损失"></a>3.4&emsp;身份损失</h3><h3 id="emsp-emsp-emsp-为了确保输入图像和输出图像的颜色分布相似"><a href="#emsp-emsp-emsp-为了确保输入图像和输出图像的颜色分布相似" class="headerlink" title="&emsp;&emsp;&emsp;为了确保输入图像和输出图像的颜色分布相似"></a>&emsp;&emsp;&emsp;为了确保输入图像和输出图像的颜色分布相似</h3><p><img src="/2021/08/03/U-GAT-IT/1627975653043.png" alt="1627975653043"></p><h3 id="3-5-emsp-CAM损失"><a href="#3-5-emsp-CAM损失" class="headerlink" title="3.5&emsp;CAM损失"></a>3.5&emsp;CAM损失</h3><h3 id="emsp-emsp-emsp-通过利用来自辅助分类器ηs和η-Dt的信息-是的G-s→t-和Dt了解他们需要改进的地方，或者在当前状态下两个领域的最大区别"><a href="#emsp-emsp-emsp-通过利用来自辅助分类器ηs和η-Dt的信息-是的G-s→t-和Dt了解他们需要改进的地方，或者在当前状态下两个领域的最大区别" class="headerlink" title="&emsp;&emsp;&emsp;通过利用来自辅助分类器ηs和η_Dt的信息,是的G_(s→t)和Dt了解他们需要改进的地方，或者在当前状态下两个领域的最大区别:"></a>&emsp;&emsp;&emsp;通过利用来自辅助分类器ηs和η_Dt的信息,是的G_(s→t)和Dt了解他们需要改进的地方，或者在当前状态下两个领域的最大区别:</h3><p><img src="/2021/08/03/U-GAT-IT/1627975912525.png" alt="1627975912525"></p><h3 id="3-6-emsp-总损失"><a href="#3-6-emsp-总损失" class="headerlink" title="3.6 &emsp;总损失"></a>3.6 &emsp;总损失</h3><p><img src="/2021/08/03/U-GAT-IT/1627976087788.png" alt="1627976087788"></p><hr><h1 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h1><h2 id="emsp-emsp-个人理解创新的地方在于"><a href="#emsp-emsp-个人理解创新的地方在于" class="headerlink" title="&emsp;&emsp;个人理解创新的地方在于"></a>&emsp;&emsp;<strong>个人理解创新的地方在于</strong></h2><ol><li><p><strong>CAM损失，能够帮助两个不同域直接和合成。</strong></p></li><li><p><strong>有两种不同的特征图——编码器特征图和注意力特征图。</strong></p><p><strong>Dt(x)使用编码特征图E_Dt(x)上面的权重w_Dt去寻找注意力特征图<img src="/2021/08/03/U-GAT-IT/1627973410325.png" alt="1627973410325" style="zoom:50%;">，这个编码特征图E_dT(x)由辅助分类器 ηDt(x)训练得来</strong></p></li><li><p><strong>鉴别器中的注意力模块引导生成器聚焦于对生成逼真图像至关重要的区域。生成器中的注意模块关注与其他域不同的区域。</strong></p></li><li><p><strong>损失函数使用的是LSGAN)目标进行稳定训练，而不是传统GAN</strong></p></li></ol><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1、论文全名-—-U-GAT-IT-UNSUPERVISED-GENERATIVE-ATTENTIONAL-NETWORKS-WITH-ADAPTIVE-LAYERINSTANCE-NORMALIZATION-FOR-IMAGE-TO-IMAGE&quot;&gt;&lt;a href</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="注意力模型" scheme="http://example.com/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>Stack++</title>
    <link href="http://example.com/2021/08/01/StackGAN-v2/"/>
    <id>http://example.com/2021/08/01/StackGAN-v2/</id>
    <published>2021-08-01T13:18:44.000Z</published>
    <updated>2021-08-03T11:32:41.478Z</updated>
    
    <content type="html"><![CDATA[  <meta name="referrer" content="no-referrer">  <h1 id="1、论文全名-—-stackGAN-Realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks"><a href="#1、论文全名-—-stackGAN-Realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks" class="headerlink" title="1、论文全名 — stackGAN++: Realistic Image Synthesis with    Stacked Generative Adversarial Networks"></a>1、论文全名 — stackGAN++: Realistic Image Synthesis with    Stacked Generative Adversarial Networks</h1><h1 id="2、整体结构"><a href="#2、整体结构" class="headerlink" title="2、整体结构"></a>2、整体结构</h1><p><img src="/2021/08/01/StackGAN-v2/1627825385517.png"></p><p>​                                      <center>StackGAN-v2流程图</center></p><h1 id="3、过程以及损失函数的设计"><a href="#3、过程以及损失函数的设计" class="headerlink" title="3、过程以及损失函数的设计"></a>3、过程以及损失函数的设计</h1><p> &emsp; &emsp;StackGAN-v2由多个生成器(G)和鉴别器(D)组成，它们在树状结构中共享大多数参数。网络的输入可以被视为树的根，并且多尺度图像从树的不同分支生成。从低分辨率到高分辨率的图像是从树的不同分支生成的。</p><p>&emsp;&emsp;在每个分支，生成器捕获该比例下的图像分布，鉴别器估计样本来自该比例的训练图像而不是生成器的概率。生成器被联合训练以逼近多个分布，并且生成器和鉴别器以交替的方式被训练。在本节中，我们探讨了两种类型的多重分布:(1)多尺度图像分布以及(2)联合条件和无条件图像分布。</p><h3 id="3-1-多尺度图像分布近似-Multi-scale-image-distributions-approximation"><a href="#3-1-多尺度图像分布近似-Multi-scale-image-distributions-approximation" class="headerlink" title="3.1 多尺度图像分布近似(Multi-scale image distributions approximation)"></a>3.1 多尺度图像分布近似(Multi-scale image distributions approximation)</h3><p>&emsp;&emsp; StackGAN-v2以一个噪声向量z作为输入，并有多个生成器来生成不同比例的图像。噪声是一种先验分布，通常为标准正态分布。潜在变量z被逐层转换为隐藏特征。我们通过非线性变换计算每个发生器G的隐藏特征hi。</p><p>&emsp;&emsp;hi表示第i个分支的隐藏特征，m为总分支数，为了捕捉在前面的分支中省略的信息，噪声矢量z连接到隐藏特征h_(i -1)，作为 Fi 的输入去计算hi。</p><p><img src="/2021/08/01/StackGAN-v2/1627828037446-1627873594719.png"></p><p><img src="/2021/08/01/StackGAN-v2/1627828068601.png"></p><p>&emsp;&emsp;在每个生成器Gi之后跟着一个鉴别器Di，通过最小化以下交叉熵损失来训练鉴别器Di，该鉴别器Di以真实样本xi和伪样本si作为输入，以将输入分类为两类(真或假)。</p><p><img src="/2021/08/01/StackGAN-v2/1627828305495.png"></p><p>&emsp;&emsp;多个鉴别器被并行训练，并且每个鉴别器聚焦在单个图像尺度上。</p><p>&emsp;&emsp;在训练好的鉴别器的指导下，生成器通过最小化下面的损失函数被优化以联合逼近多尺度图像分布</p><p><img src="/2021/08/01/StackGAN-v2/1627828424158.png"></p><p>&emsp;其中l_g是用于近似第i个尺度上的图像分布的损失函数。在训练过程中，鉴别器和生成器交替优化，直到收敛。</p><p>&emsp;&emsp;<strong>提出的StackGAN-v2的动机是，通过在多个尺度上建模数据分布，如果这些模型分布中的任何一个与该尺度上的真实数据分布共享支持，则重叠可以提供良好的梯度信号，以在多个尺度上加速或稳定整个网络的训练。</strong></p><h3 id="3-2-联合条件和无条件图像分布近似（-JCD-）"><a href="#3-2-联合条件和无条件图像分布近似（-JCD-）" class="headerlink" title="3.2 联合条件和无条件图像分布近似（ JCD ）"></a>3.2 联合条件和无条件图像分布近似（ JCD ）</h3><p>&emsp;&emsp;<strong>无条件损失决定图像的真假，有条件损失决定图像和条件是否匹配。</strong>    </p><p>&emsp;&emsp;对于我们的条件StackGAN-v2的G，F0和Fi 被转换为将条件向量c作为输入。对于Fi，调节向量c代替噪声向量z，以鼓励生成器根据调节变量绘制具有更多细节的图像。因此，多尺度样本现在由si=  Gi(hi)生成。</p><p><img src="/2021/08/01/StackGAN-v2/1627870863531.png" alt="1627870863531"></p><p><img src="/2021/08/01/StackGAN-v2/1627870873418.png" alt="1627870873418"></p><p>&emsp;&emsp;<strong>训练条件D的目标函数现在由两个项组成，无条件损失和条件损失。</strong></p><p><img src="/2021/08/01/StackGAN-v2/1627870996625.png" alt="1627870996625"></p><p>&emsp;&emsp;<strong>这部分的损失函数为</strong></p><p><img src="/2021/08/01/StackGAN-v2/1627871482209.png" alt="1627871482209"></p><h3 id="3-3-颜色一致性正则化（-Color-consistency-regularization）"><a href="#3-3-颜色一致性正则化（-Color-consistency-regularization）" class="headerlink" title="3.3 颜色一致性正则化（ Color-consistency regularization）"></a>3.3 颜色一致性正则化（ Color-consistency regularization）</h3><p>&emsp;&emsp;当我们在不同的生成器上增加图像分辨率时，在不同比例下生成的图像应该共享相似的基本结构和颜色。引入颜色一致性正则化项，以保持从不同G的相同输入生成的样本在颜色上更加一致，从而提高生成图像的质量。</p><p><img src="/2021/08/01/StackGAN-v2/1627872407715.png" alt="1627872407715"></p><p><img src="/2021/08/01/StackGAN-v2/1627872459349.png" alt="1627872459349"></p><p><img src="/2021/08/01/StackGAN-v2/1627873918668.png" alt="1627873918668"></p><p>X_k表示生成的图像中的一个像素，下面的代表给定图像的像素的平均值和协方差，N为像素个数。</p><p><strong>颜色一致性正则化的目的是最小化不同尺度之间的像素平均值和协方差的差异，以促进一致性。</strong></p><p><img src="/2021/08/01/StackGAN-v2/1627872829324.png" alt="1627872829324"></p><hr><h1 id="4、总结："><a href="#4、总结：" class="headerlink" title="4、总结："></a>4、总结：</h1><h3 id="emsp-emsp-这个文章是在StackGAN上面的延续，针对条件生成任务和无条件生成任务，提出了一种先进的多阶段生成对抗网络体系结构StackGAN-v2。"><a href="#emsp-emsp-这个文章是在StackGAN上面的延续，针对条件生成任务和无条件生成任务，提出了一种先进的多阶段生成对抗网络体系结构StackGAN-v2。" class="headerlink" title="&emsp;&emsp;这个文章是在StackGAN上面的延续，针对条件生成任务和无条件生成任务，提出了一种先进的多阶段生成对抗网络体系结构StackGAN-v2。"></a>&emsp;&emsp;这个文章是在StackGAN上面的延续，针对条件生成任务和无条件生成任务，提出了一种先进的多阶段生成对抗网络体系结构StackGAN-v2。</h3><h2 id="emsp-emsp-stackGAN有三个主要贡献："><a href="#emsp-emsp-stackGAN有三个主要贡献：" class="headerlink" title="&emsp;&emsp;stackGAN有三个主要贡献："></a>&emsp;&emsp;stackGAN有三个主要贡献：</h2><ol><li><strong>StackGAN-v1首次从文本描述中分阶段生成具有照片级逼真细节的256×256分辨率的图像。</strong></li><li><strong>StackGAN-v2通过联合逼近多个分布，进一步提高了生成图像的质量，稳定了GANs的训练。</strong></li><li><strong>提出了一个颜色一致性正则化项来指导我们的生成器在不同的尺度上生成更多的相干样本。</strong></li></ol><hr>]]></content>
    
    
      
      
    <summary type="html">  &lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;  




&lt;h1 id=&quot;1、论文全名-—-stackGAN-Realistic-Image-Synthesis-with-Stacked-Generative-Adversarial</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN，论文阅读" scheme="http://example.com/tags/GAN%EF%BC%8C%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>StackGAN</title>
    <link href="http://example.com/2021/08/01/StackGAN/"/>
    <id>http://example.com/2021/08/01/StackGAN/</id>
    <published>2021-08-01T11:20:10.000Z</published>
    <updated>2021-08-03T08:03:55.168Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1、论文全名-—-StackGAN-Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks"><a href="#1、论文全名-—-StackGAN-Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks" class="headerlink" title="1、论文全名 — StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks"></a>1、论文全名 — StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks</h1><h1 id="2、整体结构"><a href="#2、整体结构" class="headerlink" title="2、整体结构"></a>2、整体结构</h1><p><img src="/2021/08/01/StackGAN/1627817144163-1627822726262.png"></p><p>​                                                                 <center> <strong>StackGAN 的流程图</strong></center> </p><h1 id="3、-StackGAN过程"><a href="#3、-StackGAN过程" class="headerlink" title="3、 StackGAN过程"></a>3、 StackGAN过程</h1><p>&emsp;&emsp;第一阶段生成器通过从给定文本中绘制对象的粗略形状和基本颜色，并从随机噪声向量中绘制背景，来绘制低分辨率图像。</p><p>&emsp;&emsp; 第二阶段生成器纠正缺陷，并在第一阶段的结果中添加引人注目的细节，产生更真实的高分辨率图像。</p><h2 id="3-1-第一阶段（并非自己关注的重点）"><a href="#3-1-第一阶段（并非自己关注的重点）" class="headerlink" title="3.1  第一阶段（并非自己关注的重点）"></a>3.1  第一阶段（并非自己关注的重点）</h2><p>&emsp;&emsp;ϕt 表示给定描述的文本嵌入，它是由本文中预先训练的编码器生成的。条件^C0，随机变量Z。</p><p>&emsp;&emsp;<em>第一阶段随机交替的最大化等式 L(Do)和最小化 L(Go)来训练生成器Go和判别器Do</em></p><img src="/2021/08/01/StackGAN/1627817709932-1627822752622.png" style="zoom:67%;"><img src="/2021/08/01/StackGAN/1627817814686-1627822752622.png" alt="1627817814686" style="zoom:67%;"><h2 id="3-2-第二阶段（重点关注第一阶段过渡到第二阶段的代码）"><a href="#3-2-第二阶段（重点关注第一阶段过渡到第二阶段的代码）" class="headerlink" title="3.2 第二阶段（重点关注第一阶段过渡到第二阶段的代码）"></a>3.2 第二阶段（重点关注第一阶段过渡到第二阶段的代码）</h2><p>&emsp;&emsp; 第一阶段GAN生成的低分辨率图像通常缺少生动的物体部分，并且可能包含形状失真。文本中的一些细节也可能在第一阶段被省略，这对于生成照片真实感图像至关重要。第二阶段GAN是建立在第一阶段结果的基础上，以生成高分辨率图像。它以低分辨率图像和再次嵌入文本为条件，以纠正第一阶段结果中的缺陷。</p><p>&emsp;&emsp;第二阶段不再使用随机噪声，使用的so表示第一阶段生成结果。</p><p>&emsp;&emsp;<em>第二阶段随机交替的最大化等式 L(D)和最小化 L(G)来训练生成器G和判别器D</em></p><img src="../images/StackGAN/1627818853115.png" alt="1627818853115" style="zoom:67%;"><img src="/2021/08/01/StackGAN/1627818853115-1627822752622.png" alt="1627818853115" style="zoom:67%;"><h1 id="3、总结"><a href="#3、总结" class="headerlink" title="3、总结"></a>3、总结</h1><h4 id="emsp-emsp-这篇文章是利用文本生成来生成图像，所以很多的细节不需要掌握、重点学习的是怎么把前面一个阶段的图放入下一个阶段。看论文只是次要、还是得复现代码。"><a href="#emsp-emsp-这篇文章是利用文本生成来生成图像，所以很多的细节不需要掌握、重点学习的是怎么把前面一个阶段的图放入下一个阶段。看论文只是次要、还是得复现代码。" class="headerlink" title="&emsp;&emsp;这篇文章是利用文本生成来生成图像，所以很多的细节不需要掌握、重点学习的是怎么把前面一个阶段的图放入下一个阶段。看论文只是次要、还是得复现代码。"></a>&emsp;&emsp;这篇文章是利用文本生成来生成图像，所以很多的细节不需要掌握、重点学习的是怎么把前面一个阶段的图放入下一个阶段。看论文只是次要、还是得复现代码。</h4><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1、论文全名-—-StackGAN-Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks&quot;&gt;&lt;a href=&quot;#1、论文全名-—-StackGAN-</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN，论文阅读" scheme="http://example.com/tags/GAN%EF%BC%8C%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>Unsupervised Attention-guided GAN</title>
    <link href="http://example.com/2021/08/01/Unsupervised-Attention-guided/"/>
    <id>http://example.com/2021/08/01/Unsupervised-Attention-guided/</id>
    <published>2021-08-01T11:20:10.000Z</published>
    <updated>2021-09-02T13:17:53.985Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1、论文全名-—-Unsupervised-Attention-guided-Image-to-Image-Translation"><a href="#1、论文全名-—-Unsupervised-Attention-guided-Image-to-Image-Translation" class="headerlink" title="1、论文全名 — Unsupervised Attention-guided Image-to-Image Translation"></a>1、论文全名 — Unsupervised Attention-guided Image-to-Image Translation</h1><h1 id="2、-emsp-整体结构"><a href="#2、-emsp-整体结构" class="headerlink" title="2、&emsp;整体结构"></a>2、&emsp;整体结构</h1><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627892637831.png" alt="1627892637831"></p><p>​                                                          <center>UAG-GAN流程图</center></p><h1 id="3、-emsp-UAG-GAN过程"><a href="#3、-emsp-UAG-GAN过程" class="headerlink" title="3、&emsp;UAG-GAN过程"></a>3、&emsp;UAG-GAN过程</h1><p>&emsp;&emsp;&emsp;文章出发点是在cycleGAN 的基础上改进的，图像风格变换实质上是两个不同域之间的相互转换。</p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627893141106.png" alt="1627893141106"></p><p>&emsp;&emsp;为了进一步处理，需要解决两个主要任务：</p><ol><li>在每个图像中定位要平移的区域，</li><li>对定位的区域应用正确的平移。</li></ol><h2 id="3-1-emsp-生成器G解读"><a href="#3-1-emsp-生成器G解读" class="headerlink" title="3.1 &emsp;生成器G解读"></a>3.1 &emsp;生成器G解读</h2><p>&emsp;&emsp;A_S与A_T表示两个不同的注意力网络，Sa 和 Ta分别是由 S 和 T 导出的注意图。每个注意力图包含每像素[0，1]的估计值。<strong>如果注意力图所有值为0，则输出背景项；如果全为1，则输出原图。</strong>将输入图像输入到生成器后，我们使用逐元素乘积将学习到的掩码应用到生成的图像，然后使用应用于输入图像的反遮罩添加背景。因此，A_S 和 A_T 与G一起训练，如图所示。</p><p>&emsp;&emsp;首先，我们将输入图像 s∈S 馈送到生成器F_(S→T), 生成器 F_(S→T)将s映射到目标域T，然后，将相同的输入馈送到注意力网络A_S，得到注意力图 Sa 。为了创建“前景”对象sf，我们把每个RGB通道上的注意力模型 Sa 和生成器F_(S→T)进行逐元素乘积。然后，对注意力图Sa取反，再和原图S进行逐元素成绩，得到“背景”图像Sb。最后，将前景和后景图相加即可得到最终图像。</p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627894572673.png" alt="1627894572673"></p><h2 id="3-2-emsp-损失函数"><a href="#3-2-emsp-损失函数" class="headerlink" title="3.2 &emsp;损失函数"></a>3.2 &emsp;损失函数</h2><p>&emsp;<strong>对抗损失：</strong></p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627895057172.png" alt="1627895057172"></p><p>&emsp;</p><p>&emsp;<strong>循环一致性损失：</strong>   &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;其中 S‘’ 是生成的T域图片再转回S域的图像。</p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627895140042.png" alt="1627895140042"></p><p>&emsp;<strong>最终损失：</strong></p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627901641560.png" alt="1627901641560"></p><p>&emsp;<strong>在整个实验中，我们通过求解极小极大优化问题得到L的最优参数:</strong></p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627901652097.png" alt="1627901652097"></p><h2 id="3-3-emsp-判别器D解读"><a href="#3-3-emsp-判别器D解读" class="headerlink" title="3.3 &emsp;判别器D解读"></a>3.3 &emsp;判别器D解读</h2><p>&emsp;&emsp;生成器仅作用于关注区域: 随着注意力网络训练在寻找前景方面会变得更加准确。但是也有两个引起误差的行为：（1）注意力图慢慢的包括越来越多的背景，向完全关注的图收敛 (<strong>图中的所有值都收敛到1</strong>)。（2）生成器F_(S→T)将背景直接“绘制”到关注区域中.</p><p>&emsp;单纯用原图像S和通过<strong>已经训练好了的A_S生成的</strong>注意力图像Sa进行逐元素乘积是有问题的，因为反馈给鉴别器的真实样本现在依赖于最初未训练的注意力图sa。如果GAN中的所有网络都被联合训练，这将导致模式崩溃。为了克服这个问题，我们首先在30个时期的完整图像上训练辨别器，然后在注意力网络A_S和A_T发展起来后，切换到掩蔽图像。</p><p>图像转换的流程如图：</p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627896930053.png" alt="1627896930053"></p><p>我们设置注意力取值不能为0，因为全0就变成了输出背景，故鉴别器设定学习注意图的阈值如下:</p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627901667458.png" alt="1627901667458"></p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627901532979.png" alt="1627901532979"></p><h2 id="3-3-总结学习FS→T的训练程序"><a href="#3-3-总结学习FS→T的训练程序" class="headerlink" title="3.3 总结学习FS→T的训练程序"></a>3.3 总结学习FS→T的训练程序</h2><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627901540811.png" alt="1627901540811"></p><h1 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h1><p><strong>&emsp;&emsp;这篇文章引入了注意力、把一张图片的合成分成了前景图片和后景图片的合成、分别处理后再相加。这样可以使得更加专注于前景图，对需要转化部分图像的处理达到更好的效果。</strong></p><p><strong>&emsp;&emsp;有一个想法：直接用前景减去后景是不是能够让素描的合成更加准确。</strong></p><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1、论文全名-—-Unsupervised-Attention-guided-Image-to-Image-Translation&quot;&gt;&lt;a href=&quot;#1、论文全名-—-Unsupervised-Attention-guided-Image-to-Image-T</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN，论文阅读" scheme="http://example.com/tags/GAN%EF%BC%8C%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
</feed>

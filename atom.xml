<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>lllllcy</title>
  
  <subtitle>2020.7</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-08-31T02:38:13.438Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>George</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>详细解读batch norm</title>
    <link href="http://example.com/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/"/>
    <id>http://example.com/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/</id>
    <published>2021-08-29T04:50:02.000Z</published>
    <updated>2021-08-31T02:38:13.438Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Batch-Normalization-概念"><a href="#Batch-Normalization-概念" class="headerlink" title="Batch Normalization 概念"></a>Batch Normalization 概念</h1><p>Batch Normalization：批标准化<br>批：一批数据，通常为mini-batch<br>标准化：0均值，1方差</p><p>计算方式：<br>mini-batch中有x 1 , x 2 , . . . x m x_1,x_2,…x_m个数据，有两个待学习的参数 γ , β 然后通过这两个参数对x进行BN变化。 </p><p> 1.计算均值。    2.计算方差。     3.归一化处理到均值为0，方差为1。    4.恢复出这一层网络所要学到的分布   </p><p>具体计算公式看下图：</p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630212948797.png" alt="1630212948797" style="zoom:60%;"><p>在公式中求normalize这步中，为了防止分母为0的情况出现，加了一个修正系数ϵ ，得到的x ^ i  是一个服从0均值，1标准差的分布。最后对x ^ i  进行scale和shift操作就是通过两个超参数进行的。</p><h1 id="PyTorch的Batch-Nomalzaton-1d-2d-3d实现"><a href="#PyTorch的Batch-Nomalzaton-1d-2d-3d实现" class="headerlink" title="PyTorch的Batch Nomalzaton 1d/2d/3d实现"></a>PyTorch的Batch Nomalzaton 1d/2d/3d实现</h1><p><strong>_BatchNorm（基类）</strong><br>·nn.BatchNorm1d<br>·nn.BatchNorm2d<br>·nn.BatchNorm3d</p><p><strong>基类的参数：</strong><br>·num_features：一个样本特征数量（最重要）<br>·eps：分母修正项，一般是1e-5<br>·momentum：指数加权平均估计当前mean/var<br>·affine：是否需要affine transform，默认是true<br>·track_running_stats：是训练状态，还是测试状态</p><p><strong>主要属性：</strong><br>·running_mean：均值就是图片公式中的μ<br>·running_Var：方差图片公式中的σ<br>·weight:affine transform中的γ （可学习）<br>·bias:affine transform中的β（可学习）<br>上面四个属性中，后面两个是可学习的，前面两个呢？<br>在训练阶段：均值和方差采用<strong>指数加权平均</strong>计算<br>running_mean=(1-momentum)* pre_running_mean +momentum * mean_t<br>running_var=(1-momentum)* pre_running_var+ momentum * var_t<br>在测试阶段：当前统计值（已经估计好的值）</p><h2 id="1D"><a href="#1D" class="headerlink" title="1D"></a>1D</h2><p>·nn.BatchNorm1d input=B* 特征数* 1d特征<br>看下图可知，有3个batch，每个batch的特征数量是5个，特征的维度是1.所以大小是3<em>5</em>1，有时候1省略不写变成3 * 5.<br>那如何计算BatchNorm1d 的四个属性呢？<br>对每个特征横着看，对1.1.1求均值方差，学习γ 和β可得到第一个特征的四个属性，<br>同样对2.2.2求均值方差，学习γ 和β 可得到第二个特征的四个属性<br>同样对3.3.3求均值方差，学习γ 和β 可得到第三个特征的四个属性</p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630220059607.png" alt="1630220059607" style="zoom:67%;"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">9</span>)  <span class="comment"># 设置随机种子</span></span><br><span class="line">flag = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> flag:</span><br><span class="line">    batch_size = <span class="number">3</span></span><br><span class="line">    num_features = <span class="number">5</span><span class="comment">#特征数5个</span></span><br><span class="line">    momentum = <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line">    features_shape = (<span class="number">1</span>)<span class="comment">#1d，就是图中的每个特征维度为1</span></span><br><span class="line"></span><br><span class="line">    feature_map = torch.ones(features_shape) <span class="comment">#得到一个为1的张量                                                   </span></span><br><span class="line">    feature_maps = torch.stack([feature_map*(i+<span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_features)], dim=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 然后在特征数量方向进行扩展，就是图中的y轴        </span></span><br><span class="line">    feature_maps_bs = torch.stack([feature_maps <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size)], dim=<span class="number">0</span>)  </span><br><span class="line">    <span class="comment"># 在batch方向上进行扩展，就是图中的x轴          </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;input data:\n&#123;&#125; \n  shape is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(feature_maps_bs, feature_maps_bs.shape))<span class="comment">#打印出来应该是3*5*1</span></span><br><span class="line">    </span><br><span class="line">    bn = nn.BatchNorm1d(num_features=num_features, momentum=momentum)</span><br><span class="line"></span><br><span class="line">    running_mean, running_var = <span class="number">0</span>, <span class="number">1</span>          <span class="comment">## 均值和方差初始化</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        outputs = bn(feature_maps_bs)              <span class="comment">## running_mean=(1-momentum)* pre_running_mean +momentum * mean_t</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\niteration:&#123;&#125;, running mean: &#123;&#125; &quot;</span>.<span class="built_in">format</span>(i, bn.running_mean))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;iteration:&#123;&#125;, running var:&#123;&#125; &quot;</span>.<span class="built_in">format</span>(i, bn.running_var))</span><br><span class="line"></span><br><span class="line">        running_mean = (<span class="number">1</span> - momentum) * running_mean + momentum * mean_t</span><br><span class="line">        running_var = (<span class="number">1</span> - momentum) * running_var + momentum * var_t</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;iteration:&#123;&#125;, 第二个特征的running mean: &#123;&#125; &quot;</span>.<span class="built_in">format</span>(i, running_mean))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;iteration:&#123;&#125;, 第二个特征的running var:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i, running_var))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出结果：</p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630222648383.png" alt="1630222648383" style="zoom:77%;"><h3 id="均值计算"><a href="#均值计算" class="headerlink" title="均值计算"></a>均值计算</h3><p>根据公式：running_mean=(1-momentum)* pre_running_mean +momentum * mean_t</p><p>由于是第一次迭代，pre_running_mean （上一次的均值）没有，默认是0，</p><p>当前均值mean_t = 1、2、3、4、5</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">     第一个特征（3个1）                       计算结果：running_mean=(1-0.3)*0+0.3 * 1 = 0.3；</span><br><span class="line">同理，第二个特征（3个2）                       计算结果：running_mean=(1-0.3)*0+0.3 * 2 = 0.6；</span><br><span class="line">同理，第三个特征（3个3）                       计算结果：running_mean=(1-0.3)*0+0.3 * 3 = 0.9；</span><br><span class="line">同理，第二个特征（3个4）                       计算结果：running_mean=(1-0.3)*0+0.3 * 4 = 1.2；</span><br><span class="line">同理，第三个特征（3个5）                       计算结果：running_mean=(1-0.3)*0+0.3 * 5 = 1.5；</span><br></pre></td></tr></table></figure><p>下面看第二次迭代的时候：momentum = 0.3，mean_t = 1、2、3、4、5<br><strong>pre_running_mean = 上一个阶段计算出来的running_mean。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">     第一个特征（3个1）                    计算结果：running_mean=(1-0.3)*0.3+0.3 * 1 = 0.51；</span><br><span class="line">同理，第二个特征（3个2）                    计算结果：running_mean=(1-0.3)*0.6+0.3 * 2 = 1.02；</span><br><span class="line">同理，第三个特征（3个3）                    计算结果：running_mean=(1-0.3)*0.9+0.3 * 3 = 1.53；</span><br><span class="line">同理，第二个特征（3个4）                    计算结果：running_mean=(1-0.3)*1.2+0.3 * 4 = 2.04；</span><br><span class="line">同理，第三个特征（3个5）                    计算结果：running_mean=(1-0.3)*1.5+0.3 * 5 = 2.55；</span><br></pre></td></tr></table></figure><h3 id="方差计算"><a href="#方差计算" class="headerlink" title="方差计算"></a>方差计算</h3><p>根据公式：running_var=(1-momentum)* pre_running_var+ momentum * var_t</p><p>由于是第一次迭代，上一次的方差）没有，默认是pre_running_var = 1，当前方差var_t 为0</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">     第一个特征（3个1）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br><span class="line">同理，第二个特征（3个2）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br><span class="line">同理，第三个特征（3个3）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br><span class="line">同理，第二个特征（3个4）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br><span class="line">同理，第三个特征（3个5）                    计算结果：running_var = (1-0.3)*1+0.3 * 0 = 0.7；</span><br></pre></td></tr></table></figure><p>下面看第二次迭代的时候：momentum = 0.3，pre_running_var = 0.7，当前方差var_t 为0</p><pre><code>     第一个特征（3个1）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；同理，第二个特征（3个2）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；同理，第三个特征（3个3）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；同理，第二个特征（3个4）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；同理，第三个特征（3个5）                  计算结果：running_var = (1-0.3)*0.7+0.3 * 0 = 0.49；</code></pre><h2 id="2D"><a href="#2D" class="headerlink" title="2D"></a>2D</h2><p> ·nn.BatchNorm2d input=B* 特征数* 2d特征 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630223117775.png" alt="1630223117775" style="zoom:67%;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">batch_size = 3               # X轴长度</span><br><span class="line">num_features = 3             # Y轴长度</span><br><span class="line">momentum = 0.3   </span><br><span class="line">features_shape = (2, 2)  #   每个图形大小</span><br></pre></td></tr></table></figure><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224409278.png" alt="1630224409278" style="zoom:60%;"><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224422110.png" alt="1630224422110" style="zoom:80%;"><p>由于特征数num_features 是3，所以四个属性的shape也是3. 计算结果和1D一样。</p><h2 id="3D"><a href="#3D" class="headerlink" title="3D"></a>3D</h2><p> ·nn.BatchNorm3d input=B* 特征数* 3d特征 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224639302.png" alt="1630224639302" style="zoom:67%;"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">batch_size = 3</span><br><span class="line">num_features = 4</span><br><span class="line">momentum = 0.3</span><br><span class="line">features_shape = (2, 2, 3)     # 上图代码表示。</span><br></pre></td></tr></table></figure><p> 上述一个特征的维度是2 * 2 * 3，每个特征有4个特征数，总共有3个样本 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224866710.png" alt="1630224866710" style="zoom:85%;"><h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><h2 id="1-Layer-Normalization"><a href="#1-Layer-Normalization" class="headerlink" title="1.Layer Normalization"></a>1.Layer Normalization</h2><p> 起因：BN不适用于变长的网络，如RNN  ，特征数长短不一。</p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630224982805.png" alt="1630224982805" style="zoom:80%;"><p> 思路：逐层计算均值和方差，按下图三个圈圈来计算 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225024395.png" alt="1630225024395" style="zoom:80%;"><h2 id="2-Instance-Normalization"><a href="#2-Instance-Normalization" class="headerlink" title="2.Instance Normalization"></a>2.Instance Normalization</h2><p> 起因：BN在图像生成（lmage Generation）中不适用 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225208910.png" alt="1630225208910" style="zoom:80%;"><p> 思路：逐Instance（channel）计算均值和方差 </p><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225260732.png" alt="1630225260732" style="zoom:80%;"><p>nn.InstanceNorm主要参数（和bn一样，所以InstanceNorm也有1d，2d，3d，这里就不赘述了）：<br>·num_features：一个样本特征数量（最重要）<br>·eps：分母修正项<br>·momentum：指数加权平均估计当前mean/var<br>·affine：是否需要affine transform<br>·track_running_stats：是训练状态，还是测试状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import numpy as np</span><br><span class="line">import torch.nn as nn</span><br><span class="line">torch.manual_seed(9)  # 设置随机种子</span><br><span class="line"></span><br><span class="line"># ======================================== nn.layer norm</span><br><span class="line">flag = 1</span><br><span class="line">if flag:</span><br><span class="line">    batch_size = 3</span><br><span class="line">    num_features = 3</span><br><span class="line">    momentum = 0.3</span><br><span class="line"></span><br><span class="line">    features_shape = (2, 2)#设置这个大小是和上面图片一样</span><br><span class="line"></span><br><span class="line">    feature_map = torch.ones(features_shape)    # 2D</span><br><span class="line">    feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)  # 3D</span><br><span class="line">    feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)  # 4D</span><br><span class="line"></span><br><span class="line">    print(&quot;Instance Normalization&quot;)#打印输入数据</span><br><span class="line">    print(&quot;input data:\n&#123;&#125; \n shape is &#123;&#125;\n&quot;.format(feature_maps_bs, feature_maps_bs.shape))</span><br><span class="line"></span><br><span class="line">    instance_n = nn.InstanceNorm2d(num_features=num_features, momentum=momentum)</span><br><span class="line"></span><br><span class="line">    for i in range(1):</span><br><span class="line">        outputs = instance_n(feature_maps_bs)</span><br><span class="line"></span><br><span class="line">        print(outputs)</span><br><span class="line">        print(&quot;\niter:&#123;&#125;, running_mean.shape: &#123;&#125;&quot;.format(i, bn.running_mean.shape))</span><br><span class="line">        print(&quot;iter:&#123;&#125;, running_var.shape: &#123;&#125;&quot;.format(i, bn.running_var.shape))</span><br><span class="line">        print(&quot;iter:&#123;&#125;, weight.shape: &#123;&#125;&quot;.format(i, bn.weight.shape))</span><br><span class="line">        print(&quot;iter:&#123;&#125;, bias.shape: &#123;&#125;&quot;.format(i, bn.bias.shape))</span><br></pre></td></tr></table></figure><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225515365.png" alt="1630225515365" style="zoom: 67%;"><img src="/2021/08/29/%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BBbatch%20norm/1630225585148.png" alt="1630225585148" style="zoom:67%;">]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Batch-Normalization-概念&quot;&gt;&lt;a href=&quot;#Batch-Normalization-概念&quot; class=&quot;headerlink&quot; title=&quot;Batch Normalization 概念&quot;&gt;&lt;/a&gt;Batch Normalization </summary>
      
    
    
    
    <category term="深度学习（第一层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>归一化</title>
    <link href="http://example.com/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/"/>
    <id>http://example.com/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/</id>
    <published>2021-08-29T03:32:18.758Z</published>
    <updated>2021-08-29T04:50:08.738Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一-本文的内容包括："><a href="#一-本文的内容包括：" class="headerlink" title="一. 本文的内容包括："></a>一. 本文的内容包括：</h3><pre><code>   1. Batch Normalization，其论文：https://arxiv.org/pdf/1502.03167.pdf   2. Layer Normalizaiton，其论文：https://arxiv.org/pdf/1607.06450v1.pdf3. Instance Normalization，其论文：https://arxiv.org/pdf/1607.08022.pdf4. Group Normalization，其论文：https://arxiv.org/pdf/1803.08494.pdf5. Switchable Normalization，其论文：https://arxiv.org/pdf/1806.10779.pdf</code></pre><h3 id="二-介绍"><a href="#二-介绍" class="headerlink" title="二. 介绍"></a>二. 介绍</h3><p>​    在介绍各个算法之前，我们先引进一个问题：为什么要做归一化处理？</p><p>神经网络学习过程的本质就是为了学习数据分布，如果我们没有做归一化处理，那么每一批次训练数据的分布不一样，从大的方向上看，神经网络则需要在这多个分布中找到平衡点，从小的方向上看，由于每层网络输入数据分布在不断变化，这也会导致每层网络在找平衡点，显然，神经网络就很难收敛了。当然，如果我们只是对输入的数据进行归一化处理（比如将输入的图像除以255，将其归到0到1之间），只能保证输入层数据分布是一样的，并不能保证每层网络输入数据分布是一样的，所以也需要在神经网络的中间层加入归一化处理。</p><p>BN、LN、IN和GN这四个归一化的计算流程几乎是一样的，可以分为四步：</p><p>  1.计算出均值</p><p>  2.计算出方差</p><p>  3.归一化处理到均值为0，方差为1</p><p>  4.变化重构，恢复出这一层网络所要学到的分布           </p><p>​                 (尺度变换和偏移：将x_i乘以γ 调整数值大小，再加上β增加偏移后得到y_i ，这里的γ是尺度因子，β是平移因子。这一步是BN的精髓，由于归一化后的 x_i 基本会被限制在正态分布下，使得网络的表达能力下降。为解决该问题，我们引入两个新的参数：γ , β γ,β<em>γ</em>,<em>β</em>。 γ γ<em>γ</em>和β β<em>β</em>是在训练时网络自己学习得到的。)</p><img src="/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/1630208171755.png" alt="1630208171755" style="zoom:67%;"><p> 训练的时候，是根据输入的每一批数据来计算均值和方差，那么测试的时候，平均值和方差是怎么来的？</p><p>对于均值来说直接计算所有训练时batch 均值的平均值；然后对于标准偏差采用每个batch 方差的无偏估计</p><img src="/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/1630208372638.png" alt="1630208372638" style="zoom:67%;"><p>接下来，我们先用一个示意图来形象的表现BN、LN、IN和GN的区别（图片来自于GN这一篇论文），在输入图片的维度为（NCHW）中，HW是被合成一个维度，这个是方便画出示意图，C和N各占一个维度</p><p><img src="/2021/08/29/%E5%BD%92%E4%B8%80%E5%8C%96/1630208469512.png" alt="1630208469512"></p><p> Batch Normalization：</p><p>   1.BN的计算就是把每个通道的NHW单独拿出来归一化处理</p><p>   2.针对每个channel我们都有一组γ,β，所以可学习的参数为2*C</p><p>   3.当batch size越小，BN的表现效果也越不好，因为计算过程中所得到的均值和方差不能代表全局</p><p>Layer Normalizaiton：</p><p>   1.LN的计算就是把每个CHW单独拿出来归一化处理，不受batchsize 的影响</p><p>   2.常用在RNN网络，但如果输入的特征区别很大，那么就不建议使用它做归一化处理</p><p>Instance Normalization</p><p>   1.IN的计算就是把每个HW单独拿出来归一化处理，不受通道和batchsize 的影响</p><p>   2.常用在风格化迁移，但如果特征图可以用到通道之间的相关性，那么就不建议使用它做归一化处理</p><p>Group Normalization</p><p>1.GN的计算就是把先把通道C分成G组，然后把每个gHW单独拿出来归一化处理，最后把G组归一化之后的数据合并成CHW</p><p>2.GN介于LN和IN之间，当然可以说LN和IN就是GN的特列，比如G的大小为1或者为C</p><p>Switchable Normalization</p><p>1.将 BN、LN、IN 结合，赋予权重，让网络自己去学习归一化层应该使用什么方法</p><p>2.集万千宠爱于一身，但训练复杂</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;一-本文的内容包括：&quot;&gt;&lt;a href=&quot;#一-本文的内容包括：&quot; class=&quot;headerlink&quot; title=&quot;一. 本文的内容包括：&quot;&gt;&lt;/a&gt;一. 本文的内容包括：&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;   1. Batch Normalization，其论</summary>
      
    
    
    
    <category term="深度学习（第一层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>在深度学习中Python常用模块</title>
    <link href="http://example.com/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/"/>
    <id>http://example.com/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/</id>
    <published>2021-08-20T07:20:00.000Z</published>
    <updated>2021-08-29T03:33:17.411Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1、OS模块"><a href="#1、OS模块" class="headerlink" title="1、OS模块"></a>1、OS模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">os.getcwd()//获取当前工作的目录，如：返回结果为：&#x27;C:\\Program Files\\Python36&#x27;</span><br><span class="line">os.listdir(path)//列出path目录下所有的文件和目录名。Path参数可以省略,如：os.listdir(&quot;.&quot;)</span><br><span class="line">os.remove(path)//删除path指定的文件，该参数不能省略。</span><br><span class="line">os.rmdir(path)//删除path指定的目录，该参数不能省略。</span><br><span class="line">os.mkdir(path)//创建path指定的目录，该参数不能省略。递归建立可用：os.makedirs()</span><br><span class="line">os.path.split(path)//返回路径的目录和文件名，即将目录和文件名分开，而不是一个整体。此处只是把前后两部分分开而已。就是找最后一个&#x27;/&#x27;。</span><br><span class="line">os.path.join(path, name)//连接目录和文件名，与os.path.split(path)相对。</span><br><span class="line">os.chdir(path)//&#x27;change dir&#x27;改变目录到指定目录</span><br><span class="line">os.path.basename(path)//返回文件名</span><br><span class="line">os.path.dirname(path)//返回文件路径</span><br><span class="line">os.walk(path)//返回的是一个三元组(root,dirs,files):</span><br><span class="line">&#123;root 所指的是当前正在遍历的这个文件夹的本身的地址</span><br><span class="line">dirs 是一个 list ，内容是该文件夹中所有的目录的名字(不包括子目录)</span><br><span class="line">files 同样是 list , 内容是该文件夹中所有的文件(不包括子目录)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2、sys模块"><a href="#2、sys模块" class="headerlink" title="2、sys模块"></a>2、sys模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sys.path.insert(0,path)//使用sys.path.insert()方法可以临时添加搜索路径，方便更简洁的import其他包和模块。</span><br></pre></td></tr></table></figure><h2 id="3、pandas模块"><a href="#3、pandas模块" class="headerlink" title="3、pandas模块"></a>3、pandas模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">df：任意的Pandas DataFrame对象，一个类似于一维数组的对象，它有一个数组标签，也称之为索引 (index)</span><br><span class="line">s：任意的Pandas Series对象，类似于一个表格</span><br><span class="line"></span><br><span class="line">导入数据----------pd</span><br><span class="line"></span><br><span class="line">pd.read_csv(filename)//从CSV文件导入数据</span><br><span class="line">pd.read_json(json_string)//从JSON格式的字符串导入数据</span><br><span class="line">pd.DataFrame(dict)//从字典对象导入数据，Key是列名，Value是数据</span><br><span class="line">pd.read_excel(filename)//从Excel文件导入数据</span><br><span class="line"></span><br><span class="line">导出数据----------df.to</span><br><span class="line"></span><br><span class="line">df.to_csv(filename)//导出数据到CSV文件</span><br><span class="line">df.to_excel(filename)//导出数据到Excel文件</span><br><span class="line">df.to_json(filename)//以Json格式导出数据到文本文件</span><br><span class="line"></span><br><span class="line">创建测试对象</span><br><span class="line"></span><br><span class="line">pd.DataFrame(np.random.rand(20,5))//创建20行5列的随机数组成的DataFrame对象</span><br><span class="line">pd.Series(my_list)//从可迭代对象my_list创建一个Series对象</span><br><span class="line"></span><br><span class="line">查看、检查数据</span><br><span class="line"></span><br><span class="line">df.head(n)//查看DataFrame对象的前n行</span><br><span class="line">df.tail(n)//查看DataFrame对象的最后n行</span><br><span class="line">df.shape()//查看行数和列数</span><br><span class="line">df.info()//查看索引、数据类型和内存信息</span><br><span class="line"></span><br><span class="line">数据选取</span><br><span class="line"></span><br><span class="line">df[col]//根据列名，并以Series的形式返回列</span><br><span class="line">df[[col1, col2]]//以DataFrame形式返回多列</span><br><span class="line">s.iloc[0]//按位置选取数据</span><br><span class="line">s.loc[&#x27;index_one&#x27;]//按索引选取数据</span><br><span class="line">df.iloc[0,:]//返回第一行</span><br><span class="line">df.iloc[0,0]//返回第一列的第一个元素</span><br><span class="line">df.values[:,:-1]//返回除了最后一列的其他列的所以数据</span><br><span class="line">df.query(&#x27;[1, 2] not in c&#x27;)//返回c列中不包含1，2的其他数据集</span><br><span class="line"></span><br><span class="line">数据处理</span><br><span class="line"></span><br><span class="line">df[df[col] &gt; 0.5]//选择col列的值大于0.5的行</span><br><span class="line">df.sort_values(col1)//按照列col1排序数据，默认升序排列</span><br><span class="line">df.sort_values(col2, ascending=False)//按照列col1降序排列数据</span><br><span class="line">df.sort_values([col1,col2], ascending=[True,False])//先按列col1升序排列，后按col2降序排列数据</span><br><span class="line">df1.append(df2)//将df2中的行添加到df1的尾部</span><br><span class="line">df.concat([df1, df2],axis=1)//将df2中的列添加到df1的尾部</span><br><span class="line">df1.join(df2,on=col1,how=&#x27;inner&#x27;)//对df1的列和df2的列执行SQL形式的join</span><br><span class="line"></span><br><span class="line">数据统计</span><br><span class="line"></span><br><span class="line">df.describe()//查看数据值列的汇总统计</span><br><span class="line">df.mean()//返回所有列的均值</span><br><span class="line">df.corr()//返回列与列之间的相关系数</span><br><span class="line">df.count()//返回每一列中的非空值的个数</span><br><span class="line">df.max()//返回每一列的最大值</span><br><span class="line">df.min()//返回每一列的最小值</span><br><span class="line">df.median()//返回每一列的中位数</span><br><span class="line">df.std()//返回每一列的标准差</span><br></pre></td></tr></table></figure><h2 id="4、Numpy模块"><a href="#4、Numpy模块" class="headerlink" title="4、Numpy模块"></a>4、Numpy模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line">创建数组array</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">a = np.array([1,2,3])   #创建数组</span><br><span class="line">b = np.array([(1.5,2,3), (4,5,6)],dtype=float)</span><br><span class="line">c = np.array([(1.5,2,3), (4,5,6)],[(3,2,1), (4,5,6) ] ], dtype=float)</span><br><span class="line"></span><br><span class="line">np.zeros((3,4))  #创建0数组</span><br><span class="line">np.ones((2,3,4), dtype=np.int16)  #创建1数组</span><br><span class="line">d = np.arrange(10,25,5)  #创建相同步数数组</span><br><span class="line">np.linspace(0,2,9)  #创建等差数组</span><br><span class="line"></span><br><span class="line">e = np.full((2,2), 7) #创建常数数组</span><br><span class="line">f = np.eye(2) #创建2x2矩阵</span><br><span class="line">np.random.random((2,2)) #创建随机数组</span><br><span class="line">np.empty((3,2)) #创建空数组</span><br><span class="line"></span><br><span class="line">复制数组</span><br><span class="line"></span><br><span class="line">h = a.view()</span><br><span class="line">np.copy(a)</span><br><span class="line">h = a.copy()</span><br><span class="line"></span><br><span class="line">输出数组</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">print(my_array) #打印数组</span><br><span class="line"></span><br><span class="line">#saving &amp;Loading on disk保存到磁盘</span><br><span class="line">np.save(&#x27;my_array&#x27;, a)</span><br><span class="line">np.savez(&#x27;array.npz&#x27;, a, b)</span><br><span class="line">np.load(&#x27;my_array.npy&#x27;)</span><br><span class="line"></span><br><span class="line">#saving &amp;Loading Text files保存到文件</span><br><span class="line">np.loadtxt(&quot;my file.txt&quot;)</span><br><span class="line">np.genfromtxt(&quot;my_file.csv&quot;, delimiter=&#x27;,&#x27;)</span><br><span class="line">np.savetxt(&quot;marry.txt&quot;, a, delimiter=&quot;&quot;)</span><br><span class="line"></span><br><span class="line">Numpy中的基本运算</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">#arithmetic operation算术运算</span><br><span class="line">g = a - b</span><br><span class="line">np.subtract(a,b) #减法</span><br><span class="line">b+a</span><br><span class="line">np.add(b,a) #加法</span><br><span class="line">a / b</span><br><span class="line">np.divide(a,b) #除法</span><br><span class="line">a * b</span><br><span class="line">np.multiple(a,b) #乘法</span><br><span class="line">np.exp(b) #指数</span><br><span class="line">np.sqrt(b) #开方</span><br><span class="line">np.sin(a) #sin函数</span><br><span class="line">np.cos(b) #cos函数</span><br><span class="line">np.log(a) #log函数</span><br><span class="line">e.dot(f) #内积</span><br><span class="line"></span><br><span class="line">#Comparison比较</span><br><span class="line">a == b #元素</span><br><span class="line">a &lt; 2 #元素</span><br><span class="line">np.array_equal(a,b) #数组</span><br><span class="line"></span><br><span class="line">#Aggregate Functions 函数</span><br><span class="line">a.sum() #求和</span><br><span class="line">b.min() #最小值</span><br><span class="line">b.max(axis=0) #最大值数组列</span><br><span class="line">b.cumsum(axis=1) #元素累加和</span><br><span class="line">a.mean() #平均值</span><br><span class="line">b.median() #中位数</span><br><span class="line">a.corrcoef() #相关系数</span><br><span class="line">np.std(b) #标准差</span><br><span class="line"></span><br><span class="line">数组处理</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">#Transposing Array</span><br><span class="line">I = np.transpose(b) #转置矩阵</span><br><span class="line">i.T #转置矩阵</span><br><span class="line"></span><br><span class="line">#Changing Array Shape</span><br><span class="line">b.ravel() #降为一维数组</span><br><span class="line">g.reshape(3,-2) #重组</span><br><span class="line"></span><br><span class="line">#Adding/Removing Elements</span><br><span class="line">h.resize((2,6)) #返回shape(2,6)</span><br><span class="line">np.append(h,g) #添加</span><br><span class="line">np.insert(a,1,5) #插入</span><br><span class="line">np.delete(a,[1]) #删除</span><br><span class="line"></span><br><span class="line">#Combining Arrays</span><br><span class="line">np.concatenate((a,d), axis=0) #连结</span><br><span class="line">np.vstack((a,b)) #垂直堆叠</span><br><span class="line">np.r_[e,f] #垂直堆叠</span><br><span class="line">np.hstack((e,f)) #水平堆叠</span><br><span class="line">np.column_stack((a,d)) #创建水平堆叠</span><br><span class="line">np.c_[a,d] ##创建水平堆叠</span><br><span class="line"></span><br><span class="line">#splitting arrays</span><br><span class="line">np.hsplit(a,3) #水平分离</span><br><span class="line">np.vsplit(c,2) #垂直分离</span><br><span class="line"></span><br><span class="line">数组索引</span><br><span class="line">import numpy as np</span><br><span class="line">#subsetting</span><br><span class="line">a[2] #选取数组第三个元素</span><br><span class="line">b[1,2] #选取2行3列元素</span><br><span class="line"></span><br><span class="line">#slicing</span><br><span class="line">a[0:2] #选1到3元素</span><br><span class="line">b[0:2,1] #选1到2行的2列元素</span><br><span class="line">b[:1] #选所有1行的元素</span><br><span class="line">c[1,...] #c[1,:,:]</span><br><span class="line">a[ : :-1]  #反转数组</span><br><span class="line"></span><br><span class="line">#Boolean Indexing</span><br><span class="line">a[a&lt;2] #选取数组中元素&lt;2的</span><br><span class="line"></span><br><span class="line">#Fancy Indexing</span><br><span class="line">b[[1,0,1,0], [0,1,2,0]]</span><br><span class="line">#选取[1,0],[0,1],[1,2],[0,0]</span><br><span class="line">b[[1,0,1,0][:, [0,1,2,0]]]</span><br><span class="line">#选取矩阵的一部分</span><br><span class="line"></span><br><span class="line">Numpy中的数据类型</span><br><span class="line"></span><br><span class="line">np.int64 #64位整数</span><br><span class="line">np.float32 #标准双精度浮点</span><br><span class="line">np.complex #复杂树已浮点128为代表</span><br><span class="line">np.bool #true&amp;false</span><br><span class="line">np.object #python object</span><br><span class="line">np.string_ #固定长度字符串</span><br><span class="line">np.unicode_ #固定长度统一码</span><br><span class="line"></span><br><span class="line">检查数组信息</span><br><span class="line">a.shape #数组维度</span><br><span class="line">len(a) #数组长度</span><br><span class="line">b.ndim #数组维度数量</span><br><span class="line">e.size #数组元素数量</span><br><span class="line">b.dtype #元素数据类型</span><br><span class="line">b.dtype.name #数据类型名</span><br><span class="line">b.astype(int) #改变数组类型</span><br><span class="line"></span><br><span class="line">#asking for help更多信息</span><br><span class="line">np.info(np.ndarray.dtype)</span><br><span class="line"></span><br><span class="line">对数组进行排序</span><br><span class="line"></span><br><span class="line">#对数组进行排序</span><br><span class="line">a.sort()</span><br><span class="line">c.sort(axis=0)</span><br></pre></td></tr></table></figure><h2 id="5、matplotlib模块"><a href="#5、matplotlib模块" class="headerlink" title="5、matplotlib模块"></a>5、matplotlib模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">plt.figure(num=None,</span><br><span class="line">figsize=None, </span><br><span class="line"> dpi=None,</span><br><span class="line"> facecolor=None, </span><br><span class="line">  edgecolor=None, </span><br><span class="line">  frameon=True, </span><br><span class="line">  FigureClass=&lt;class &#x27;matplotlib.figure.Figure&#x27;&gt;, </span><br><span class="line">  clear=False, **kwargs)</span><br><span class="line">  num：整数或字符串，可选，默认:无</span><br><span class="line">  figsize：(float, float), optional, default: None</span><br><span class="line">  dpi：图形分辨率，整数，可选，默认:无</span><br><span class="line">  facecolor：背景颜色</span><br><span class="line">  edgecolor：边框颜色</span><br><span class="line">  frameon：bool，可选，默认值:True//如果为False，则禁止绘制图形框</span><br><span class="line">  FigureClass：图的子类</span><br><span class="line">  clear：bool，可选，默认值:True如果为True且该图片已经存在，则清除它。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.imshow()</span><br><span class="line"></span><br><span class="line">plt.imshow(X, </span><br><span class="line">cmap=None,</span><br><span class="line"> norm=None, </span><br><span class="line"> aspect=None, </span><br><span class="line"> interpolation=None, </span><br><span class="line"> alpha=None, </span><br><span class="line"> vmin=None, </span><br><span class="line"> vmax=None, </span><br><span class="line"> origin=None, </span><br><span class="line"> extent=None, </span><br><span class="line"> shape=&lt;deprecated parameter&gt;, </span><br><span class="line"> filternorm=1, </span><br><span class="line"> filterrad=4.0,</span><br><span class="line"> imlim=&lt;deprecated parameter&gt;, </span><br><span class="line"> resample=None, </span><br><span class="line"> url=None, </span><br><span class="line"> *, </span><br><span class="line"> data=None, </span><br><span class="line"> **kwargs)</span><br><span class="line">X：图像数据</span><br><span class="line">cmap：str或Colormap，可选</span><br><span class="line">norm：正常化,可选</span><br><span class="line">aspect：&#123;&#x27;equal&#x27;， &#x27;auto&#x27;&#125;或float，可选‘equal’:确保长宽比为1；’auto‘：自动调整长宽</span><br><span class="line">interpolation：str,可选 &#x27;none&#x27;, &#x27;nearest&#x27;, &#x27;bilinear&#x27;, &#x27;bicubic&#x27;, &#x27;spline16&#x27;, &#x27;spline36&#x27;, &#x27;hanning&#x27;, &#x27;hamming&#x27;, </span><br><span class="line">&#x27;hermite&#x27;, &#x27;kaiser&#x27;, &#x27;quadric&#x27;, &#x27;catrom&#x27;, &#x27;gaussian&#x27;, &#x27;bessel&#x27;, &#x27;mitchell&#x27;, &#x27;sinc&#x27;, &#x27;lanczos&#x27;</span><br><span class="line">alpha：比例,可选介于0(透明)和1(不透明)之间</span><br><span class="line">vmin, vmax：比例,可选当使用标量数据而没有明确的norm时，vmin和vmax定义了颜色映射所涵盖的数据范围</span><br><span class="line">origin： &#123;&#x27;upper&#x27;, &#x27;lower&#x27;&#125;，可选的</span><br><span class="line"></span><br><span class="line">plt.subplot()</span><br><span class="line"></span><br><span class="line">plt.subplot(nrows,ncols,index,**kwargs)</span><br><span class="line">子图将在包含nrows行和ncols列的网格中占据索引位置。index从左上角的1开始，向右递增</span><br><span class="line"></span><br><span class="line">plt.plot()</span><br><span class="line"></span><br><span class="line">plt.plot(x,y,format_string,**kwargs)</span><br><span class="line">x轴数据，</span><br><span class="line">y轴数据，</span><br><span class="line">format_string控制曲线的格式字串 ，format_string由颜色字符，风格字符，和标记字符 </span><br><span class="line">&#x27;b&#x27;blue</span><br><span class="line">&#x27;g&#x27;green</span><br><span class="line">&#x27;r&#x27;red</span><br><span class="line">&#x27;c&#x27;cyan</span><br><span class="line">&#x27;m&#x27;magenta</span><br><span class="line">&#x27;y&#x27;yellow</span><br><span class="line">&#x27;k&#x27;black</span><br><span class="line">&#x27;w&#x27;white</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="6、argparse模块"><a href="#6、argparse模块" class="headerlink" title="6、argparse模块"></a>6、argparse模块</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">##创建解析器</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=&#x27;Process some integers.&#x27;)</span><br><span class="line"></span><br><span class="line">该ArgumentParser对象将保存将命令行解析为 Python 数据类型所需的所有信息。</span><br><span class="line"></span><br><span class="line">## 添加参数</span><br><span class="line"></span><br><span class="line">ArgumentParser通过调用add_argument() 方法来填充有关程序参数的信息。通常，这些调用告诉ArgumentParser 如何在命令行上获取字符串并将它们转换为对象。该信息在parse_args()被调用时被存储和使用。例如：</span><br><span class="line"> parser.add_argument(&#x27;integers&#x27;, metavar=&#x27;N&#x27;, type=int, nargs=&#x27;+&#x27;,</span><br><span class="line">                    help=&#x27;an integer for the accumulator&#x27;)</span><br><span class="line"> parser.add_argument(&#x27;--sum&#x27;, dest=&#x27;accumulate&#x27;, action=&#x27;store_const&#x27;,</span><br><span class="line">                     const=sum, default=max,</span><br><span class="line">                     help=&#x27;sum the integers (default: find the max)&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 解析参数</span><br><span class="line"></span><br><span class="line">ArgumentParser 通过parse_args()方法解析参数 。这将检查命令行，将每个参数转换为适当的类型，然后调用适当的操作。</span><br><span class="line"></span><br><span class="line"> config = parser.parse_args()</span><br><span class="line"></span><br><span class="line">在脚本中，parse_args()通常会不带参数地调用，并且将自动从确定命令行参数sys.argv</span><br><span class="line"></span><br><span class="line">## ArgumentParser 对象----代码只用到了三个</span><br><span class="line"></span><br><span class="line">argparse.addP_ArgumentParser( *prog=None* , *usage=None* , *description=None* , *epilog=None* , *parents=[]* , *formatter_class=argparse.HelpFormatter* , *prefix_chars=&#x27;-&#x27;* , *fromfile_prefix_chars=None* , *argument_default=None* , *conflict_handler=&#x27;error&#x27;* , *add_help =True* , *allow_abbrev=True* , *exit_on_error=True* ) </span><br><span class="line"></span><br><span class="line">  创建一个新ArgumentParser对象。所有参数都应作为关键字参数传递。每个参数在下面都有更详细的描述，但简而言之，它们是：</span><br><span class="line"></span><br><span class="line">  PROG -程序的名称（默认：`sys.argv[0]`）</span><br><span class="line"></span><br><span class="line">  description- 在参数帮助之前显示的文本（默认值：无）</span><br><span class="line"></span><br><span class="line">  argument_default -为参数的全局默认值（默认值：`None`）</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="7、PIL库—处理图像"><a href="#7、PIL库—处理图像" class="headerlink" title="7、PIL库—处理图像"></a>7、PIL库—处理图像</h2><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629444947068.png" alt="1629444947068"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629444960440.png" alt="1629444960440"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629444979009.png" alt="1629444979009"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629445020254.png" alt="1629445020254"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629445055246.png" alt="1629445055246"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629445103852.png" alt="1629445103852"></p><p><img src="/2021/08/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84python%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97/1629445114582.png" alt="1629445114582"></p><h2 id="8、pytorch读取数据"><a href="#8、pytorch读取数据" class="headerlink" title="8、pytorch读取数据"></a>8、pytorch读取数据</h2><p>具体细节看—<a href="https://zhuanlan.zhihu.com/p/30934236">https://zhuanlan.zhihu.com/p/30934236</a></p><h2 id="9-itertools库"><a href="#9-itertools库" class="headerlink" title="9.itertools库"></a>9.itertools库</h2><p> &emsp;&emsp;迭代器（生成器）在Python中是一种很常用也很好用的数据结构，比起列表(list)来说，迭代器最大的优势就是延迟计算，按需使用，从而提高开发体验和运行效率，以至于在Python 3中map,filter等操作返回的不再是列表而是迭代器。 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line">itertools.accumulate</span><br><span class="line"></span><br><span class="line">简单来说就是累加。</span><br><span class="line">&gt;&gt;&gt; import itertools</span><br><span class="line">&gt;&gt;&gt; x = itertools.accumulate(range(10))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 1, 3, 6, 10, 15, 21, 28, 36, 45]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.chain</span><br><span class="line"></span><br><span class="line">连接多个列表或者迭代器。</span><br><span class="line">&gt;&gt;&gt; x = itertools.chain(range(3), range(4), [3,2,1])</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 1, 2, 0, 1, 2, 3, 3, 2, 1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.combinations</span><br><span class="line"></span><br><span class="line">求列表或生成器中指定数目的元素不重复的所有组合</span><br><span class="line">&gt;&gt;&gt; x = itertools.combinations(range(4), 3)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(0, 1, 2), (0, 1, 3), (0, 2, 3), (1, 2, 3)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.combinations_with_replacement</span><br><span class="line"></span><br><span class="line">允许重复元素的组合</span><br><span class="line">&gt;&gt;&gt; x = itertools.combinations_with_replacement(&#x27;ABC&#x27;, 2)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(&#x27;A&#x27;, &#x27;A&#x27;), (&#x27;A&#x27;, &#x27;B&#x27;), (&#x27;A&#x27;, &#x27;C&#x27;), (&#x27;B&#x27;, &#x27;B&#x27;), (&#x27;B&#x27;, &#x27;C&#x27;), (&#x27;C&#x27;, &#x27;C&#x27;)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.compress</span><br><span class="line">按照真值表筛选元素</span><br><span class="line">&gt;&gt;&gt; x = itertools.compress(range(5), (True, False, True, True, False))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 2, 3]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.count</span><br><span class="line"></span><br><span class="line">就是一个计数器,可以指定起始位置和步长</span><br><span class="line">&gt;&gt;&gt; x = itertools.count(start=20, step=-1)</span><br><span class="line">&gt;&gt;&gt; print(list(itertools.islice(x, 0, 10, 1)))</span><br><span class="line">[20, 19, 18, 17, 16, 15, 14, 13, 12, 11]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.cycle</span><br><span class="line"></span><br><span class="line">循环指定的列表和迭代器</span><br><span class="line">&gt;&gt;&gt; x = itertools.cycle(&#x27;ABC&#x27;)</span><br><span class="line">&gt;&gt;&gt; print(list(itertools.islice(x, 0, 10, 1)))</span><br><span class="line">[&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;A&#x27;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.dropwhile</span><br><span class="line"></span><br><span class="line">按照真值函数丢弃掉列表和迭代器前面的元素</span><br><span class="line">&gt;&gt;&gt; x = itertools.dropwhile(lambda e: e &lt; 5, range(10))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[5, 6, 7, 8, 9]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.filterfalse</span><br><span class="line"></span><br><span class="line">保留对应真值为False的元素</span><br><span class="line">&gt;&gt;&gt; x = itertools.filterfalse(lambda e: e &lt; 5, (1, 5, 3, 6, 9, 4))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[5, 6, 9]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.groupby</span><br><span class="line"></span><br><span class="line">按照分组函数的值对元素进行分组</span><br><span class="line">&gt;&gt;&gt; x = itertools.groupby(range(10), lambda x: x &lt; 5 or x &gt; 8)                                                                                                </span><br><span class="line">&gt;&gt;&gt; for condition, numbers in x:                                                  </span><br><span class="line">...     print(condition, list(numbers))                                                                                                        </span><br><span class="line">True [0, 1, 2, 3, 4]                                                              </span><br><span class="line">False [5, 6, 7, 8]                                                                </span><br><span class="line">True [9]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.islice</span><br><span class="line">上文使用过的函数，对迭代器进行切片</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x = itertools.islice(range(10), 0, 9, 2)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 2, 4, 6, 8]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.permutations</span><br><span class="line">产生指定数目的元素的所有排列(顺序有关)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x = itertools.permutations(range(4), 3)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(0, 1, 2), (0, 1, 3), (0, 2, 1), (0, 2, 3), (0, 3, 1), (0, 3, 2), (1, 0, 2), (1, 0, 3), (1, 2, 0), (1, 2, 3), (1, 3, 0), (1, 3, 2), (2, 0, 1), (2, 0,3), (2, 1, 0), (2, 1, 3), (2, 3, 0), (2, 3, 1), (3, 0, 1), (3, 0, 2), (3, 1, 0), (3, 1, 2), (3, 2, 0), (3, 2, 1)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.product</span><br><span class="line"></span><br><span class="line">产生多个列表和迭代器的(积)</span><br><span class="line">&gt;&gt;&gt; x = itertools.product(&#x27;ABC&#x27;, range(3))</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(&#x27;A&#x27;, 0), (&#x27;A&#x27;, 1), (&#x27;A&#x27;, 2), (&#x27;B&#x27;, 0), (&#x27;B&#x27;, 1), (&#x27;B&#x27;, 2), (&#x27;C&#x27;, 0), (&#x27;C&#x27;, 1), (&#x27;C&#x27;, 2)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.repeat</span><br><span class="line"></span><br><span class="line">简单的生成一个拥有指定数目元素的迭代器</span><br><span class="line">&gt;&gt;&gt; x = itertools.repeat(0, 5)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 0, 0, 0, 0]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.starmap</span><br><span class="line"></span><br><span class="line">类似map</span><br><span class="line">&gt;&gt;&gt; x = itertools.starmap(str.islower, &#x27;aBCDefGhI&#x27;)</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[True, False, False, False, True, True, False, True, False]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.takewhile</span><br><span class="line"></span><br><span class="line">与dropwhile相反，保留元素直至真值函数值为假。</span><br><span class="line">&gt;&gt;&gt; x = itertools.takewhile(lambda e: e &lt; 5, range(10))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[0, 1, 2, 3, 4]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.tee</span><br><span class="line"></span><br><span class="line">生成指定数目的迭代器</span><br><span class="line">&gt;&gt;&gt; x = itertools.tee(range(10), 2)</span><br><span class="line">&gt;&gt;&gt; for letters in x:</span><br><span class="line">...     print(list(letters))</span><br><span class="line">...</span><br><span class="line">[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span><br><span class="line">[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">itertools.zip_longest</span><br><span class="line">类似于zip，不过已较长的列表和迭代器的长度为准</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x = itertools.zip_longest(range(3), range(5))</span><br><span class="line">&gt;&gt;&gt; y = zip(range(3), range(5))</span><br><span class="line">&gt;&gt;&gt; print(list(x))</span><br><span class="line">[(0, 0), (1, 1), (2, 2), (None, 3), (None, 4)]</span><br><span class="line">&gt;&gt;&gt; print(list(y))</span><br><span class="line">[(0, 0), (1, 1), (2, 2)]</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1、OS模块&quot;&gt;&lt;a href=&quot;#1、OS模块&quot; class=&quot;headerlink&quot; title=&quot;1、OS模块&quot;&gt;&lt;/a&gt;1、OS模块&lt;/h2&gt;&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=</summary>
      
    
    
    
    <category term="深度学习（第一层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="常用模块（第二层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="python" scheme="http://example.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>解读第四阶段素描GAN代码</title>
    <link href="http://example.com/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/"/>
    <id>http://example.com/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/</id>
    <published>2021-08-14T08:20:25.707Z</published>
    <updated>2021-09-01T05:47:35.578Z</updated>
    
    <content type="html"><![CDATA[<h1 id="填充和归一化"><a href="#填充和归一化" class="headerlink" title="填充和归一化"></a>填充和归一化</h1><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629449069633.png" alt="1629449069633"></p><p> **nn.ReflectionPad2d，使用输入边界的反射填充输入张量，与常规的零填充相比， 填充内容来自输入， 在GAN中使用比较常见。 **</p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629448984899.png" alt="1629448984899"></p><p> <code>torch.nn.Conv2d</code>( <em>in_channels</em> , <em>out_channels</em> , <em>kernel_size</em> , <em>stride=1</em> , <em>padding=0</em> , <em>dilation=1</em> , <em>groups=1</em> , <em>bias=True</em> , <em>padding_mode=’zeros’</em> , <em>device=None</em> , <em>dtype=None</em> ) </p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629449268090.png" alt="1629449268090"></p><p> <code>torch.nn.InstanceNorm2d</code>( <em>num_features</em> , <em>eps=1e-05</em> , <em>Momentum=0.1</em> , <em>affine=False</em> , <em>track_running_stats=False</em> , <em>device=None</em> , <em>dtype=None</em> ) ——第一个值：预期输入的大小。</p><p> 对于一个4D（N, C, H, W）张量，对于每个mini-batch (N)， 在每个通道 ( C ) 对每个二维张量 (H, W) 单独进行计算均值和方差。即对于一个（16，256， 128，128）的张量，计算16*256次均值方差。 </p><p> 对 4D 输入（具有附加通道维度的小批量 2D 输入）应用实例标准化 ，均值和标准差是针对小批量中的每个对象分别按维度计算的。 γ<em>γ</em> 和 β<em>β</em>是大小为C（其中C是输入大小）的可学习参数向量 </p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629450185909.png" alt="1629450185909"></p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629450464658.png" alt="1629450464658"></p><h1 id="生成器和判别器"><a href="#生成器和判别器" class="headerlink" title="生成器和判别器"></a>生成器和判别器</h1><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629461869476.png" alt="1629461869476"></p><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;生成器结构为上图。</p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629460495243.png" alt="1629460495243"></p><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;判别器结构为上图。</p><h2 id="生成器具体结构"><a href="#生成器具体结构" class="headerlink" title="生成器具体结构"></a>生成器具体结构</h2><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630393690709.png" alt="1630393690709"></p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630393705838.png" alt="1630393705838"></p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630393723184.png" alt="1630393723184"></p><h3 id="判别器具体结构"><a href="#判别器具体结构" class="headerlink" title="判别器具体结构"></a>判别器具体结构</h3><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630393831249.png" alt="1630393831249"></p><p>&emsp;&emsp;普通的GAN判别器最终输出一个向量，只需要输出一个表示整个图像评估的真或假，但PatchGAN的输出是一个N *N矩阵，每个元素如只有两个选择True或False，结果通常通过卷积层来实现。鉴别器对每个补丁进行真假判别，并取平均值作为最终鉴别器输出的图片结果。</p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629462224062.png" alt="1629462224062" style="zoom:50%;"><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;ResNet结构</p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1629466487764.png" alt="1629466487764"></p><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;完整流程图</p><h1 id="优化器-Optimizer"><a href="#优化器-Optimizer" class="headerlink" title="优化器 Optimizer"></a>优化器 Optimizer</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prediction = wx + b             # b 是偏置量</span><br></pre></td></tr></table></figure><p>训练的过程，其实就是计算合适的w和b的过程。那么，什么样的w和b是“合适”的呢？答案就是预测值与真实值相差不大。例如定义损失函数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = sum(|(y_ - prediction)|)</span><br></pre></td></tr></table></figure><p>即，真实值减去预测值，取绝对值后求和。训练的过程，可以粗略的理解成：调节 w 和 b， 使 loss 尽可能小。对w和b参数的调节，就是优化器（optimizer）需要做的，这就是优化器的作用。</p><p> <strong>在训练阶段， 每一次训练，神经网络参数都将得到一次拟合，达到一定次数后，才会收敛。而每次收敛的调整节奏，则取决于优化器</strong> </p><h2 id="优化器中的常用算法分为"><a href="#优化器中的常用算法分为" class="headerlink" title="优化器中的常用算法分为"></a>优化器中的常用算法分为</h2><p>（1）朴素梯度下降</p><ul><li><p>批量梯度下降法(Batch Gradient Descent )</p></li><li><p>随机梯度下降法（Stochastic Gradient Descent）</p></li><li><p>小批量随机梯度下降（Mini-Batch Gradient Descent）</p></li><li><p>带有动量的随机梯度下降(SGD with momentum)</p></li></ul><p>(2) 自适应梯度下降</p><ul><li> Adagrad （Adaptive gradient algorithm）</li><li> Adadelta/RMSProp</li><li> Adam（Adaptive Moment Estimation）</li><li> NAdam </li></ul><h3 id="Pytorch的十种优化器"><a href="#Pytorch的十种优化器" class="headerlink" title="Pytorch的十种优化器"></a>Pytorch的十种优化器</h3><p>1、optim.SGD：随机梯度下降法<br>2、optim.Adagrad：自适应学习率梯度下降法（对每个可学习参数具有1个自适应学习率）<br>3、optim.RMSprop：Adagrad的改进<br>4、optim.Adadelta：Adagrad的改进<br>5、optim.Adam：RMSprop结合Momentum<br>6、optim.Adamax：Adam增加学习率上限<br>7、optim.SparseAdam：稀疏版Adam<br>8、optim.ASGD：随机平均梯度下降<br>9、optim.Rprop：弹性反向传播（优化器应用场景在所有样本full_batch 一起计算梯度）<br>10、optim.LBFGS：BFGS的改进<br>原文链接：<a href="https://blog.csdn.net/qq_43784940/article/details/107955191">https://blog.csdn.net/qq_43784940/article/details/107955191</a></p><p><a href="https://www.cnblogs.com/peachtea/p/13532190.html">https://www.cnblogs.com/peachtea/p/13532190.html</a></p><p>torch为什么要使用optimizer.zero_grad() <a href="https://blog.csdn.net/scut_salmon/article/details/82414730">https://blog.csdn.net/scut_salmon/article/details/82414730</a></p><h3 id="1-批量梯度下降法-Batch-gradient-descent）"><a href="#1-批量梯度下降法-Batch-gradient-descent）" class="headerlink" title="1. 批量梯度下降法(Batch gradient descent）"></a><strong>1. 批量梯度下降法(Batch gradient descent</strong>）</h3><p><strong>更新规则</strong>：采用整个训练集的数据来计算loss函数对参数的梯度： </p><p><strong>优点</strong>：对于凸函数可以收敛到全局极小值，对于非凸函数可以收敛到局部极小值<br><strong>缺点</strong>：在一次更新中，对整个数据集计算梯度，计算速度很慢；如果数据集过大，则内存无法容纳；在模型训练过程中，无法使用新的数据更新模型。 </p><h3 id="2-随机梯度下降Stochastic-gradient-descent"><a href="#2-随机梯度下降Stochastic-gradient-descent" class="headerlink" title="2.随机梯度下降Stochastic gradient descent"></a><strong>2.随机梯度下降Stochastic gradient descent</strong></h3><p><strong>更新规则</strong>：SGD每次更新时对每个样本进行梯度下降。 </p><p> <strong>优点</strong>：对于很大的数据集来说，可能有很相似的样本，导致BGD在计算梯度时会出现冗余，而SGD一次只进行单样本更新，所以针对一次更新来说没有冗余，而且速度快<br><strong>缺点</strong>：更新频繁，造成loss函数严重震荡。  </p><p> BGD可以收敛到局部最小值，SGD的震荡也可能跳到更优的局部最小值。稍微减少learning rate，SGD和BGD收敛性一致，对凸函数和非凸函数能分别收敛到全局最优和局部最优。 </p><h3 id="3-小批量梯度下降Mini-batch-Stochastic-gradient-descent"><a href="#3-小批量梯度下降Mini-batch-Stochastic-gradient-descent" class="headerlink" title="3.小批量梯度下降Mini-batch Stochastic gradient descent"></a><strong>3.小批量梯度下降Mini-batch Stochastic gradient descent</strong></h3><p><strong>梯度更新规则</strong>：每一次更新使用一小批样本进行更新</p><p>和 SGD 的区别是每一次循环不是作用于每个样本，而是具有 n 个样本的批次。</p><p>优点：降低参数更新时的方差，收敛更稳定；可利用深度学习库中高度优化的矩阵操作来更有效的梯度计算<br><strong>缺点：</strong>MBSGD不能保证很好的收敛性，提供了一系列的挑战需要去解决：<br>1.选择合适的学习率十分困难。如果选择太小，收敛速度太慢；如果太大，loss函数会在极小值出震荡甚至发散。<br>2.学习率在训练过程中退火调整，学习率的减少根据提前确定好的计划或者当目标在两个轮次之间的变化低于一个阈值，计划和阈值必须要提前确定，因此不能适应数据集的特征。<br>3.对所有参数更新时应用同样的学习率，如果数据是稀疏的，更希望对出现频率低的特征进行大一点的更新。<br>4.对于非凸的误差函数，要避免陷入局部极小值以及鞍点处。鞍点周围的梯度都一样并且趋近于0，SGD不容易突破。</p><h3 id="4-含有动量的随机梯度下降法SGD-with-momentum"><a href="#4-含有动量的随机梯度下降法SGD-with-momentum" class="headerlink" title="4.含有动量的随机梯度下降法SGD with momentum"></a><strong>4.含有动量的随机梯度下降法SGD with momentum</strong></h3><p>SGD在山谷的情况下不容易导向，会多走一些弯路，山谷的曲面在某一个参数维度会比另外一个参数维度更陡峭，这种情况在局部最优解附近很常见。在这种场景下，SGD穿过山谷的斜坡时会震荡。 </p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630378142301.png" alt="1630378142301"></p><p>momentum能帮助加速SGD在确定方向的下降并且抑制震荡。<br>超参数一般设为0.9左右，意味着参数更新方向不仅由当前梯度决定，也与此前累计的下降方向有关，这使得momentum会增加更新某个维度下降方向不变的梯度，减少更新某个维度下降方向改变的梯度。因此获得了更快的收敛性和减少了震荡。</p><h3 id="5-AdaGrad"><a href="#5-AdaGrad" class="headerlink" title="5.AdaGrad"></a>5.AdaGrad</h3><p>针对SGD及Momentum存在的问题，2011年John Duchi等发布了AdaGrad（Adaptive Gradient，自适应梯度）优化算法，<strong>能够对每个不同参数调整不同的学习率，对频繁变化的参数以更小的步长进行更新，而稀疏的参数以更大的步长更新。</strong>对稀疏的数据表现很好，提高了SGD的鲁棒性。<br><strong>优点：</strong>能够为不同参数应不同的学习率，大多数学习率（<strong>η</strong>）使用0.01为默认值可实现较好的效果。<br><strong>缺点：</strong>分母项对梯度平方进行不断的累加，分母项越来越大，最终学习率收缩到无穷小使得无法进行有效更新。 </p><h3 id="6-Adadelta-RMSProp"><a href="#6-Adadelta-RMSProp" class="headerlink" title="6.Adadelta/RMSProp"></a>6.Adadelta/RMSProp</h3><p>为了解决AdaGrad单调递减的学习率急速下降的问题，考虑一个改变二阶动量计算方法的策略：不累积全部梯度，而只关注过去一段时间窗口的下降梯度，这就是delta中的来历。<br>采用计算梯度的指数移动平均数（Exponential Moving Average） ， 这个算法是对 Adagrad 的改进， </p><h3 id="7-Adam"><a href="#7-Adam" class="headerlink" title="7.Adam"></a><strong>7.Adam</strong></h3><p>可以认为是RMSprop和Momentum的结合。对一阶动量和二阶动量都采用指数移动平均计算。<br>默认为0.9,默认为0,999。在迭代初始阶段，和有一个向初值的偏移（过多偏向0），因此需要对一阶和二阶动量进行偏置校正（bias correction） </p><p><img src="/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A8%8B%E8%A7%A3%E8%AF%BB/1630378505616.png" alt="1630378505616"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;填充和归一化&quot;&gt;&lt;a href=&quot;#填充和归一化&quot; class=&quot;headerlink&quot; title=&quot;填充和归一化&quot;&gt;&lt;/a&gt;填充和归一化&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;/2021/08/14/%E4%BB%A3%E7%A0%81%E6%B5%81%E7%A</summary>
      
    
    
    
    <category term="深度学习（第一层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="代码解读（第二层级）" scheme="http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN" scheme="http://example.com/tags/GAN/"/>
    
  </entry>
  
  <entry>
    <title>Residual Attention Network</title>
    <link href="http://example.com/2021/08/04/Residual%20Attention%20Network/"/>
    <id>http://example.com/2021/08/04/Residual%20Attention%20Network/</id>
    <published>2021-08-04T04:16:21.000Z</published>
    <updated>2021-08-05T04:26:17.350Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1、论文全名-—-Residual-Attention-Network-for-Image-Classification"><a href="#1、论文全名-—-Residual-Attention-Network-for-Image-Classification" class="headerlink" title="1、论文全名 — Residual Attention Network for Image Classification"></a>1、论文全名 — Residual Attention Network for Image Classification</h1><h1 id="2、-emsp-整体结构"><a href="#2、-emsp-整体结构" class="headerlink" title="2、&emsp;整体结构"></a>2、&emsp;整体结构</h1><p><img src="/2021/08/04/Residual%20Attention%20Network/1628056822799.png" alt="1628056822799"></p><p>左图:一个例子展示了特征和注意力面具之间的相互作用。</p><p>右图:举例说明在我们的网络中，不同的特征有不同的对应注意面具。</p><p><img src="/2021/08/04/Residual%20Attention%20Network/1628066487666.png" alt="1628066487666"></p><center>软掩码分支结构</center>&emsp;&emsp;&emsp;掩码分支包含**快速前馈扫描**和**自上而下的反馈**步骤。**前者快速采集整幅图像的全局信息，后者将全局信息与原始特征图相结合**。在卷积神经网络中，这两个步骤展开为自下而上、自上而下的全卷积结构。从输入来看，在少量剩余单位后，**进行几次最大池化以快速增加感受野**。在达到最低分辨率后，全局信息通过**对称**的自上而下架构进行扩展，以指导每个位置的输入特征。**线性插值在一些残差单位后向上采样输出**。**双线性插值的数量与最大池化相同，以保持输出大小与输入要素图相同**。然后，连续两个1 × 1卷积层后，sigmoid层对输出进行归一化，范围为[0，1]。我们还在自下而上和自上而下的零件之间添加了跳跃连接，以从不同的比例捕获信息。<p><img src="/2021/08/04/Residual%20Attention%20Network/1628065657226.png" alt="1628065657226"></p><center>残差注意力网络结构</center>超参数p表示在分成主干分支和掩码分支**之前预处理剩余单元的数量**。t表示**主干分支**中剩余单元的数量。r表示**掩码分支**中相邻汇集层之间的剩余单元数。<center>软掩码分支结构</center># 3、 残差注意力网络分析<p>我们的剩余注意力网络是通过堆叠多个注意力模块构建的。每个注意模块分为两个分支:掩码分支和主干分支。主干分支执行特征处理，并且可以适应任何最先进的网络结构。</p><p>使用pre-activation Residual Unit、ResNeXt 和Inception 作为剩余注意网络的基本单元来构建注意模块</p><h2 id="3-1-emsp-注意力剩余学习"><a href="#3-1-emsp-注意力剩余学习" class="headerlink" title="3.1&emsp;注意力剩余学习"></a>3.1&emsp;注意力剩余学习</h2><p>给定输入为x的主干分支输出T(x)，掩码分支使用自下而上自上而下的结构来学习相同大小的掩码M(x)，该掩码对输出特征T(x)进行软加权。</p><p>注意模块H的输出为：     &emsp;&emsp;&emsp;&emsp;</p><img src="/2021/08/04/Residual%20Attention%20Network/1628066609969.png" alt="1628066609969"><p>在Attention Modules 中，attention mask不仅可以在前向推理过程中充当特征选择器，还可以在反向传播过程中充当梯度更新过滤器。在软遮罩分支中，输入要素的遮罩梯度为:</p><p><img src="/2021/08/04/Residual%20Attention%20Network/1628129507416.png" alt="1628129507416"></p><p>θ是掩码分支参数，φ是主干分支参数。此属性使注意力模块对有噪声的标签具有鲁棒性。遮罩分支可以防止错误的渐变(来自有噪声的标签)来更新主干参数。</p><h2 id="3-2-emsp-软掩码分支（Soft-Mask-Branch）"><a href="#3-2-emsp-软掩码分支（Soft-Mask-Branch）" class="headerlink" title="3.2&emsp;软掩码分支（Soft Mask Branch）"></a>3.2&emsp;软掩码分支（Soft Mask Branch）</h2><p>掩码分支目的是改进主干分支特征，而不是直接解决复杂的问题</p><p><img src="/2021/08/04/Residual%20Attention%20Network/1628131500040.png" alt="1628131500040"></p><center>掩蔽分支和主干分支的感受野比较</center>注意力模块的输出修改为：&emsp;&emsp;&emsp;<p><img src="/2021/08/04/Residual%20Attention%20Network/1628130312831.png" alt="1628130312831"></p><p><img src="/2021/08/04/Residual%20Attention%20Network/1628130471469.png" alt="1628130471469" style="zoom:85%;">是由深度卷积网络生成的特征mask分支M(x)，它们充当特征选择器，增强好的特征并抑制来自主干特征的噪声。</p><h2 id="3-3-emsp-遮罩分支提供的注意力随着主干分支特征而自适应地改变"><a href="#3-3-emsp-遮罩分支提供的注意力随着主干分支特征而自适应地改变" class="headerlink" title="3.3&emsp;遮罩分支提供的注意力随着主干分支特征而自适应地改变"></a>3.3&emsp;遮罩分支提供的注意力随着主干分支特征而自适应地改变</h2><p><img src="/2021/08/04/Residual%20Attention%20Network/1628133676240.png" alt="1628133676240"></p><p>xi表示第I个空间位置的特征向量。I在所有空间位置范围内，c在所有通道范围内</p><p>无附加限制的混合注意f1对每个通道和空间位置使用简单的sigmoid。</p><p>通道注意力f2在所有通道内对每个空间位置执行L2归一化，以去除空间信息。</p><p>空间注意力f3在来自每个通道的特征图内执行标准化，然后sigmoid以获得仅与空间信息相关的软掩模。</p><h1 id="4、-emsp-总结"><a href="#4、-emsp-总结" class="headerlink" title="4、&emsp;总结"></a>4、&emsp;总结</h1><p>普通注意力模型的缺点：</p><p>1、<strong>具有杂乱背景、复杂场景和大的外观变化的图像需要通过不同类型的关注来建模</strong>。在这种情况下，来自不同层的特征需要由不同的注意力遮罩来建模。使用单个掩码分支将需要指数数量的通道来捕获不同因素的所有组合。</p><p>2、<strong>单个注意模块只修改一次特征。如果映像的某些部分修改失败，以下网络模块将没有第二次机会。</strong></p><p><strong>本文提出的残余注意力网络缓解了上述问题</strong>。在注意力模块中，每个主干分支都有自己的掩码分支来学习专门针对其特征的注意力。</p><p><strong>1.堆叠网络结构:我们的剩余注意力网络是通过堆叠多个注意力模块来构建的。不同类型的注意力能够在不同的注意力模块中被捕获。改变 f（x）即可</strong></p><p><strong>2.整个soft mask branch 才是重点，输出的M当做残差加一以后再去卷积主干的特征</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1、论文全名-—-Residual-Attention-Network-for-Image-Classification&quot;&gt;&lt;a href=&quot;#1、论文全名-—-Residual-Attention-Network-for-Image-Classification</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="注意力模型（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="注意力模型" scheme="http://example.com/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>MUNIT</title>
    <link href="http://example.com/2021/08/03/MUNIT/"/>
    <id>http://example.com/2021/08/03/MUNIT/</id>
    <published>2021-08-03T08:45:44.000Z</published>
    <updated>2021-08-05T04:27:00.452Z</updated>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer">  <h1 id="1、论文全名-—-Multimodal-Unsupervised-Image-to-Image-Translation"><a href="#1、论文全名-—-Multimodal-Unsupervised-Image-to-Image-Translation" class="headerlink" title="1、论文全名 — Multimodal Unsupervised Image-to-Image Translation"></a>1、论文全名 — Multimodal Unsupervised Image-to-Image Translation</h1><h1 id="emsp-emsp-多模态无监督图像到图像翻译"><a href="#emsp-emsp-多模态无监督图像到图像翻译" class="headerlink" title="&emsp;&emsp;(多模态无监督图像到图像翻译)"></a>&emsp;&emsp;(多模态无监督图像到图像翻译)</h1><h1 id="2、整体结构"><a href="#2、整体结构" class="headerlink" title="2、整体结构"></a>2、整体结构</h1><p><img src="/2021/08/03/MUNIT/1627986033107.png" alt="1627986033107"></p><p><img src="/2021/08/03/MUNIT/1627980504738.png" alt="1627980504738"></p><h1 id="3、过程"><a href="#3、过程" class="headerlink" title="3、过程"></a>3、过程</h1><p>&emsp;&emsp;如图1 (a)所示，我们的框架做了几个假设。我们首先假设图像的潜在空间可以分解为内容空间C和风格空间S。我们进一步假设不同领域的图像共享一个共同的内容空间，但不共享样式空间。为了将图像翻译到目标域，我们将其内容代码与目标样式空间中的随机样式代码重新组合(图1(b))。</p><p>&emsp;&emsp;内容代码对翻译过程中应该保留的信息进行编码，而样式代码表示输入图像中不包含的其余变体。通过采样不同的风格代码，我们的模型能够产生不同的多模态输出。</p><p><img src="/2021/08/03/MUNIT/1627981675082.png" alt="1627981675082"></p><p>&emsp;&emsp;如图2(a)所示，每个自动编码器的潜在代码被分解成内容代码ci和样式代码si。如图2(b)所示，通过交换编码器-解码器对来执行图像到图像的转换。</p><p>&emsp;&emsp;为了将图像x1∈x1翻译成X2，我们首先提取其内容潜在代码<img src="/2021/08/03/MUNIT/1627982033272.png" alt="1627982033272" style="zoom:60%;">，并从先验分布<img src="/2021/08/03/MUNIT/1627982067523.png" alt="1627982067523" style="zoom:50%;">中随机绘制一个风格潜在代码s2。然后，我们使用G2产生最终输出图像<img src="/2021/08/03/MUNIT/1627982112763.png" alt="1627982112763" style="zoom:60%;">。</p><h2 id="4、损失函数设计"><a href="#4、损失函数设计" class="headerlink" title="4、损失函数设计"></a>4、损失函数设计</h2><h2 id="4-1-emsp-双向重建损失"><a href="#4-1-emsp-双向重建损失" class="headerlink" title="4.1&emsp;双向重建损失"></a>4.1&emsp;双向重建损失</h2><p><strong>图像重建损失:</strong> </p><p><img src="/2021/08/03/MUNIT/1627986277230.png" alt="1627986277230"></p><p><strong>潜在的重建损失：</strong>（内容重建损失和风格重建损失）</p><p><img src="/2021/08/03/MUNIT/1627986328694.png" alt="1627986328694"></p><p>在给定不同风格代码的情况下，风格重建损失具有鼓励不同输出的效果，内容重构损失重新鼓励翻译图像以保留输入图像的语义内容。</p><h2 id="4-2-emsp-对抗损失"><a href="#4-2-emsp-对抗损失" class="headerlink" title="4.2&emsp;对抗损失"></a>4.2&emsp;对抗损失</h2><p>先验分布<img src="/2021/08/03/MUNIT/1627987418253.png" alt="1627987418253" style="zoom:50%;">，边缘分布p(x）</p><p><img src="/2021/08/03/MUNIT/1627986915469.png" alt="1627986915469"></p><h2 id="4-3-emsp-总损失"><a href="#4-3-emsp-总损失" class="headerlink" title="4.3&emsp;总损失"></a>4.3&emsp;总损失</h2><img src="/2021/08/03/MUNIT/1627987289574.png" alt="1627987289574" style="zoom:75%;"><img src="/2021/08/03/MUNIT/1627987296909.png" alt="1627987296909" style="zoom:75%;"><h1 id="5、总结"><a href="#5、总结" class="headerlink" title="5、总结"></a>5、总结</h1><p>&emsp;&emsp;<strong>网络设计有点复杂，思路很容易理解。将图片分成风格编码器和内容编码器，然后拆开编码，最后再进行组合，同一个内容可以混合不同的风格。设计损失函数的时候也有重建风格损失，重建内容损失。</strong></p><hr>]]></content>
    
    
      
      
    <summary type="html"> &lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;  


&lt;h1 id=&quot;1、论文全名-—-Multimodal-Unsupervised-Image-to-Image-Translation&quot;&gt;&lt;a href=&quot;#1、论文全名-—-Mu</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN，论文阅读" scheme="http://example.com/tags/GAN%EF%BC%8C%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>U-GAT-IT</title>
    <link href="http://example.com/2021/08/03/U-GAT-IT/"/>
    <id>http://example.com/2021/08/03/U-GAT-IT/</id>
    <published>2021-08-03T03:44:36.000Z</published>
    <updated>2021-08-04T04:19:42.969Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1、论文全名-—-U-GAT-IT-UNSUPERVISED-GENERATIVE-ATTENTIONAL-NETWORKS-WITH-ADAPTIVE-LAYERINSTANCE-NORMALIZATION-FOR-IMAGE-TO-IMAGE"><a href="#1、论文全名-—-U-GAT-IT-UNSUPERVISED-GENERATIVE-ATTENTIONAL-NETWORKS-WITH-ADAPTIVE-LAYERINSTANCE-NORMALIZATION-FOR-IMAGE-TO-IMAGE" class="headerlink" title="1、论文全名 — U-GAT-IT: UNSUPERVISED GENERATIVE ATTENTIONAL NETWORKS  WITH ADAPTIVE LAYERINSTANCE NORMALIZATION FOR IMAGE-TO-IMAGE"></a>1、论文全名 — U-GAT-IT: UNSUPERVISED GENERATIVE ATTENTIONAL NETWORKS  WITH ADAPTIVE LAYERINSTANCE NORMALIZATION FOR IMAGE-TO-IMAGE</h1><p>TRANSLATION（用于图像到图像翻译的具有自适应层度归一化的无监督生成注意网络）</p><h1 id="2、-emsp-整体结构"><a href="#2、-emsp-整体结构" class="headerlink" title="2、&emsp;整体结构"></a>2、&emsp;整体结构</h1><p><img src="/2021/08/03/U-GAT-IT/1627963121891.png" alt="1627963121891"></p><p>​                                <center><strong>U - GAT - IT结构图</strong></center></p><h1 id="2、-emsp-U-GAT-IT过程"><a href="#2、-emsp-U-GAT-IT过程" class="headerlink" title="2、&emsp;U - GAT - IT过程"></a>2、&emsp;U - GAT - IT过程</h1><p>&emsp;&emsp;目标是训练一个函数G_(s→t)，该函数仅使用从每个域提取的不成对样本将图像从源域Xs映射到目标域Xt。我们的框架由两个生成器G_(s→t)和G_(t→s)和两个鉴别器Ds 和 Dt 组成。我们将注意力模块集成到生成器和鉴别器中。<strong>鉴别器中的注意力模块引导生成器聚焦于对生成逼真图像至关重要的区域。生成器中的注意模块关注与其他域不同的区域。</strong></p><h2 id="2-1-生成器G-s→t"><a href="#2-1-生成器G-s→t" class="headerlink" title="2.1  生成器G_(s→t)"></a>2.1  生成器G_(s→t)</h2><p>组成成分：编码器Es，解码器Gt，辅助分类器 ηs，其中ηs(x)表示x来自Xs的概率，</p><p>通过使用全局平均池和全局最大池，<strong>辅助分类器被训练来学习源域的第k特征图的权重w^k_(s),</strong></p><p><img src="/2021/08/03/U-GAT-IT/1627965570665.png" alt="1627965570665"></p><p>利用w^k_(s)，们可以计算一组域特定注意特征图a_s(x)为：&emsp;&emsp;其中n为特征图的数量</p><img src="/2021/08/03/U-GAT-IT/1627965767793.png" alt="1627965767793" style="zoom:70%;"><p>然后，我们的翻译模型Gs→t变得等于G_t(a_s(x))。</p><p>**自适应层重要性归一化(AdaLIN)**，其参数在训练期间通过自适应地选择实例归一化(IN)和层归一化(LN)之间的适当比率从数据集学习。</p><p><img src="/2021/08/03/U-GAT-IT/1627965972979.png" alt="1627965972979"></p><p> µ_I,  µ_L, σ_I, σ_L分别是通道级均值、层级均值和标准差，γ和β是全连通层生成的参数，τ是学习率，△ρ表示优化器确定的参数更新向量(如梯度)。</p><p>LN 并不假设通道之间不相关，有时它不能很好地保持原始领域的内容结构，因为它只考虑了特征地图的全局统计。归一化技术AdaLIN通过选择性地保留或改变内容信息，结合了AdaIN和LN的优点，这有助于解决广泛的图像到图像翻译问题</p><h2 id="2-2-emsp-判别器Dt"><a href="#2-2-emsp-判别器Dt" class="headerlink" title="2.2 &emsp;判别器Dt"></a>2.2 &emsp;判别器Dt</h2><p>组成成分：是由编码器E_Dt、分类器C__Dt和辅助分类器  η_(Dt) 组成的多尺度模型。</p><p>x∞{  Xt，Gs→t(Xs) } 表示来自目标域和翻译后的源域的样本。与其他翻译模型不同，η_Dt(x)和D_t(x)都被训练来区分x是否来自 Xt 还是 Gs→t(Xs)。</p><p>给定一个样本x，Dt(x)使用编码特征图E_Dt(x)上面的权重w_Dt去寻找注意力特征图<img src="/2021/08/03/U-GAT-IT/1627973410325.png" alt="1627973410325" style="zoom:50%;">，这个编码特征图E_dT(x)由辅助分类器 ηDt(x)训练得来。然后，我们的鉴别器Dt(x)变得等于<img src="/2021/08/03/U-GAT-IT/1627973368892.png" alt="1627973368892" style="zoom:55%;"></p><h1 id="3、损失函数的设计"><a href="#3、损失函数的设计" class="headerlink" title="3、损失函数的设计"></a>3、损失函数的设计</h1><p>我们模型的全部目标包括四个损失函数。</p><p>这里，我们使用最小二乘GAN  (LSGAN)目标进行稳定训练，而不是使用普通的GAN目标。</p><h3 id="3-1-emsp-知识介绍-–-LSGAN"><a href="#3-1-emsp-知识介绍-–-LSGAN" class="headerlink" title="3.1 &emsp;知识介绍 – LSGAN"></a>3.1 &emsp;知识介绍 – LSGAN</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Least Squares GAN   这篇文章针对的是原始GAN生成的图片质量不高以及训练过程不稳定这两个缺陷进行改进。</span><br><span class="line"></span><br><span class="line">改进方法就是将GAN的目标函数由交叉熵损失换成最小二乘损失，而且这一个改变同时解决了两个缺陷。</span><br><span class="line">为以交叉熵作为损失，会使得生成器不会再优化那些被判别器识别为真实图片的生成图片，即使这些生成图片距离判别器的决策边界仍然很远，也就是距真实数据比较远。因为它已经成功欺骗了判别器，这导致了生成器的生成图片质量并不高。</span><br><span class="line"></span><br><span class="line">最小二乘损失函数会对处于判别成真的那些远离决策边界的样本进行惩罚，把远离决策边界的假样本拖进决策边界，从而提高生成图片的质量。</span><br></pre></td></tr></table></figure><p><img src="/2021/08/03/U-GAT-IT/1627975227737.png" alt="1627975227737"></p><p><img src="/2021/08/03/U-GAT-IT/1627975341016.png" alt="1627975341016"></p><h3 id="3-2-emsp-对抗损失"><a href="#3-2-emsp-对抗损失" class="headerlink" title="3.2&emsp;对抗损失"></a>3.2&emsp;对抗损失</h3><p><img src="/2021/08/03/U-GAT-IT/1627975505284.png" alt="1627975505284"></p><h3 id="3-3-emsp-循环损失"><a href="#3-3-emsp-循环损失" class="headerlink" title="3.3&emsp;循环损失"></a>3.3&emsp;循环损失</h3><h3 id="emsp-emsp-emsp-可以缓解模式崩溃问题"><a href="#emsp-emsp-emsp-可以缓解模式崩溃问题" class="headerlink" title="&emsp;&emsp;&emsp;可以缓解模式崩溃问题"></a>&emsp;&emsp;&emsp;可以缓解模式崩溃问题</h3><p><img src="/2021/08/03/U-GAT-IT/1627975587820.png" alt="1627975587820"></p><h3 id="3-4-emsp-身份损失"><a href="#3-4-emsp-身份损失" class="headerlink" title="3.4&emsp;身份损失"></a>3.4&emsp;身份损失</h3><h3 id="emsp-emsp-emsp-为了确保输入图像和输出图像的颜色分布相似"><a href="#emsp-emsp-emsp-为了确保输入图像和输出图像的颜色分布相似" class="headerlink" title="&emsp;&emsp;&emsp;为了确保输入图像和输出图像的颜色分布相似"></a>&emsp;&emsp;&emsp;为了确保输入图像和输出图像的颜色分布相似</h3><p><img src="/2021/08/03/U-GAT-IT/1627975653043.png" alt="1627975653043"></p><h3 id="3-5-emsp-CAM损失"><a href="#3-5-emsp-CAM损失" class="headerlink" title="3.5&emsp;CAM损失"></a>3.5&emsp;CAM损失</h3><h3 id="emsp-emsp-emsp-通过利用来自辅助分类器ηs和η-Dt的信息-是的G-s→t-和Dt了解他们需要改进的地方，或者在当前状态下两个领域的最大区别"><a href="#emsp-emsp-emsp-通过利用来自辅助分类器ηs和η-Dt的信息-是的G-s→t-和Dt了解他们需要改进的地方，或者在当前状态下两个领域的最大区别" class="headerlink" title="&emsp;&emsp;&emsp;通过利用来自辅助分类器ηs和η_Dt的信息,是的G_(s→t)和Dt了解他们需要改进的地方，或者在当前状态下两个领域的最大区别:"></a>&emsp;&emsp;&emsp;通过利用来自辅助分类器ηs和η_Dt的信息,是的G_(s→t)和Dt了解他们需要改进的地方，或者在当前状态下两个领域的最大区别:</h3><p><img src="/2021/08/03/U-GAT-IT/1627975912525.png" alt="1627975912525"></p><h3 id="3-6-emsp-总损失"><a href="#3-6-emsp-总损失" class="headerlink" title="3.6 &emsp;总损失"></a>3.6 &emsp;总损失</h3><p><img src="/2021/08/03/U-GAT-IT/1627976087788.png" alt="1627976087788"></p><hr><h1 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h1><h2 id="emsp-emsp-个人理解创新的地方在于"><a href="#emsp-emsp-个人理解创新的地方在于" class="headerlink" title="&emsp;&emsp;个人理解创新的地方在于"></a>&emsp;&emsp;<strong>个人理解创新的地方在于</strong></h2><ol><li><p><strong>CAM损失，能够帮助两个不同域直接和合成。</strong></p></li><li><p><strong>有两种不同的特征图——编码器特征图和注意力特征图。</strong></p><p><strong>Dt(x)使用编码特征图E_Dt(x)上面的权重w_Dt去寻找注意力特征图<img src="/2021/08/03/U-GAT-IT/1627973410325.png" alt="1627973410325" style="zoom:50%;">，这个编码特征图E_dT(x)由辅助分类器 ηDt(x)训练得来</strong></p></li><li><p><strong>鉴别器中的注意力模块引导生成器聚焦于对生成逼真图像至关重要的区域。生成器中的注意模块关注与其他域不同的区域。</strong></p></li><li><p><strong>损失函数使用的是LSGAN)目标进行稳定训练，而不是传统GAN</strong></p></li></ol><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1、论文全名-—-U-GAT-IT-UNSUPERVISED-GENERATIVE-ATTENTIONAL-NETWORKS-WITH-ADAPTIVE-LAYERINSTANCE-NORMALIZATION-FOR-IMAGE-TO-IMAGE&quot;&gt;&lt;a href</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="注意力模型" scheme="http://example.com/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>Stack++</title>
    <link href="http://example.com/2021/08/01/StackGAN-v2/"/>
    <id>http://example.com/2021/08/01/StackGAN-v2/</id>
    <published>2021-08-01T13:18:44.000Z</published>
    <updated>2021-08-03T11:32:41.478Z</updated>
    
    <content type="html"><![CDATA[  <meta name="referrer" content="no-referrer">  <h1 id="1、论文全名-—-stackGAN-Realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks"><a href="#1、论文全名-—-stackGAN-Realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks" class="headerlink" title="1、论文全名 — stackGAN++: Realistic Image Synthesis with    Stacked Generative Adversarial Networks"></a>1、论文全名 — stackGAN++: Realistic Image Synthesis with    Stacked Generative Adversarial Networks</h1><h1 id="2、整体结构"><a href="#2、整体结构" class="headerlink" title="2、整体结构"></a>2、整体结构</h1><p><img src="/2021/08/01/StackGAN-v2/1627825385517.png"></p><p>​                                      <center>StackGAN-v2流程图</center></p><h1 id="3、过程以及损失函数的设计"><a href="#3、过程以及损失函数的设计" class="headerlink" title="3、过程以及损失函数的设计"></a>3、过程以及损失函数的设计</h1><p> &emsp; &emsp;StackGAN-v2由多个生成器(G)和鉴别器(D)组成，它们在树状结构中共享大多数参数。网络的输入可以被视为树的根，并且多尺度图像从树的不同分支生成。从低分辨率到高分辨率的图像是从树的不同分支生成的。</p><p>&emsp;&emsp;在每个分支，生成器捕获该比例下的图像分布，鉴别器估计样本来自该比例的训练图像而不是生成器的概率。生成器被联合训练以逼近多个分布，并且生成器和鉴别器以交替的方式被训练。在本节中，我们探讨了两种类型的多重分布:(1)多尺度图像分布以及(2)联合条件和无条件图像分布。</p><h3 id="3-1-多尺度图像分布近似-Multi-scale-image-distributions-approximation"><a href="#3-1-多尺度图像分布近似-Multi-scale-image-distributions-approximation" class="headerlink" title="3.1 多尺度图像分布近似(Multi-scale image distributions approximation)"></a>3.1 多尺度图像分布近似(Multi-scale image distributions approximation)</h3><p>&emsp;&emsp; StackGAN-v2以一个噪声向量z作为输入，并有多个生成器来生成不同比例的图像。噪声是一种先验分布，通常为标准正态分布。潜在变量z被逐层转换为隐藏特征。我们通过非线性变换计算每个发生器G的隐藏特征hi。</p><p>&emsp;&emsp;hi表示第i个分支的隐藏特征，m为总分支数，为了捕捉在前面的分支中省略的信息，噪声矢量z连接到隐藏特征h_(i -1)，作为 Fi 的输入去计算hi。</p><p><img src="/2021/08/01/StackGAN-v2/1627828037446-1627873594719.png"></p><p><img src="/2021/08/01/StackGAN-v2/1627828068601.png"></p><p>&emsp;&emsp;在每个生成器Gi之后跟着一个鉴别器Di，通过最小化以下交叉熵损失来训练鉴别器Di，该鉴别器Di以真实样本xi和伪样本si作为输入，以将输入分类为两类(真或假)。</p><p><img src="/2021/08/01/StackGAN-v2/1627828305495.png"></p><p>&emsp;&emsp;多个鉴别器被并行训练，并且每个鉴别器聚焦在单个图像尺度上。</p><p>&emsp;&emsp;在训练好的鉴别器的指导下，生成器通过最小化下面的损失函数被优化以联合逼近多尺度图像分布</p><p><img src="/2021/08/01/StackGAN-v2/1627828424158.png"></p><p>&emsp;其中l_g是用于近似第i个尺度上的图像分布的损失函数。在训练过程中，鉴别器和生成器交替优化，直到收敛。</p><p>&emsp;&emsp;<strong>提出的StackGAN-v2的动机是，通过在多个尺度上建模数据分布，如果这些模型分布中的任何一个与该尺度上的真实数据分布共享支持，则重叠可以提供良好的梯度信号，以在多个尺度上加速或稳定整个网络的训练。</strong></p><h3 id="3-2-联合条件和无条件图像分布近似（-JCD-）"><a href="#3-2-联合条件和无条件图像分布近似（-JCD-）" class="headerlink" title="3.2 联合条件和无条件图像分布近似（ JCD ）"></a>3.2 联合条件和无条件图像分布近似（ JCD ）</h3><p>&emsp;&emsp;<strong>无条件损失决定图像的真假，有条件损失决定图像和条件是否匹配。</strong>    </p><p>&emsp;&emsp;对于我们的条件StackGAN-v2的G，F0和Fi 被转换为将条件向量c作为输入。对于Fi，调节向量c代替噪声向量z，以鼓励生成器根据调节变量绘制具有更多细节的图像。因此，多尺度样本现在由si=  Gi(hi)生成。</p><p><img src="/2021/08/01/StackGAN-v2/1627870863531.png" alt="1627870863531"></p><p><img src="/2021/08/01/StackGAN-v2/1627870873418.png" alt="1627870873418"></p><p>&emsp;&emsp;<strong>训练条件D的目标函数现在由两个项组成，无条件损失和条件损失。</strong></p><p><img src="/2021/08/01/StackGAN-v2/1627870996625.png" alt="1627870996625"></p><p>&emsp;&emsp;<strong>这部分的损失函数为</strong></p><p><img src="/2021/08/01/StackGAN-v2/1627871482209.png" alt="1627871482209"></p><h3 id="3-3-颜色一致性正则化（-Color-consistency-regularization）"><a href="#3-3-颜色一致性正则化（-Color-consistency-regularization）" class="headerlink" title="3.3 颜色一致性正则化（ Color-consistency regularization）"></a>3.3 颜色一致性正则化（ Color-consistency regularization）</h3><p>&emsp;&emsp;当我们在不同的生成器上增加图像分辨率时，在不同比例下生成的图像应该共享相似的基本结构和颜色。引入颜色一致性正则化项，以保持从不同G的相同输入生成的样本在颜色上更加一致，从而提高生成图像的质量。</p><p><img src="/2021/08/01/StackGAN-v2/1627872407715.png" alt="1627872407715"></p><p><img src="/2021/08/01/StackGAN-v2/1627872459349.png" alt="1627872459349"></p><p><img src="/2021/08/01/StackGAN-v2/1627873918668.png" alt="1627873918668"></p><p>X_k表示生成的图像中的一个像素，下面的代表给定图像的像素的平均值和协方差，N为像素个数。</p><p><strong>颜色一致性正则化的目的是最小化不同尺度之间的像素平均值和协方差的差异，以促进一致性。</strong></p><p><img src="/2021/08/01/StackGAN-v2/1627872829324.png" alt="1627872829324"></p><hr><h1 id="4、总结："><a href="#4、总结：" class="headerlink" title="4、总结："></a>4、总结：</h1><h3 id="emsp-emsp-这个文章是在StackGAN上面的延续，针对条件生成任务和无条件生成任务，提出了一种先进的多阶段生成对抗网络体系结构StackGAN-v2。"><a href="#emsp-emsp-这个文章是在StackGAN上面的延续，针对条件生成任务和无条件生成任务，提出了一种先进的多阶段生成对抗网络体系结构StackGAN-v2。" class="headerlink" title="&emsp;&emsp;这个文章是在StackGAN上面的延续，针对条件生成任务和无条件生成任务，提出了一种先进的多阶段生成对抗网络体系结构StackGAN-v2。"></a>&emsp;&emsp;这个文章是在StackGAN上面的延续，针对条件生成任务和无条件生成任务，提出了一种先进的多阶段生成对抗网络体系结构StackGAN-v2。</h3><h2 id="emsp-emsp-stackGAN有三个主要贡献："><a href="#emsp-emsp-stackGAN有三个主要贡献：" class="headerlink" title="&emsp;&emsp;stackGAN有三个主要贡献："></a>&emsp;&emsp;stackGAN有三个主要贡献：</h2><ol><li><strong>StackGAN-v1首次从文本描述中分阶段生成具有照片级逼真细节的256×256分辨率的图像。</strong></li><li><strong>StackGAN-v2通过联合逼近多个分布，进一步提高了生成图像的质量，稳定了GANs的训练。</strong></li><li><strong>提出了一个颜色一致性正则化项来指导我们的生成器在不同的尺度上生成更多的相干样本。</strong></li></ol><hr>]]></content>
    
    
      
      
    <summary type="html">  &lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;  




&lt;h1 id=&quot;1、论文全名-—-stackGAN-Realistic-Image-Synthesis-with-Stacked-Generative-Adversarial</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN，论文阅读" scheme="http://example.com/tags/GAN%EF%BC%8C%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>StackGAN</title>
    <link href="http://example.com/2021/08/01/StackGAN/"/>
    <id>http://example.com/2021/08/01/StackGAN/</id>
    <published>2021-08-01T11:20:10.000Z</published>
    <updated>2021-08-03T08:03:55.168Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1、论文全名-—-StackGAN-Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks"><a href="#1、论文全名-—-StackGAN-Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks" class="headerlink" title="1、论文全名 — StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks"></a>1、论文全名 — StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks</h1><h1 id="2、整体结构"><a href="#2、整体结构" class="headerlink" title="2、整体结构"></a>2、整体结构</h1><p><img src="/2021/08/01/StackGAN/1627817144163-1627822726262.png"></p><p>​                                                                 <center> <strong>StackGAN 的流程图</strong></center> </p><h1 id="3、-StackGAN过程"><a href="#3、-StackGAN过程" class="headerlink" title="3、 StackGAN过程"></a>3、 StackGAN过程</h1><p>&emsp;&emsp;第一阶段生成器通过从给定文本中绘制对象的粗略形状和基本颜色，并从随机噪声向量中绘制背景，来绘制低分辨率图像。</p><p>&emsp;&emsp; 第二阶段生成器纠正缺陷，并在第一阶段的结果中添加引人注目的细节，产生更真实的高分辨率图像。</p><h2 id="3-1-第一阶段（并非自己关注的重点）"><a href="#3-1-第一阶段（并非自己关注的重点）" class="headerlink" title="3.1  第一阶段（并非自己关注的重点）"></a>3.1  第一阶段（并非自己关注的重点）</h2><p>&emsp;&emsp;ϕt 表示给定描述的文本嵌入，它是由本文中预先训练的编码器生成的。条件^C0，随机变量Z。</p><p>&emsp;&emsp;<em>第一阶段随机交替的最大化等式 L(Do)和最小化 L(Go)来训练生成器Go和判别器Do</em></p><img src="/2021/08/01/StackGAN/1627817709932-1627822752622.png" style="zoom:67%;"><img src="/2021/08/01/StackGAN/1627817814686-1627822752622.png" alt="1627817814686" style="zoom:67%;"><h2 id="3-2-第二阶段（重点关注第一阶段过渡到第二阶段的代码）"><a href="#3-2-第二阶段（重点关注第一阶段过渡到第二阶段的代码）" class="headerlink" title="3.2 第二阶段（重点关注第一阶段过渡到第二阶段的代码）"></a>3.2 第二阶段（重点关注第一阶段过渡到第二阶段的代码）</h2><p>&emsp;&emsp; 第一阶段GAN生成的低分辨率图像通常缺少生动的物体部分，并且可能包含形状失真。文本中的一些细节也可能在第一阶段被省略，这对于生成照片真实感图像至关重要。第二阶段GAN是建立在第一阶段结果的基础上，以生成高分辨率图像。它以低分辨率图像和再次嵌入文本为条件，以纠正第一阶段结果中的缺陷。</p><p>&emsp;&emsp;第二阶段不再使用随机噪声，使用的so表示第一阶段生成结果。</p><p>&emsp;&emsp;<em>第二阶段随机交替的最大化等式 L(D)和最小化 L(G)来训练生成器G和判别器D</em></p><img src="../images/StackGAN/1627818853115.png" alt="1627818853115" style="zoom:67%;"><img src="/2021/08/01/StackGAN/1627818853115-1627822752622.png" alt="1627818853115" style="zoom:67%;"><h1 id="3、总结"><a href="#3、总结" class="headerlink" title="3、总结"></a>3、总结</h1><h4 id="emsp-emsp-这篇文章是利用文本生成来生成图像，所以很多的细节不需要掌握、重点学习的是怎么把前面一个阶段的图放入下一个阶段。看论文只是次要、还是得复现代码。"><a href="#emsp-emsp-这篇文章是利用文本生成来生成图像，所以很多的细节不需要掌握、重点学习的是怎么把前面一个阶段的图放入下一个阶段。看论文只是次要、还是得复现代码。" class="headerlink" title="&emsp;&emsp;这篇文章是利用文本生成来生成图像，所以很多的细节不需要掌握、重点学习的是怎么把前面一个阶段的图放入下一个阶段。看论文只是次要、还是得复现代码。"></a>&emsp;&emsp;这篇文章是利用文本生成来生成图像，所以很多的细节不需要掌握、重点学习的是怎么把前面一个阶段的图放入下一个阶段。看论文只是次要、还是得复现代码。</h4><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1、论文全名-—-StackGAN-Text-to-Photo-realistic-Image-Synthesis-with-Stacked-Generative-Adversarial-Networks&quot;&gt;&lt;a href=&quot;#1、论文全名-—-StackGAN-</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN，论文阅读" scheme="http://example.com/tags/GAN%EF%BC%8C%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>Unsupervised Attention-guided GAN</title>
    <link href="http://example.com/2021/08/01/Unsupervised-Attention-guided/"/>
    <id>http://example.com/2021/08/01/Unsupervised-Attention-guided/</id>
    <published>2021-08-01T11:20:10.000Z</published>
    <updated>2021-08-03T11:32:34.271Z</updated>
    
    <content type="html"><![CDATA[  <meta name="referrer" content="no-referrer">  <h1 id="1、论文全名-—-Unsupervised-Attention-guided-Image-to-Image-Translation"><a href="#1、论文全名-—-Unsupervised-Attention-guided-Image-to-Image-Translation" class="headerlink" title="1、论文全名 — Unsupervised Attention-guided Image-to-Image Translation"></a>1、论文全名 — Unsupervised Attention-guided Image-to-Image Translation</h1><h1 id="2、-emsp-整体结构"><a href="#2、-emsp-整体结构" class="headerlink" title="2、&emsp;整体结构"></a>2、&emsp;整体结构</h1><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627892637831.png" alt="1627892637831"></p><p>​                                                          <center>UAG-GAN流程图</center></p><h1 id="3、-emsp-UAG-GAN过程"><a href="#3、-emsp-UAG-GAN过程" class="headerlink" title="3、&emsp;UAG-GAN过程"></a>3、&emsp;UAG-GAN过程</h1><p>&emsp;&emsp;&emsp;文章出发点是在cycleGAN 的基础上改进的，图像风格变换实质上是两个不同域之间的相互转换。</p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627893141106.png" alt="1627893141106"></p><p>&emsp;&emsp;为了进一步处理，需要解决两个主要任务：</p><ol><li>在每个图像中定位要平移的区域，</li><li>对定位的区域应用正确的平移。</li></ol><h2 id="3-1-emsp-生成器G解读"><a href="#3-1-emsp-生成器G解读" class="headerlink" title="3.1 &emsp;生成器G解读"></a>3.1 &emsp;生成器G解读</h2><p>&emsp;&emsp;A_S与A_T表示两个不同的注意力网络，Sa 和 Ta分别是由 S 和 T 导出的注意图。每个注意力图包含每像素[0，1]的估计值。<strong>如果注意力图所有值为0，则输出背景项；如果全为1，则输出原图。</strong>将输入图像输入到生成器后，我们使用逐元素乘积将学习到的掩码应用到生成的图像，然后使用应用于输入图像的反遮罩添加背景。因此，A_S 和 A_T 与G一起训练，如图所示。</p><p>&emsp;&emsp;首先，我们将输入图像 s∈S 馈送到生成器F_(S→T), 生成器 F_(S→T)将s映射到目标域T，然后，将相同的输入馈送到注意力网络A_S，得到注意力图 Sa 。为了创建“前景”对象sf，我们把每个RGB通道上的注意力模型 Sa 和生成器F_(S→T)进行逐元素乘积。然后，对注意力图Sa取反，再和原图S进行逐元素成绩，得到“背景”图像Sb。最后，将前景和后景图相加即可得到最终图像。</p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627894572673.png" alt="1627894572673"></p><h2 id="3-2-emsp-损失函数"><a href="#3-2-emsp-损失函数" class="headerlink" title="3.2 &emsp;损失函数"></a>3.2 &emsp;损失函数</h2><p>&emsp;<strong>对抗损失：</strong></p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627895057172.png" alt="1627895057172"></p><p>&emsp;</p><p>&emsp;<strong>循环一致性损失：</strong>   &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;其中 S‘’ 是生成的T域图片再转回S域的图像。</p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627895140042.png" alt="1627895140042"></p><p>&emsp;<strong>最终损失：</strong></p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627901641560.png" alt="1627901641560"></p><p>&emsp;<strong>在整个实验中，我们通过求解极小极大优化问题得到L的最优参数:</strong></p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627901652097.png" alt="1627901652097"></p><h2 id="3-3-emsp-判别器D解读"><a href="#3-3-emsp-判别器D解读" class="headerlink" title="3.3 &emsp;判别器D解读"></a>3.3 &emsp;判别器D解读</h2><p>&emsp;&emsp;生成器仅作用于关注区域: 随着注意力网络训练在寻找前景方面会变得更加准确。但是也有两个引起误差的行为：（1）注意力图慢慢的包括越来越多的背景，向完全关注的图收敛 (<strong>图中的所有值都收敛到1</strong>)。（2）生成器F_(S→T)将背景直接“绘制”到关注区域中.</p><p>&emsp;单纯用原图像S和通过<strong>已经训练好了的A_S生成的</strong>注意力图像Sa进行逐元素乘积是有问题的，因为反馈给鉴别器的真实样本现在依赖于最初未训练的注意力图sa。如果GAN中的所有网络都被联合训练，这将导致模式崩溃。为了克服这个问题，我们首先在30个时期的完整图像上训练辨别器，然后在注意力网络A_S和A_T发展起来后，切换到掩蔽图像。</p><p>图像转换的流程如图：</p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627896930053.png" alt="1627896930053"></p><p>我们设置注意力取值不能为0，因为全0就变成了输出背景，故鉴别器设定学习注意图的阈值如下:</p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627901667458.png" alt="1627901667458"></p><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627901532979.png" alt="1627901532979"></p><h2 id="3-3-总结学习FS→T的训练程序"><a href="#3-3-总结学习FS→T的训练程序" class="headerlink" title="3.3 总结学习FS→T的训练程序"></a>3.3 总结学习FS→T的训练程序</h2><p><img src="/2021/08/01/Unsupervised-Attention-guided/1627901540811.png" alt="1627901540811"></p><h1 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h1><p><strong>&emsp;&emsp;这篇文章引入了注意力、把一张图片的合成分成了前景图片和后景图片的合成、分别处理后再相加。这样可以使得更加专注于前景图，对需要转化部分图像的处理达到更好的效果。</strong></p><p><strong>&emsp;&emsp;有一个想法：直接用前景减去后景是不是能够让素描的合成更加准确。</strong></p><hr>]]></content>
    
    
      
      
    <summary type="html">  &lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;&gt;  


&lt;h1 id=&quot;1、论文全名-—-Unsupervised-Attention-guided-Image-to-Image-Translation&quot;&gt;&lt;a href=&quot;#1、论文</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7/"/>
    
    
    <category term="GAN，论文阅读" scheme="http://example.com/tags/GAN%EF%BC%8C%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>SGAN1</title>
    <link href="http://example.com/2021/08/01/SGAN1/"/>
    <id>http://example.com/2021/08/01/SGAN1/</id>
    <published>2021-08-01T08:25:02.000Z</published>
    <updated>2021-08-03T11:05:07.066Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1、论文全名-—-Stacked-Generative-Adversarial-Networks"><a href="#1、论文全名-—-Stacked-Generative-Adversarial-Networks" class="headerlink" title="1、论文全名 — Stacked Generative Adversarial Networks"></a>1、论文全名 — Stacked Generative Adversarial Networks</h1><h1 id="2、整体结构"><a href="#2、整体结构" class="headerlink" title="2、整体结构"></a>2、整体结构</h1><p><img src="/2021/08/01/SGAN1/1627801448989-1627822969518.png"></p><p>​                                                                         <center> <strong>SGAN 的流程图</strong></center> </p><h1 id="3、SGAN过程"><a href="#3、SGAN过程" class="headerlink" title="3、SGAN过程"></a>3、SGAN过程</h1><ol><li><p>我们首先考虑一个为分类而预先训练的自下而上的DNN，它在全文中被称为编码器E。</p><p>我们定义了一堆自下而上的确定性非线性映射:， h0= x是输入图像。</p><p><img src="/2021/08/01/SGAN1/1627801876266-1627822969518.png" alt="1627801876266"></p></li><li><p>.提供一个预先训练好的编码器E，我们的目标是训练一个自顶向下的发生器G，它将E反转。具体来说，G由一个自顶向下的发生器Gi栈组成，每个G都被训练成反转一个自底向上的映射Ei。每个Gi将一个高级特征和一个噪声向量zi作为输入，并输出低级特征 ^hi。我们首先独立训练每个GAN，然后以端到端的方式联合训练它们。</p></li><li><p>每个G在独立训练阶段从编码器接收条件输入，在联合训练阶段从上层生成器接收条件输入。</p><p><img src="/2021/08/01/SGAN1/1627802710910-1627822969518.png" alt="1627802710910"></p></li></ol><p>&emsp;</p><p>&emsp;&emsp;<strong>图像的总变化可以被分解成多个级别，具有较高级别的语义变化(例如，属性、对象类别、粗略形状)和较低级别的变化(例如，详细的轮廓和纹理、背景杂波)。</strong></p><p><strong>&emsp;&emsp;为了采样图像，所有的 G 以自上而下的方式堆叠在一起，如图1 (c)所示。</strong></p><h1 id="4、损失函数的设计"><a href="#4、损失函数的设计" class="headerlink" title="4、损失函数的设计"></a>4、损失函数的设计</h1><p> &emsp;&emsp;<em>每个生成器G都是使用三个损失项的线性组合进行训练: 对抗性损失(adversarial loss)、</em></p><p><em>条件性损失(conditional loss)和熵损失(entropy loss)</em></p><p><img src="/2021/08/01/SGAN1/1627803164885-1627822969518.png" alt="1627803164885"></p><h2 id="4-1-对抗性损失-adversarial-loss"><a href="#4-1-对抗性损失-adversarial-loss" class="headerlink" title="4.1 对抗性损失(adversarial loss)"></a>4.1 对抗性损失(adversarial loss)</h2><p> 公式为：</p><p><img src="/2021/08/01/SGAN1/1627803661221-1627822969518.png" alt="1627803661221"></p><h2 id="4-2-条件性损失-conditional-loss"><a href="#4-2-条件性损失-conditional-loss" class="headerlink" title="4.2 条件性损失(conditional loss)"></a>4.2 条件性损失(conditional loss)</h2><p>&emsp;&emsp;&emsp;在每个stack中，一个生成器G被训练来捕获低级表示hi的分布，条件是高级表示hi+1。然而，在上面的公式中，生成器可能会选择忽略hi+1，并从零开始生成可能的^hi+1。本文使用的解决办法是添加一个条件损失项来正则化生成器将生成的较低级别表示 ^hi = Gi(hi+1，zi)反馈给编码器E，并计算恢复的较高级别表示。</p><p>&emsp;&emsp; 其中 f 是距离度量，表示标签和交叉熵的欧氏距离</p><p><img src="/2021/08/01/SGAN1/1627803944276-1627822969518.png" alt="1627803944276"></p><h2 id="4-3-熵损失-entropy-loss"><a href="#4-3-熵损失-entropy-loss" class="headerlink" title="4.3 熵损失(entropy loss)"></a>4.3 熵损失(entropy loss)</h2><p>&emsp;&emsp;简单地加上条件损失会导致另一个问题:生成器Gi学会了忽略噪声zi，并从hi+1中不确定地计算^hi。为了解决这个问题，我们希望当条件为hi+1时，生成的表示^hi足够多样，即条件熵H( ^hi | hi+1)应该尽可能高。由于直接最大化H( ^hi | hi+1)是难以处理的，我们建议改为最大化条件熵的变分下界。</p><p><strong>Variational Conditional Entropy Maximization（变分条件熵最大化）</strong>:</p><p>我们使用辅助分布Qi(zi |^hi)来近似真实后验Pi( zi |^hi)，并且用称为熵损失的损失项来扩充训练目标:</p><p><img src="/2021/08/01/SGAN1/1627805251705-1627822969519.png" alt="1627805251705"></p><p><strong>最小化的L（ent）Gi 等价于最大化的H（^hi 丨hi+1），证明省略。</strong></p><h1 id="5、总结："><a href="#5、总结：" class="headerlink" title="5、总结："></a>5、总结：</h1><h4 id="emsp-emsp-这篇文章提出的新模型训练的生成器G刚好是编码器E的反过来，整个模型是由自上而下的GAN组合而成，每个GAN都生成了表示高级表示的低级特征。同时引入了一个条件损失，它鼓励使用来自上面一层的条件信息，以及一个新的熵损失，他可以最大化G输出的条件熵损失。"><a href="#emsp-emsp-这篇文章提出的新模型训练的生成器G刚好是编码器E的反过来，整个模型是由自上而下的GAN组合而成，每个GAN都生成了表示高级表示的低级特征。同时引入了一个条件损失，它鼓励使用来自上面一层的条件信息，以及一个新的熵损失，他可以最大化G输出的条件熵损失。" class="headerlink" title="&emsp;&emsp;这篇文章提出的新模型训练的生成器G刚好是编码器E的反过来，整个模型是由自上而下的GAN组合而成，每个GAN都生成了表示高级表示的低级特征。同时引入了一个条件损失，它鼓励使用来自上面一层的条件信息，以及一个新的熵损失，他可以最大化G输出的条件熵损失。"></a>&emsp;&emsp;这篇文章提出的新模型训练的生成器G刚好是编码器E的反过来，整个模型是由自上而下的GAN组合而成，每个GAN都生成了表示高级表示的低级特征。同时引入了一个条件损失，它鼓励使用来自上面一层的条件信息，以及一个新的熵损失，他可以最大化G输出的条件熵损失。</h4><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1、论文全名-—-Stacked-Generative-Adversarial-Networks&quot;&gt;&lt;a href=&quot;#1、论文全名-—-Stacked-Generative-Adversarial-Networks&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    <category term="论文阅读（第一层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="GAN（第二层级）" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/GAN%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="GAN，论文阅读" scheme="http://example.com/tags/GAN%EF%BC%8C%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>我的第一个博客(Typora基础的使用技巧)</title>
    <link href="http://example.com/2021/07/31/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%8D%9A%E5%AE%A2/"/>
    <id>http://example.com/2021/07/31/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%8D%9A%E5%AE%A2/</id>
    <published>2021-07-31T07:00:00.000Z</published>
    <updated>2021-08-26T02:30:27.133Z</updated>
    
    <content type="html"><![CDATA[<h2 id><a href="#" class="headerlink" title></a></h2><h2 id="大概花费了2天时间才把hexo框架搭好、刚刚下载了一个Typora编辑器来练练手熟悉一下操作。"><a href="#大概花费了2天时间才把hexo框架搭好、刚刚下载了一个Typora编辑器来练练手熟悉一下操作。" class="headerlink" title="大概花费了2天时间才把hexo框架搭好、刚刚下载了一个Typora编辑器来练练手熟悉一下操作。"></a>大概花费了2天时间才把hexo框架搭好、刚刚下载了一个Typora编辑器来练练手熟悉一下操作。</h2><hr><h2 id="以下是具体的一些基础使用方法。"><a href="#以下是具体的一些基础使用方法。" class="headerlink" title="以下是具体的一些基础使用方法。"></a>以下是具体的一些基础使用方法。</h2><h2 id="1-常用的语法和快捷键"><a href="#1-常用的语法和快捷键" class="headerlink" title="1.常用的语法和快捷键"></a>1.常用的语法和快捷键</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"> Ctrl+1  一阶标题                        Ctrl+B  字体加粗</span><br><span class="line"></span><br><span class="line"> Ctrl+2  二阶标题                        Ctrl+I  字体倾斜</span><br><span class="line"></span><br><span class="line"> Ctrl+3  三阶标题                        Ctrl+U  下划线</span><br><span class="line"></span><br><span class="line"> Ctrl+4  四阶标题                        Ctrl+Home   返回Typora顶部 </span><br><span class="line"></span><br><span class="line">Ctrl+5  五阶标题    Ctrl+End    返回Typora底部 </span><br><span class="line"></span><br><span class="line">Ctrl+6  六阶标题    Ctrl+T  创建表格 </span><br><span class="line"></span><br><span class="line">Ctrl+L  选中某句话     Ctrl+D  选中某个单词 </span><br><span class="line"></span><br><span class="line"> Ctrl+F  搜索                Ctrl+E  选中相同格式的文字   </span><br><span class="line"></span><br><span class="line"> Ctrl+H  搜索并替换                       Alt+Shift+5 删除线</span><br><span class="line"></span><br><span class="line"> Ctrl+Shift+I    插入图片                 Ctrl+Shift+M   公式块 </span><br><span class="line"> </span><br><span class="line"> Ctrl+K（先复制链接，然后选中要加链接的文本，按快捷键。Ctrl+左键点击文本可跳转到对应链接） </span><br><span class="line"> </span><br><span class="line">`代码片段：Ctrl+Shift+ ` </span><br><span class="line"></span><br><span class="line"> 代码块：任意位置按 Ctrl+Shift+K ，然后选择语言然后在代码块中输入代码</span><br></pre></td></tr></table></figure><h4 id="字体颜色的切换："><a href="#字体颜色的切换：" class="headerlink" title="字体颜色的切换："></a>字体颜色的切换：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;span style=<span class="string">&quot;color:red&quot;</span>&gt;这是一个红色&lt;/span&gt;</span><br><span class="line">&lt;span style=<span class="string">&quot;color:blue&quot;</span>&gt;这是一个蓝色&lt;/span&gt;</span><br><span class="line">&lt;span style=<span class="string">&quot;color:green&quot;</span>&gt;这是一个绿色&lt;/span&gt;</span><br><span class="line">&lt;span style=<span class="string">&quot;color:yellow&quot;</span>&gt;这是一个黄色&lt;/span&gt;</span><br></pre></td></tr></table></figure><p><span style="color:red">这是一个红色</span><br><span style="color:blue">这是一个蓝色</span><br><span style="color:green">这是一个绿色</span><br><span style="color:yellow">这是一个黄色</span></p><hr><h2 id="2-列表的生成"><a href="#2-列表的生成" class="headerlink" title="2.列表的生成"></a>2.列表的生成</h2><h4 id="普通列表："><a href="#普通列表：" class="headerlink" title="普通列表："></a>普通列表：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">* 样式<span class="number">1</span></span><br><span class="line">+ 样式<span class="number">2</span></span><br><span class="line">* 加符号前按` Tab `键有缩进效果</span><br><span class="line">    + 第一项</span><br><span class="line">    - 第二项</span><br></pre></td></tr></table></figure><ul><li>这是第一项<ul><li>​    加tab即可<ul><li>继续加tab</li></ul></li></ul></li><li>第二项</li></ul><h4 id="任务列表："><a href="#任务列表：" class="headerlink" title="任务列表："></a>任务列表：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">- [ ] <span class="number">7</span>:<span class="number">00</span> 起床</span><br><span class="line">- [x] <span class="number">8</span>:<span class="number">00</span> 吃饭</span><br></pre></td></tr></table></figure><p>显示效果如下：</p><ul><li><input disabled type="checkbox"> 7:00 起床</li><li><input checked disabled type="checkbox"> 8:00 吃饭</li></ul><hr><h2 id="3-语法生成"><a href="#3-语法生成" class="headerlink" title="3.语法生成"></a>3.语法生成</h2><h4 id="3-1-表格语句"><a href="#3-1-表格语句" class="headerlink" title="3.1 表格语句"></a>3.1 表格语句</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">|姓名|性别|年龄|手机号|</span><br><span class="line">|:---|:--:|:--:|---:|</span><br><span class="line">|张三|男|<span class="number">21</span>|<span class="number">12345678909</span>|</span><br><span class="line">|李四|女|<span class="number">23</span>|<span class="number">12345678908</span>|</span><br><span class="line">|王五|男|<span class="number">25</span>|<span class="number">12345678907</span>|</span><br></pre></td></tr></table></figure><p>生成效果如下:</p><table><thead><tr><th align="left">姓名</th><th align="center">性别</th><th align="center">年龄</th><th align="right">手机号</th></tr></thead><tbody><tr><td align="left">张三</td><td align="center">男</td><td align="center">21</td><td align="right">12345678909</td></tr><tr><td align="left">李四</td><td align="center">女</td><td align="center">23</td><td align="right">12345678908</td></tr><tr><td align="left">王五</td><td align="center">男</td><td align="center">25</td><td align="right">12345678907</td></tr></tbody></table><h4 id="3-2-区块"><a href="#3-2-区块" class="headerlink" title="3.2 区块"></a>3.2 区块</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt; 这是一个区块。</span><br><span class="line">&gt; 网上也有人称为引用。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">区块外层</span><br><span class="line">  &gt; 嵌套<span class="number">0</span></span><br><span class="line">  &gt;&gt; 嵌套<span class="number">1</span></span><br><span class="line">  &gt;&gt;&gt; 嵌套<span class="number">2</span></span><br></pre></td></tr></table></figure><p>生成效果如下:</p><blockquote><p>这是一个区块。<br>网上也有人称为引用。</p></blockquote><p>区块外层</p><blockquote><p>嵌套0</p><blockquote><p>嵌套1</p><blockquote><p>嵌套2</p></blockquote></blockquote></blockquote><hr><h2 id="4-引用"><a href="#4-引用" class="headerlink" title="4.引用"></a>4.引用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27; 引用网址：[显示名称](跳转链接) &#x27;</span></span><br><span class="line">[简书](https://www.jianshu.com/)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27; 引用图片网址链接：！[图象名称](网址/也可以是当前计算机图片路径) &#x27;</span></span><br><span class="line"><span class="string">&#x27; ！[图片名称要不要无所谓，填写会显示](网址/路径是必须要的！)  &#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27; 引用视频链接：&lt;video src=&quot;xxx.mp4&quot; /&gt; (视频不会自动播放!) &#x27;</span></span><br><span class="line">&lt;video src=<span class="string">&quot;https://typora.io/img/beta.mp4&quot;</span>/&gt;</span><br></pre></td></tr></table></figure><p>‘ 引用网址：<a href="%E8%B7%B3%E8%BD%AC%E9%93%BE%E6%8E%A5">显示名称</a> ‘<br><a href="https://www.jianshu.com/">简书</a></p><p>‘ 引用图片网址链接：！<a href="https://www.macz.com/desk/1245.html">孙悟空</a> ‘<br>‘ ！<a href="%E7%BD%91%E5%9D%80/%E8%B7%AF%E5%BE%84%E6%98%AF%E5%BF%85%E9%A1%BB%E8%A6%81%E7%9A%84%EF%BC%81">图片名称要不要无所谓，填写会显示</a>  ‘</p><p>‘ 引用视频链接：<video src="xxx.mp4"> (视频不会自动播放!) ‘<br><video src="https://typora.io/img/beta.mp4"></video></video></p><hr><h2 id="参考网站"><a href="#参考网站" class="headerlink" title="参考网站"></a><a href="https://www.jianshu.com/p/b9bba08b4dd3">参考网站</a></h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id&gt;&lt;a href=&quot;#&quot; class=&quot;headerlink&quot; title&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h2 id=&quot;大概花费了2天时间才把hexo框架搭好、刚刚下载了一个Typora编辑器来练练手熟悉一下操作。&quot;&gt;&lt;a href=&quot;#大概花费了2天时间才把hexo框架搭好、</summary>
      
    
    
    
    <category term="个人博客（第一层级）" scheme="http://example.com/categories/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    <category term="Hexo博客（第二层级）" scheme="http://example.com/categories/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%EF%BC%88%E7%AC%AC%E4%B8%80%E5%B1%82%E7%BA%A7%EF%BC%89/Hexo%E5%8D%9A%E5%AE%A2%EF%BC%88%E7%AC%AC%E4%BA%8C%E5%B1%82%E7%BA%A7%EF%BC%89/"/>
    
    
    <category term="Typora基础的使用技巧" scheme="http://example.com/tags/Typora%E5%9F%BA%E7%A1%80%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"/>
    
  </entry>
  
</feed>
